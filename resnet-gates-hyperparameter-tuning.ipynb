{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow Version: 5.4.1\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print('Pillow Version:', PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.preprocessing.image as preprocess\n",
    "from DataGenerator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing images\n",
    "#path = \"/home/hippoc/schen/imgs_colors/\"\n",
    "path = \"/home/hippoc/bin/beauvoir/data/crop_data/300x200/\"\n",
    "\n",
    "#image_num = 8000\n",
    "#images = np.zeros((image_num, 200, 300, 3))\n",
    "#for i in range(image_num):\n",
    "#    img = preprocess.load_img(path + str(i)+'.png')\n",
    "#    img_array = preprocess.img_to_array(img)\n",
    "#    images[i] = img_array\n",
    "    \n",
    "# preprocessing images (range from 0 to 1)\n",
    "#images /= 255.0\n",
    "\n",
    "#datagen = ImageDataGenerator(\n",
    "#        featurewise_center=True,\n",
    "#        samplewise_center=False,\n",
    "#        featurewise_std_normalization=True,\n",
    "#        samplewise_std_normalization=False,\n",
    "#        zca_whitening=True,\n",
    "#        rotation_range=0,\n",
    "#        width_shift_range=0,\n",
    "#        height_shift_range=0,\n",
    "#        horizontal_flip=False,\n",
    "#        vertical_flip=False\n",
    "#        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (200, 300, 3)\n",
    "\n",
    "#image_num = 58500\n",
    "image_num = 1600\n",
    "training_labels = (1, 1250)\n",
    "validation_labels = (1250, 1600)\n",
    "partition = {}\n",
    "partition['train'] = list(range(training_labels[0], training_labels[1]))\n",
    "partition['validation'] = list(range(validation_labels[0], validation_labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993\n"
     ]
    }
   ],
   "source": [
    "# importing labels\n",
    "f = open(path + 'labels.txt', 'r')\n",
    "labels = f.readlines()\n",
    "labels = [eval(x.strip()) for x in labels]\n",
    "\n",
    "# change labels to range from 0-num of pixels\n",
    "labels = [(x[0] * 300, x[1] * 200) for x in labels]\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "# preprocessing labels (range from -1 to 1)\n",
    "labels_orig = np.round(np.array([[tup[0], tup[1]] for tup in labels]))\n",
    "labels = [[(tup[0]-(input_shape[1]/2))/(input_shape[1]/2), (tup[1]-(input_shape[0]/2))/-(input_shape[0]/2)] for tup in labels]\n",
    "labels = np.array(labels)\n",
    "labels_dict = {}\n",
    "for i in range(image_num):\n",
    "    labels_dict[i] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[177. 127.]\n",
      "[174. 106.]\n",
      "[84. 99.]\n",
      "[137.  75.]\n",
      "[189.  62.]\n",
      "[115.  91.]\n",
      "[134. 131.]\n",
      "[145.  93.]\n",
      "[122.  90.]\n",
      "[153. 114.]\n",
      "[183. 104.]\n",
      "[166.  73.]\n",
      "[164.  91.]\n",
      "[155. 117.]\n",
      "[146. 119.]\n",
      "[121. 136.]\n",
      "[141.  73.]\n",
      "[141.  75.]\n",
      "[160.  83.]\n",
      "[143.  73.]\n",
      "[119.  90.]\n",
      "[169.  71.]\n",
      "[155.  83.]\n",
      "[156. 117.]\n",
      "[160. 115.]\n",
      "[187. 117.]\n",
      "[170.  86.]\n",
      "[111.  97.]\n",
      "[135.  61.]\n",
      "[160. 100.]\n",
      "[141.  70.]\n",
      "[144.  97.]\n",
      "[163. 106.]\n",
      "[137.  90.]\n",
      "[114.  98.]\n",
      "[139. 116.]\n",
      "[166. 127.]\n",
      "[157. 109.]\n",
      "[146.  92.]\n",
      "[147.  77.]\n",
      "[174.  82.]\n",
      "[ 79. 135.]\n",
      "[138. 112.]\n",
      "[105.  81.]\n",
      "[219. 106.]\n",
      "[129. 113.]\n",
      "[129. 108.]\n",
      "[150. 112.]\n",
      "[138. 128.]\n",
      "[ 96. 118.]\n",
      "[178. 107.]\n",
      "[155. 146.]\n",
      "[140.  84.]\n",
      "[154.  61.]\n",
      "[118.  65.]\n",
      "[105.  91.]\n",
      "[154.  87.]\n",
      "[158.  85.]\n",
      "[143.  74.]\n",
      "[145. 133.]\n",
      "[156. 101.]\n",
      "[141. 105.]\n",
      "[189. 117.]\n",
      "[186.  60.]\n",
      "[178. 110.]\n",
      "[159.  73.]\n",
      "[140. 112.]\n",
      "[156.  74.]\n",
      "[163. 109.]\n",
      "[180. 102.]\n",
      "[127.  87.]\n",
      "[163.  94.]\n",
      "[130. 109.]\n",
      "[150. 101.]\n",
      "[172. 117.]\n",
      "[126. 113.]\n",
      "[180.  89.]\n",
      "[174. 102.]\n",
      "[110. 110.]\n",
      "[147. 114.]\n",
      "[140. 129.]\n",
      "[154. 103.]\n",
      "[150. 114.]\n",
      "[203.  54.]\n",
      "[146.  85.]\n",
      "[114.  85.]\n",
      "[130.  73.]\n",
      "[142.  91.]\n",
      "[191. 108.]\n",
      "[137. 116.]\n",
      "[121.  80.]\n",
      "[167.  75.]\n",
      "[174.  83.]\n",
      "[111. 128.]\n",
      "[106.  88.]\n",
      "[162.  86.]\n",
      "[178.  67.]\n",
      "[133. 114.]\n",
      "[127. 115.]\n",
      "[139. 148.]\n",
      "[162. 137.]\n",
      "[179.  98.]\n",
      "[182. 115.]\n",
      "[144. 105.]\n",
      "[122. 141.]\n",
      "[130.  67.]\n",
      "[168. 117.]\n",
      "[133.  79.]\n",
      "[124. 132.]\n",
      "[217. 135.]\n",
      "[133. 123.]\n",
      "[ 93. 109.]\n",
      "[197.  77.]\n",
      "[161.  85.]\n",
      "[132.  95.]\n",
      "[145.  64.]\n",
      "[159.  84.]\n",
      "[112.  67.]\n",
      "[171.  53.]\n",
      "[169.  98.]\n",
      "[145. 117.]\n",
      "[132.  57.]\n",
      "[186. 100.]\n",
      "[173. 121.]\n",
      "[127. 129.]\n",
      "[166. 146.]\n",
      "[146.  84.]\n",
      "[166.  65.]\n",
      "[160. 119.]\n",
      "[186. 118.]\n",
      "[152.  93.]\n",
      "[160.  78.]\n",
      "[123. 105.]\n",
      "[151. 117.]\n",
      "[142.  80.]\n",
      "[131. 101.]\n",
      "[151.  87.]\n",
      "[152.  49.]\n",
      "[121.  87.]\n",
      "[173.  90.]\n",
      "[168.  93.]\n",
      "[163.  91.]\n",
      "[145.  94.]\n",
      "[151.  73.]\n",
      "[121. 135.]\n",
      "[111. 107.]\n",
      "[140.  68.]\n",
      "[82. 60.]\n",
      "[138. 111.]\n",
      "[141.  84.]\n",
      "[147.  65.]\n",
      "[160. 109.]\n",
      "[145.  91.]\n",
      "[114.  82.]\n",
      "[138. 128.]\n",
      "[136. 119.]\n",
      "[184.  79.]\n",
      "[153.  82.]\n",
      "[125.  90.]\n",
      "[114.  77.]\n",
      "[170.  91.]\n",
      "[178.  93.]\n",
      "[139.  68.]\n",
      "[153. 121.]\n",
      "[164. 126.]\n",
      "[126. 118.]\n",
      "[124. 131.]\n",
      "[154.  73.]\n",
      "[178.  83.]\n",
      "[113. 124.]\n",
      "[133.  83.]\n",
      "[113. 112.]\n",
      "[151. 137.]\n",
      "[138. 106.]\n",
      "[181.  85.]\n",
      "[148.  76.]\n",
      "[170.  99.]\n",
      "[151. 121.]\n",
      "[162.  93.]\n",
      "[155.  84.]\n",
      "[155.  98.]\n",
      "[136.  82.]\n",
      "[122.  80.]\n",
      "[165. 100.]\n",
      "[221.  64.]\n",
      "[127. 119.]\n",
      "[184.  84.]\n",
      "[110. 100.]\n",
      "[138. 105.]\n",
      "[111. 122.]\n",
      "[195. 106.]\n",
      "[171.  89.]\n",
      "[176. 156.]\n",
      "[150. 105.]\n",
      "[143. 143.]\n",
      "[115.  58.]\n",
      "[133.  85.]\n",
      "[141.  63.]\n",
      "[159.  83.]\n",
      "[133.  72.]\n"
     ]
    }
   ],
   "source": [
    "# VERIFY THAT IMAGES ARE LABELLED CORRECTLY \n",
    "# puts a cross on the supposed center and saves it to folder \"orig_labels\"\n",
    "\n",
    "from PIL import ImageDraw\n",
    "\n",
    "for i in range(200):\n",
    "    img = Image.open(path + str(i)+'.png')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    pred = labels_orig[i]\n",
    "    \n",
    "    draw.line([tuple(pred - [10, 0]), tuple(pred + [10, 0])], fill=\"blue\", width=3)\n",
    "    draw.line([tuple(pred - [0, 10]), tuple(pred + [0, 10])], fill=\"red\", width=3)\n",
    "\n",
    "#    draw.point(labels_orig[i], fill=\"blue\")\n",
    "#    draw.point(preds[i-12000], fill=\"black\")\n",
    "    print(labels_orig[i])\n",
    "    img.save(path + \"orig_labels/\" + str(i) + \"_label.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'dim': input_shape[0:2],\n",
    "          'batch_size': 32,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03590918  0.08592534]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_dict[152])\n",
    "print(labels_dict[152].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels_dict, path=path, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels_dict, path=path, **params)\n",
    "\n",
    "# testing that images loaded correctly\n",
    "#plt.imshow(images[0])\n",
    "\n",
    "#print(labels)\n",
    "#X, y, indexes = training_generator.__getitem__(0)\n",
    "#print(y[0])\n",
    "#print(labels_dict[indexes[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Input, BatchNormalization, Activation, GaussianNoise\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import History\n",
    "\n",
    "def ResLayer(x, filters):\n",
    "    # identity\n",
    "    res = x\n",
    "    res = BatchNormalization()(res)\n",
    "    res = Conv2D(filters=filters, kernel_size=[1,1], strides=2, padding='same', use_bias=False)(res)\n",
    "    \n",
    "    # conv layers\n",
    "    out = BatchNormalization()(x)\n",
    "    out = Activation('relu')(out)\n",
    "#    out = Activation('relu')(x)\n",
    "    out = Conv2D(filters=filters, kernel_size=[3,3], strides=2, padding='same', use_bias=False)(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Conv2D(filters=filters, kernel_size=[3,3], strides=1, padding='same', use_bias=False)(out)\n",
    "    \n",
    "    # adding the identity\n",
    "    out = keras.layers.add([res,out])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 200, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 150, 32) 2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 49, 74, 32)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 49, 74, 32)   128         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 49, 74, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 37, 32)   9216        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 37, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 49, 74, 32)   128         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 37, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 37, 32)   1024        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 37, 32)   9216        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 25, 37, 32)   0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 37, 32)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 37, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 19, 64)   18432       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 19, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 37, 32)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 13, 19, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, 19, 64)   2048        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 19, 64)   36864       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 19, 64)   0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 13, 19, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 13, 19, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 10, 128)   73728       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 10, 128)   512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 19, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 10, 128)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 10, 128)   8192        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 7, 10, 128)   147456      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 7, 10, 128)   0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 10, 128)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 10, 128)   0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8960)         0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            17922       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 328,450\n",
      "Trainable params: 327,490\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=[5,5], strides=2, padding='same')(inputs)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2)(x)\n",
    "\n",
    "x = ResLayer(x, 32)\n",
    "x = ResLayer(x, 64)\n",
    "x = ResLayer(x, 128)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(2)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def mean_mse(y_true, y_pred):\n",
    "    return K.mean(K.sum(K.square(y_true-y_pred), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss history\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        \n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 508ms/step - loss: 939.4887 - val_loss: 71.4665\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 672.1089 - val_loss: 57.0919\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 496.7586 - val_loss: 53.1082\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 369.2842 - val_loss: 43.7518\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 298.6186 - val_loss: 34.4485\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 233.7928 - val_loss: 29.9142\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 177.7878 - val_loss: 23.9850\n",
      "lr:  5.202518446538067e-05 loss:  23.985022163391115\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 1042.6557 - val_loss: 79.0593\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 744.0903 - val_loss: 65.8385\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 621.7926 - val_loss: 49.9978\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 522.2003 - val_loss: 44.9217\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 439.3505 - val_loss: 39.7913\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 341.9130 - val_loss: 38.0164\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 291.5810 - val_loss: 32.5094\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 910.3228 - val_loss: 82.2264\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 729.9876 - val_loss: 58.1554\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 613.4903 - val_loss: 52.7474\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 527.4425 - val_loss: 48.7446\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 457.2642 - val_loss: 42.3242\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 416.0040 - val_loss: 39.8986\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 346.0362 - val_loss: 34.4757\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 510ms/step - loss: 951.5669 - val_loss: 60.0714\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 607.0708 - val_loss: 51.7370\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 455.9228 - val_loss: 41.1813\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 351.7639 - val_loss: 30.4543\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 267.8565 - val_loss: 23.8563\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 206.7997 - val_loss: 19.7292\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 162.0028 - val_loss: 17.7977\n",
      "lr:  5.496687503797984e-05 loss:  17.79770212173462\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 510.2705 - val_loss: 25.5380\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 85.8230 - val_loss: 10.7165\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 39.5184 - val_loss: 8.0398\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 29.6102 - val_loss: 7.4230\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 26.0371 - val_loss: 7.0717\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 21.8711 - val_loss: 6.5370\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 20.5054 - val_loss: 6.2939\n",
      "lr:  0.0003885538432993505 loss:  6.2938707113265995\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 771.6982 - val_loss: 64.5440\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 540.6656 - val_loss: 40.4169\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 375.2714 - val_loss: 39.2268\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 284.3806 - val_loss: 27.4670\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 215.1412 - val_loss: 22.6915\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 155.2253 - val_loss: 18.6654\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 137.3983 - val_loss: 15.1722\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 656.7659 - val_loss: 8.3316\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.7500 - val_loss: 8.1190\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.5414 - val_loss: 7.6752\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.0745 - val_loss: 7.7867\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 27.7294 - val_loss: 7.6639\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 27.5179 - val_loss: 7.8576\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 26.9797 - val_loss: 7.7430\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 516ms/step - loss: 1319.7440 - val_loss: 110.9935\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1093.3993 - val_loss: 89.6707\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 952.2765 - val_loss: 87.2697\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 935.2336 - val_loss: 83.5872\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 857.8143 - val_loss: 80.1208\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 960.8848 - val_loss: 81.7672\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 858.2358 - val_loss: 79.3086\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 1123.6348 - val_loss: 75.4350\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 674.0472 - val_loss: 62.2053\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 562.4472 - val_loss: 48.2997\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 418.5914 - val_loss: 38.5004\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 349.0429 - val_loss: 32.1499\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 372ms/step - loss: 279.0501 - val_loss: 29.5717\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 242.2860 - val_loss: 26.2386\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 674.2066 - val_loss: 39.1710\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 108.4791 - val_loss: 13.6094\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 47.0884 - val_loss: 10.4909\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 34.4996 - val_loss: 8.5740\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 30.0745 - val_loss: 8.0064\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 27.1719 - val_loss: 7.4008\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 24.5270 - val_loss: 6.9567\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 403.3511 - val_loss: 9.5044\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 32.3279 - val_loss: 7.9193\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 28.3068 - val_loss: 7.7017\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 25.5982 - val_loss: 7.2340\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 22.3823 - val_loss: 6.4428\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 19.8089 - val_loss: 5.9686\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 17.8241 - val_loss: 5.4626\n",
      "lr:  0.0010445606178474292 loss:  5.462560629844665\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 1403.0451 - val_loss: 182.0788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 378ms/step - loss: 1107.8105 - val_loss: 124.3070\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1033.3890 - val_loss: 106.3496\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 977.9230 - val_loss: 100.6864\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 979.5927 - val_loss: 96.9485\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 971.5180 - val_loss: 91.6276\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 939.0517 - val_loss: 86.8412\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 495ms/step - loss: 859.8388 - val_loss: 49.2211\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 358.9269 - val_loss: 27.9756\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 186.7839 - val_loss: 22.3124\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 129.4964 - val_loss: 17.5961\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 85.0502 - val_loss: 13.6629\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 64.7807 - val_loss: 10.8000\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 49.8265 - val_loss: 10.5214\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 503ms/step - loss: 1062.1957 - val_loss: 97.0220\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 961.8366 - val_loss: 85.8549\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 897.2807 - val_loss: 77.6133\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 845.9943 - val_loss: 77.7652\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 814.8243 - val_loss: 74.3891\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 835.6010 - val_loss: 72.5378\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 788.5870 - val_loss: 69.3370\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 1602.4932 - val_loss: 7.7775\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 28.4481 - val_loss: 7.6803\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.3788 - val_loss: 7.8506\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 28.0505 - val_loss: 7.6701\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 27.2835 - val_loss: 7.9997\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 26.2439 - val_loss: 7.1522\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 25.6643 - val_loss: 6.3885\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 840.9193 - val_loss: 57.5253\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 437.0043 - val_loss: 36.1281\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 238.6821 - val_loss: 25.9482\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 162.2418 - val_loss: 19.8562\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 110.8736 - val_loss: 16.7408\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 83.7186 - val_loss: 12.9854\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 61.2226 - val_loss: 11.5407\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 508ms/step - loss: 1179.3242 - val_loss: 101.1706\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1057.7542 - val_loss: 83.7799\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 887.7477 - val_loss: 77.1775\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 802.7124 - val_loss: 75.5116\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 759.8784 - val_loss: 68.2128\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 705.5446 - val_loss: 62.9091\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 650.8756 - val_loss: 59.1401\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 511ms/step - loss: 1075.7451 - val_loss: 109.6053\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1017.9344 - val_loss: 98.1094\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 944.8362 - val_loss: 83.5009\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 929.6406 - val_loss: 79.7505\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 796.4493 - val_loss: 77.5022\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 789.5965 - val_loss: 74.4041\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 790.4539 - val_loss: 67.2681\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 358616.1418 - val_loss: 1527.1111\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 49.6718 - val_loss: 10.5486\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 34.4146 - val_loss: 8.9272\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 31.6219 - val_loss: 8.8959\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 31.2139 - val_loss: 8.6433\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 30.1755 - val_loss: 8.3461\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 29.5763 - val_loss: 8.0933\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 516ms/step - loss: 1260.6990 - val_loss: 191.0805\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 1138.2133 - val_loss: 172.5552\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 1070.0235 - val_loss: 144.7048\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1070.1115 - val_loss: 132.5100\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 960.6103 - val_loss: 126.3085\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 965.5534 - val_loss: 119.8336\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 950.4617 - val_loss: 114.1275\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 514ms/step - loss: 626.9320 - val_loss: 34.7987\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 100.0578 - val_loss: 11.7349\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 41.8674 - val_loss: 8.0896\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 31.5047 - val_loss: 8.0149\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 29.4819 - val_loss: 8.0282\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 25.4180 - val_loss: 6.8683\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 24.2201 - val_loss: 7.1179\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 1208.4996 - val_loss: 70.7251\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 897.6012 - val_loss: 63.6889\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 734.9787 - val_loss: 57.0950\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 717.8158 - val_loss: 49.8840\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 607.3508 - val_loss: 47.5801\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 620.1845 - val_loss: 44.3602\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 536.3620 - val_loss: 40.4789\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 512ms/step - loss: 981.5998 - val_loss: 75.6140\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 379ms/step - loss: 537.4895 - val_loss: 52.6956\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 364.1610 - val_loss: 39.6478\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 360ms/step - loss: 254.2169 - val_loss: 27.5666\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 183.8693 - val_loss: 26.4951\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 138.5917 - val_loss: 18.8972\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 111.6082 - val_loss: 16.2293\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 604.5831 - val_loss: 33.1996\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 107.1498 - val_loss: 12.4067\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 46.5185 - val_loss: 9.0136\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 34.0378 - val_loss: 8.2951\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 28.4787 - val_loss: 7.9644\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 25.3754 - val_loss: 7.5856\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 22.5082 - val_loss: 7.2540\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 503ms/step - loss: 732.4585 - val_loss: 44.1902\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 267.4236 - val_loss: 21.8200\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 123.1572 - val_loss: 16.6350\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 76.5243 - val_loss: 10.9036\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 49.6142 - val_loss: 9.2545\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 39.6909 - val_loss: 8.1921\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 33.0351 - val_loss: 7.6879\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 505ms/step - loss: 516.9857 - val_loss: 20.4520\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 78.3761 - val_loss: 10.2794\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 38.6636 - val_loss: 8.5026\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 29.8080 - val_loss: 8.1746\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 25.7388 - val_loss: 7.7279\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 24.4398 - val_loss: 7.5944\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 23.5002 - val_loss: 7.2921\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 923.9902 - val_loss: 62.6560\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 504.3064 - val_loss: 41.3427\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 351.9541 - val_loss: 29.6827\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 238.7533 - val_loss: 24.0974\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 169.7816 - val_loss: 17.8660\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 122.5698 - val_loss: 15.6253\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 94.9200 - val_loss: 13.7926\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 635.9595 - val_loss: 27.5780\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 95.7033 - val_loss: 13.2025\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 384ms/step - loss: 45.2291 - val_loss: 9.0266\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 33.8465 - val_loss: 8.3292\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.8583 - val_loss: 7.5725\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 25.4522 - val_loss: 7.1750\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 24.1110 - val_loss: 6.9707\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 516ms/step - loss: 1296.8394 - val_loss: 7.9156\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.7059 - val_loss: 7.5267\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.6347 - val_loss: 7.5322\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.5715 - val_loss: 7.9297\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5369 - val_loss: 7.7276\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.5102 - val_loss: 7.8154\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.4875 - val_loss: 7.7827\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 560.6078 - val_loss: 25.0956\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 77.6041 - val_loss: 9.0610\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 36.9574 - val_loss: 8.1520\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 29.5384 - val_loss: 7.5202\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 25.2600 - val_loss: 6.6580\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 21.9614 - val_loss: 6.4219\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 20.4986 - val_loss: 6.1628\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 2077.6564 - val_loss: 8.1319\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 28.6624 - val_loss: 8.0749\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 28.5349 - val_loss: 7.9583\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.5024 - val_loss: 7.8059\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.2409 - val_loss: 8.0441\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.6077 - val_loss: 8.0869\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.3423 - val_loss: 7.9680\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 448.1491 - val_loss: 9.3282\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 29.9482 - val_loss: 7.6053\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 27.8642 - val_loss: 7.6417\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 26.1334 - val_loss: 7.8941\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 24.2259 - val_loss: 7.4155\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 22.0041 - val_loss: 6.6104\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 19.9053 - val_loss: 6.4120\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 1297.2705 - val_loss: 138.4167\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 1052.5873 - val_loss: 108.6757\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 1059.1267 - val_loss: 92.5008\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 924.3516 - val_loss: 90.3139\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 977.6407 - val_loss: 83.5774\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 931.8925 - val_loss: 85.4602\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 948.2725 - val_loss: 79.2350\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 1197.9424 - val_loss: 149.4915\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1090.8200 - val_loss: 135.4081\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 379ms/step - loss: 1102.0871 - val_loss: 136.5876\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1001.3291 - val_loss: 132.5844\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 1046.3964 - val_loss: 120.3745\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1071.8894 - val_loss: 123.3773\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 368ms/step - loss: 1002.2885 - val_loss: 114.4605\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 523ms/step - loss: 681.7480 - val_loss: 74.7539\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 379ms/step - loss: 299.4704 - val_loss: 21.4360\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 127.6289 - val_loss: 13.9005\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 72.9023 - val_loss: 11.1799\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 53.0645 - val_loss: 10.1741\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 42.5228 - val_loss: 9.0311\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 35.7583 - val_loss: 8.7013\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 2494.3472 - val_loss: 8.0379\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.6775 - val_loss: 7.8214\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.6137 - val_loss: 7.6310\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5274 - val_loss: 7.5250\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.4861 - val_loss: 7.9207\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.5575 - val_loss: 8.0486\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5343 - val_loss: 7.7080\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 930.9834 - val_loss: 87.7194\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 833.1890 - val_loss: 69.5272\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 746.9173 - val_loss: 56.4572\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 669.0866 - val_loss: 62.2425\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 662.7389 - val_loss: 48.8533\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 520.3840 - val_loss: 46.9331\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 481.7731 - val_loss: 44.2665\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 862.3473 - val_loss: 65.0857\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 448.0021 - val_loss: 41.4305\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 234.4814 - val_loss: 30.6936\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 159.2010 - val_loss: 23.6713\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 107.4630 - val_loss: 16.7691\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 79.5832 - val_loss: 14.7507\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 63.7139 - val_loss: 12.3066\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 481.5080 - val_loss: 10.3929\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 29.9673 - val_loss: 7.2345\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 26.9176 - val_loss: 7.3491\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 23.5628 - val_loss: 6.8145\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 20.8321 - val_loss: 6.1607\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 18.2974 - val_loss: 5.2197\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 16.6323 - val_loss: 4.3751\n",
      "lr:  0.0011716697285048393 loss:  4.3750690698623655\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 1692.9458 - val_loss: 12.1696\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.5810 - val_loss: 7.8518\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5060 - val_loss: 8.0611\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.7062 - val_loss: 7.6239\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 28.5559 - val_loss: 7.9701\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.4821 - val_loss: 8.0283\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5424 - val_loss: 7.7522\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 512.3627 - val_loss: 23.2386\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 69.5681 - val_loss: 10.0560\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 36.9676 - val_loss: 9.1117\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 29.3481 - val_loss: 7.9986\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 26.3019 - val_loss: 7.3924\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 22.9985 - val_loss: 7.3769\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 20.9068 - val_loss: 7.2106\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 471ms/step - loss: 1003.9660 - val_loss: 78.6240\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 771.3023 - val_loss: 75.1334\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 770.7869 - val_loss: 65.8531\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 699.6750 - val_loss: 66.6429\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 635.3159 - val_loss: 59.1728\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 592.9415 - val_loss: 54.3027\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 518.7170 - val_loss: 52.8248\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 925.5415 - val_loss: 73.3033\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 690.9236 - val_loss: 60.7941\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 518.2602 - val_loss: 58.7800\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 409.6918 - val_loss: 43.5898\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 352.5711 - val_loss: 33.9962\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 257.2217 - val_loss: 30.4893\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 223.9155 - val_loss: 30.9601\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 1301.1232 - val_loss: 118.2755\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 1106.3956 - val_loss: 92.9946\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1009.4724 - val_loss: 85.4800\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 921.4418 - val_loss: 79.6262\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 893.5009 - val_loss: 77.6375\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 852.0876 - val_loss: 75.2623\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 832.1934 - val_loss: 74.4906\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 1104.1345 - val_loss: 103.9424\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 1013.0801 - val_loss: 83.6265\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 906.8684 - val_loss: 76.7401\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 803.8205 - val_loss: 67.6362\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 818.7755 - val_loss: 70.6419\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 746.1108 - val_loss: 62.3133\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 697.9593 - val_loss: 60.4344\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 2503.8600 - val_loss: 8.1742\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 344ms/step - loss: 28.7466 - val_loss: 8.1092\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.6340 - val_loss: 7.9788\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.6150 - val_loss: 8.1305\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.5657 - val_loss: 8.1763\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 28.5023 - val_loss: 7.9769\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.4407 - val_loss: 7.6957\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 1272.2239 - val_loss: 147.1961\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1020.2492 - val_loss: 112.7216\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 967.7133 - val_loss: 92.0143\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 970.5313 - val_loss: 87.1030\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 884.5186 - val_loss: 84.5849\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 895.1208 - val_loss: 77.5567\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 851.5456 - val_loss: 76.0384\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 673.1885 - val_loss: 7.7196\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.6220 - val_loss: 7.7187\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.4071 - val_loss: 7.5538\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.0270 - val_loss: 7.4981\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 27.6322 - val_loss: 7.2473\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 26.8775 - val_loss: 7.5892\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 26.0179 - val_loss: 7.0724\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 549.1989 - val_loss: 47.1667\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 169.1884 - val_loss: 18.2810\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 68.6388 - val_loss: 11.0079\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 41.8207 - val_loss: 8.5602\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 33.4481 - val_loss: 7.8814\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 29.0667 - val_loss: 7.0872\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 25.0664 - val_loss: 7.2083\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 1229.6536 - val_loss: 7.9739\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5422 - val_loss: 7.9208\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.5502 - val_loss: 7.9060\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5723 - val_loss: 7.6712\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.4885 - val_loss: 8.0010\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 28.4822 - val_loss: 7.8720\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.3846 - val_loss: 7.9947\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 500.4876 - val_loss: 9.2493\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 32.2263 - val_loss: 7.8396\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 26.8813 - val_loss: 7.3634\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 24.7535 - val_loss: 7.1127\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 22.6739 - val_loss: 6.4890\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 20.4056 - val_loss: 6.2034\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 18.1558 - val_loss: 5.6744\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 467.5680 - val_loss: 9.4222\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 30.1486 - val_loss: 7.6337\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 26.6439 - val_loss: 7.0249\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 22.7245 - val_loss: 6.5915\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 19.9561 - val_loss: 5.9698\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 18.6106 - val_loss: 5.5938\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 16.4306 - val_loss: 4.8466\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 450628.9418 - val_loss: 24.5795\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 30.8171 - val_loss: 12.1252\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 30.3783 - val_loss: 8.1566\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 29.5459 - val_loss: 8.5723\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 29.4766 - val_loss: 8.3498\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 29.4064 - val_loss: 8.2280\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 29.4239 - val_loss: 8.2342\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 7050.0026 - val_loss: 8.1558\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.9130 - val_loss: 8.0922\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.7027 - val_loss: 7.7749\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.7537 - val_loss: 7.9835\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.6729 - val_loss: 7.9805\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.6905 - val_loss: 7.6778\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.6461 - val_loss: 7.6268\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 1091.2570 - val_loss: 65.1226\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 940.2059 - val_loss: 67.4560\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 909.4112 - val_loss: 63.3032\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 845.7877 - val_loss: 58.5563\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 819.7143 - val_loss: 58.6251\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 805.6729 - val_loss: 56.1750\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 727.6431 - val_loss: 54.7294\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 2731.9548 - val_loss: 8.2716\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.7689 - val_loss: 7.9111\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.6795 - val_loss: 7.5209\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.6147 - val_loss: 8.0274\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.5645 - val_loss: 7.7923\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.4947 - val_loss: 7.7713\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.5728 - val_loss: 7.9045\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 1499.5510 - val_loss: 193.8090\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1137.7712 - val_loss: 143.0826\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1079.1554 - val_loss: 108.6827\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 1057.0407 - val_loss: 101.1338\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 338ms/step - loss: 1046.5657 - val_loss: 95.3012\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 1041.8514 - val_loss: 86.5982\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 925.8918 - val_loss: 82.5931\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 715.0767 - val_loss: 48.9121\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 304.5676 - val_loss: 26.1969\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 146.8972 - val_loss: 16.6160\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 82.7168 - val_loss: 12.8476\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 63.3168 - val_loss: 11.3868\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 49.3644 - val_loss: 10.3914\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 38.0860 - val_loss: 9.4846\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 2028.1188 - val_loss: 319.8758\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1660.3385 - val_loss: 238.3286\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 1401.9770 - val_loss: 172.4628\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 1288.4897 - val_loss: 136.8921\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1163.7050 - val_loss: 114.9579\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1123.8760 - val_loss: 110.3308\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1060.9435 - val_loss: 102.9078\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 617.3042 - val_loss: 7.7390\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.5719 - val_loss: 7.7000\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.3791 - val_loss: 7.6030\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 27.6252 - val_loss: 7.4693\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 27.3526 - val_loss: 7.5040\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 25.8597 - val_loss: 6.9223\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 23.5774 - val_loss: 5.9195\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 596.8509 - val_loss: 27.0805\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 145.3009 - val_loss: 16.0294\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 60.5894 - val_loss: 10.3178\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 38.1625 - val_loss: 9.0077\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 31.8565 - val_loss: 8.0202\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 26.8453 - val_loss: 7.8570\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 24.7418 - val_loss: 7.0408\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 647.0960 - val_loss: 7.4657\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 27.0544 - val_loss: 7.1484\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 25.2673 - val_loss: 6.6625\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 23.4904 - val_loss: 6.2181\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 21.6149 - val_loss: 5.8486\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 18.9558 - val_loss: 5.4432\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 17.6049 - val_loss: 4.5703\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 411.2567 - val_loss: 19.1745\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 41.3465 - val_loss: 9.0264\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 29.2849 - val_loss: 8.1552\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 26.5558 - val_loss: 7.9771\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 23.2594 - val_loss: 7.2789\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 21.6123 - val_loss: 6.4906\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 20.4177 - val_loss: 6.3799\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 503ms/step - loss: 1016.2659 - val_loss: 94.0399\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 817.5536 - val_loss: 86.3946\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 809.8186 - val_loss: 78.5610\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 763.8345 - val_loss: 71.6581\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 724.0990 - val_loss: 65.2573\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 669.2582 - val_loss: 62.8478\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 646.6788 - val_loss: 59.6660\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 879.9870 - val_loss: 59.4877\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 637.8960 - val_loss: 48.6061\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 500.3473 - val_loss: 36.9527\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 377.2290 - val_loss: 33.9544\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 332.9697 - val_loss: 29.0782\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 267.5224 - val_loss: 25.0823\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 210.6979 - val_loss: 22.1468\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1257.7322 - val_loss: 113.8491\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 1008.9545 - val_loss: 97.6724\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 958.0353 - val_loss: 94.6906\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 976.6659 - val_loss: 88.3848\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 1010.3488 - val_loss: 86.7346\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 916.2319 - val_loss: 83.6650\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 919.2888 - val_loss: 80.0852\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 1277.0045 - val_loss: 169.2789\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 1211.6961 - val_loss: 145.0267\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1067.2816 - val_loss: 132.0355\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 1060.8306 - val_loss: 128.0245\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 964.0948 - val_loss: 115.4024\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 963.1802 - val_loss: 109.7069\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 987.2653 - val_loss: 107.2367\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 430.3664 - val_loss: 22.5853\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 58.2695 - val_loss: 9.3372\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 31.5790 - val_loss: 7.8032\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 28.6921 - val_loss: 8.0093\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 26.0584 - val_loss: 7.3833\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 23.7823 - val_loss: 6.9085\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 21.9588 - val_loss: 6.6755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 999.4981 - val_loss: 83.3050\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 858.4617 - val_loss: 69.5899\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 746.1631 - val_loss: 65.9191\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 675.2109 - val_loss: 60.4566\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 636.6383 - val_loss: 58.5119\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 594.2702 - val_loss: 50.2165\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 538.9892 - val_loss: 46.9701\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 1408.8472 - val_loss: 170.2369\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 1202.1304 - val_loss: 157.3908\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1278.4567 - val_loss: 140.1307\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 1240.3220 - val_loss: 130.7200\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1073.3001 - val_loss: 125.2688\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 1122.1142 - val_loss: 116.6196\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1093.2013 - val_loss: 116.7808\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 703.7914 - val_loss: 85.9211\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 353.6480 - val_loss: 36.5387\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 168.0578 - val_loss: 20.0699\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 99.4263 - val_loss: 15.5834\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 64.6693 - val_loss: 13.5648\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 53.9953 - val_loss: 11.5769\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 43.1862 - val_loss: 10.7570\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 905.6989 - val_loss: 69.9011\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 663.9238 - val_loss: 62.6521\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 547.5647 - val_loss: 53.7357\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 488.6449 - val_loss: 52.6024\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 401.0169 - val_loss: 45.5820\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 335.2028 - val_loss: 38.0999\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 315.4661 - val_loss: 32.3895\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 936.8350 - val_loss: 74.0830\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 843.0394 - val_loss: 72.4610\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 828.5260 - val_loss: 66.4931\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 793.9164 - val_loss: 60.1371\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 725.5766 - val_loss: 58.7329\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 692.2895 - val_loss: 57.5607\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 689.0447 - val_loss: 58.1500\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 2624.2005 - val_loss: 7.7021\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.5527 - val_loss: 7.6802\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.5378 - val_loss: 7.9270\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.5092 - val_loss: 7.9213\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.5651 - val_loss: 8.0762\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5731 - val_loss: 7.9990\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.5531 - val_loss: 7.8900\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 20293.5713 - val_loss: 19.9189\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 29.8582 - val_loss: 8.3467\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 29.5300 - val_loss: 7.9693\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 29.3671 - val_loss: 7.7860\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 29.0342 - val_loss: 7.7737\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 29.0202 - val_loss: 7.9286\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.8317 - val_loss: 7.9237\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 767.1531 - val_loss: 72.6873\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 459.6287 - val_loss: 48.3305\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 290.5178 - val_loss: 34.0952\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 198.2134 - val_loss: 26.7204\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 148.3850 - val_loss: 19.0724\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 103.5236 - val_loss: 16.4369\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 77.8012 - val_loss: 13.5754\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 963.8335 - val_loss: 78.1420\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 578.0647 - val_loss: 57.6894\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 455.6635 - val_loss: 45.5440\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 366.4515 - val_loss: 44.2403\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 277.5990 - val_loss: 32.5377\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 224.7355 - val_loss: 28.5469\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 179.0342 - val_loss: 23.5277\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 883.8428 - val_loss: 79.2277\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 528.4085 - val_loss: 53.7838\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 386.2614 - val_loss: 40.9066\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 282.7943 - val_loss: 32.9047\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 197.6804 - val_loss: 27.8231\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 138.9069 - val_loss: 20.3584\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 119.5628 - val_loss: 18.4569\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 3672.5582 - val_loss: 8.3094\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.8217 - val_loss: 7.6953\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.7407 - val_loss: 7.8387\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.5769 - val_loss: 7.6457\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.5752 - val_loss: 7.8300\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.5845 - val_loss: 7.9514\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.6222 - val_loss: 7.8125\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1146.3380 - val_loss: 8.2268\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.4798 - val_loss: 8.0007\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.4452 - val_loss: 8.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.0625 - val_loss: 7.6231\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 27.3863 - val_loss: 7.4082\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 26.9250 - val_loss: 7.6267\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 25.9719 - val_loss: 7.1453\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1293.4350 - val_loss: 145.6848\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 1010.8420 - val_loss: 123.7145\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 921.1884 - val_loss: 113.7604\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 943.5230 - val_loss: 106.8310\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 882.8780 - val_loss: 102.7653\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 861.7918 - val_loss: 94.3991\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 823.1515 - val_loss: 90.5367\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1343.8087 - val_loss: 126.2357\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 979.4016 - val_loss: 94.0295\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 996.2935 - val_loss: 90.6142\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 900.2948 - val_loss: 86.8576\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 848.6871 - val_loss: 77.9459\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 859.0776 - val_loss: 79.9072\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 790.5084 - val_loss: 78.7543\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 1033.9489 - val_loss: 71.7860\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 658.8064 - val_loss: 51.9592\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 472.7309 - val_loss: 36.5831\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 342.8879 - val_loss: 34.3715\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 252.3454 - val_loss: 24.1014\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 198.1877 - val_loss: 20.4567\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 153.3557 - val_loss: 17.4966\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 5545.7201 - val_loss: 7.8919\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.9209 - val_loss: 7.9412\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 28.8308 - val_loss: 7.9905\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.7682 - val_loss: 7.6632\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.7015 - val_loss: 7.7061\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.6080 - val_loss: 7.8144\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.6056 - val_loss: 8.0295\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 827.1475 - val_loss: 47.1362\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 391.9353 - val_loss: 36.6530\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 188.9542 - val_loss: 21.3218\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 129.0745 - val_loss: 16.6958\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 85.8576 - val_loss: 12.4213\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 65.4371 - val_loss: 11.2748\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 51.2524 - val_loss: 10.1510\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 1013.7235 - val_loss: 81.2888\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 908.6169 - val_loss: 75.8215\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 829.5211 - val_loss: 68.3126\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 773.1878 - val_loss: 65.7108\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 720.4559 - val_loss: 69.9624\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 715.9260 - val_loss: 65.1181\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 656.1537 - val_loss: 56.3395\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 767.7512 - val_loss: 48.4028\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 248.1206 - val_loss: 27.3614\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 107.8214 - val_loss: 17.8619\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 68.5444 - val_loss: 12.8377\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 49.8595 - val_loss: 10.1935\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 41.0235 - val_loss: 8.7414\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 32.7473 - val_loss: 7.7417\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 711.4601 - val_loss: 59.4918\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 273.4212 - val_loss: 32.2562\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 132.5624 - val_loss: 19.4807\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 85.1936 - val_loss: 13.1004\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 53.8409 - val_loss: 11.1668\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 43.9600 - val_loss: 9.6016\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 38.2147 - val_loss: 8.7007\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 494ms/step - loss: 3850.3148 - val_loss: 8.4748\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.8743 - val_loss: 7.9330\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.9515 - val_loss: 7.9324\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.7442 - val_loss: 7.9581\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.5062 - val_loss: 7.8170\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.5414 - val_loss: 8.0777\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.5756 - val_loss: 7.6921\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 494ms/step - loss: 741.2310 - val_loss: 53.7507\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 252.0596 - val_loss: 21.5730\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 98.0818 - val_loss: 13.6600\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 55.7030 - val_loss: 10.7790\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 41.3496 - val_loss: 8.9339\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 33.4749 - val_loss: 8.2972\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 29.6485 - val_loss: 7.9082\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 713.7676 - val_loss: 7.2725\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.6290 - val_loss: 7.7118\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 28.3499 - val_loss: 7.4290\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.0892 - val_loss: 7.8977\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.0036 - val_loss: 7.9483\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 27.2957 - val_loss: 7.7346\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 331ms/step - loss: 27.1779 - val_loss: 7.8028\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 1062.6245 - val_loss: 107.7501\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 987.9697 - val_loss: 99.6077\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 943.3111 - val_loss: 96.5527\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 900.9743 - val_loss: 94.6296\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 928.3349 - val_loss: 89.6422\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 910.6796 - val_loss: 88.9617\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 834.4915 - val_loss: 87.0775\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1094.0497 - val_loss: 95.7800\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 940.0241 - val_loss: 79.3994\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 836.2816 - val_loss: 73.4116\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 810.4088 - val_loss: 68.1390\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 727.0509 - val_loss: 61.6197\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 743.8928 - val_loss: 59.3386\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 675.0354 - val_loss: 54.6688\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 506ms/step - loss: 1971.5718 - val_loss: 333.1414\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1602.6858 - val_loss: 248.2694\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1413.2856 - val_loss: 187.5402\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1283.8208 - val_loss: 150.4797\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1124.5509 - val_loss: 124.1708\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1120.7529 - val_loss: 106.4738\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 974.2522 - val_loss: 97.4570\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 1233.1005 - val_loss: 100.9426\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 929.9613 - val_loss: 86.2776\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 911.2727 - val_loss: 78.6591\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 890.0847 - val_loss: 73.7200\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 859.6266 - val_loss: 71.0040\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 804.3380 - val_loss: 70.0927\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 795.3166 - val_loss: 68.6248\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1008.0037 - val_loss: 86.2166\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 925.8003 - val_loss: 79.1158\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 811.0139 - val_loss: 72.4297\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 814.6133 - val_loss: 69.0350\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 810.3289 - val_loss: 72.3183\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 816.9787 - val_loss: 67.5737\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 685.0941 - val_loss: 63.8398\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 921.2345 - val_loss: 79.1479\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 793.2114 - val_loss: 61.9713\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 702.2705 - val_loss: 62.6188\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 558.0845 - val_loss: 52.7536\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 511.2355 - val_loss: 49.8048\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 444.8377 - val_loss: 47.4639\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 422.3797 - val_loss: 45.4996\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 828.7944 - val_loss: 7.4823\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.6599 - val_loss: 7.8102\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.3680 - val_loss: 7.5579\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.1399 - val_loss: 7.6745\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 27.0087 - val_loss: 7.5746\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 25.9987 - val_loss: 7.0377\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 24.1147 - val_loss: 6.7395\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 1150.8798 - val_loss: 167.2255\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1044.5704 - val_loss: 152.3705\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1052.1045 - val_loss: 145.0251\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 904.4161 - val_loss: 136.0902\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 879.1459 - val_loss: 128.7901\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 978.7403 - val_loss: 124.8487\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 931.2055 - val_loss: 115.1650\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1166.5040 - val_loss: 121.3158\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 991.5006 - val_loss: 114.8774\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 944.7756 - val_loss: 107.2968\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 969.6855 - val_loss: 102.0556\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 925.1504 - val_loss: 99.0518\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 930.1363 - val_loss: 98.3830\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 925.9964 - val_loss: 96.4577\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 1185.1257 - val_loss: 80.6285\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 929.0602 - val_loss: 69.1869\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 892.5626 - val_loss: 64.2239\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 838.7467 - val_loss: 61.1434\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 714.7925 - val_loss: 58.0522\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 729.0169 - val_loss: 55.3758\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 642.5307 - val_loss: 50.1748\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1769.9848 - val_loss: 7.4838\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.5021 - val_loss: 8.0205\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.4226 - val_loss: 7.8882\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5595 - val_loss: 7.7028\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.5491 - val_loss: 7.4910\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.5425 - val_loss: 7.6589\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.5034 - val_loss: 7.6703\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1629.6098 - val_loss: 257.3647\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 354ms/step - loss: 1337.2772 - val_loss: 199.6037\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1170.1024 - val_loss: 162.0165\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 1132.7894 - val_loss: 137.1228\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 994.7358 - val_loss: 111.1756\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 1002.9562 - val_loss: 110.9246\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 880.0567 - val_loss: 105.4945\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 1101.5029 - val_loss: 128.4403\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 1216.9975 - val_loss: 112.8684\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 1164.1521 - val_loss: 116.0362\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1075.4311 - val_loss: 112.8321\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 1039.6055 - val_loss: 101.8171\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1029.7317 - val_loss: 107.8433\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 962.9518 - val_loss: 103.8004\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 998.0116 - val_loss: 89.0653\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 903.4569 - val_loss: 82.9186\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 949.0357 - val_loss: 79.2975\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 802.3993 - val_loss: 75.9687\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 837.1838 - val_loss: 73.0717\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 817.7533 - val_loss: 69.8107\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 825.7468 - val_loss: 71.6214\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 2216.3438 - val_loss: 8.0157\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.6085 - val_loss: 7.7411\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5811 - val_loss: 7.7844\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5798 - val_loss: 7.9901\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.5695 - val_loss: 7.6418\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.5800 - val_loss: 7.6657\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.5617 - val_loss: 7.7830\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 430.5809 - val_loss: 12.6254\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 43.8464 - val_loss: 8.8767\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 29.6184 - val_loss: 7.4810\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 23.1458 - val_loss: 6.9698\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 22.3371 - val_loss: 6.5418\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 19.5871 - val_loss: 6.2425\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 17.3861 - val_loss: 5.9195\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 1013.5338 - val_loss: 75.8776\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 828.6801 - val_loss: 68.5047\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 737.3812 - val_loss: 59.9468\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 823.0819 - val_loss: 62.1752\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 724.7354 - val_loss: 56.7440\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 697.8101 - val_loss: 55.1119\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 649.1800 - val_loss: 52.0500\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1407.8343 - val_loss: 213.0787\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1294.3571 - val_loss: 173.3063\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 1091.9127 - val_loss: 135.3285\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 1010.2171 - val_loss: 103.9147\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 872.8324 - val_loss: 94.2659\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 835.8983 - val_loss: 82.2355\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 829.3179 - val_loss: 78.2598\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1301.5659 - val_loss: 124.4530\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1184.4365 - val_loss: 107.2140\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1078.8076 - val_loss: 99.2511\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1027.9388 - val_loss: 90.1552\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 998.4732 - val_loss: 85.5624\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1042.7669 - val_loss: 86.2077\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 985.8345 - val_loss: 84.1320\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 500ms/step - loss: 810.3787 - val_loss: 53.5031\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 498.3918 - val_loss: 36.3050\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 322.4518 - val_loss: 33.0402\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 246.7153 - val_loss: 25.5416\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 173.4238 - val_loss: 20.6336\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 124.6839 - val_loss: 16.6091\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 109.7502 - val_loss: 14.8613\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 481.8421 - val_loss: 33.3037\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 90.7699 - val_loss: 10.3870\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 37.5361 - val_loss: 8.6650\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 29.8840 - val_loss: 7.6190\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 27.1637 - val_loss: 7.6009\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 24.3891 - val_loss: 7.0584\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 22.3288 - val_loss: 7.1465\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 426.2547 - val_loss: 13.2190\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 43.6895 - val_loss: 8.7191\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 29.7915 - val_loss: 6.8927\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 25.2935 - val_loss: 6.8946\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 22.5998 - val_loss: 6.2599\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 20.0157 - val_loss: 6.2705\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 17.6837 - val_loss: 5.2555\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 477ms/step - loss: 1178.8532 - val_loss: 129.7270\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 907.3610 - val_loss: 105.5636\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 919.9074 - val_loss: 88.0126\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 344ms/step - loss: 799.1033 - val_loss: 77.5567\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 783.9724 - val_loss: 69.9284\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 782.6405 - val_loss: 69.8781\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 734.1841 - val_loss: 65.7886\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 780.2019 - val_loss: 58.2776\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 458.6397 - val_loss: 44.0985\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 360.7022 - val_loss: 34.6205\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 230.8627 - val_loss: 24.2057\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 162.5963 - val_loss: 19.5461\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 126.6826 - val_loss: 16.2050\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 98.8857 - val_loss: 13.9727\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 756.4858 - val_loss: 53.7100\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 365.1133 - val_loss: 37.6225\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 233.5625 - val_loss: 26.5759\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 143.6179 - val_loss: 20.7784\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 91.9478 - val_loss: 14.3050\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 75.0323 - val_loss: 12.3907\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 57.9327 - val_loss: 10.8069\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 599.8135 - val_loss: 10.8117\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 33.0758 - val_loss: 8.4151\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 27.3031 - val_loss: 7.7027\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 24.5720 - val_loss: 7.2450\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 22.9725 - val_loss: 6.1790\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 20.6180 - val_loss: 6.0628\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 18.0471 - val_loss: 5.4674\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 757.9981 - val_loss: 7.8245\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.5523 - val_loss: 7.8270\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.4893 - val_loss: 8.0516\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.4289 - val_loss: 7.8954\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.4614 - val_loss: 7.9229\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.4148 - val_loss: 7.9525\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.3147 - val_loss: 8.1249\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 1648.0295 - val_loss: 8.9955\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.8223 - val_loss: 8.1763\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.7050 - val_loss: 7.6316\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 28.4113 - val_loss: 7.7639\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.4366 - val_loss: 7.8275\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.0555 - val_loss: 7.7536\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 27.6824 - val_loss: 7.3645\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 1252.0131 - val_loss: 137.2822\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1115.0825 - val_loss: 112.6732\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1055.7896 - val_loss: 104.5839\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 983.4040 - val_loss: 98.3724\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 976.0309 - val_loss: 95.9508\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 941.3298 - val_loss: 93.8532\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 970.2494 - val_loss: 88.9896\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 1026.5838 - val_loss: 107.8894\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1027.9461 - val_loss: 95.0532\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 939.0458 - val_loss: 88.1347\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 921.7903 - val_loss: 85.7414\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 942.1048 - val_loss: 81.1736\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 905.9847 - val_loss: 75.8353\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 897.8592 - val_loss: 80.9248\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1051.6368 - val_loss: 82.6132\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 920.0690 - val_loss: 73.8563\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 748.3446 - val_loss: 66.6909\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 708.5677 - val_loss: 64.7968\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 720.9179 - val_loss: 59.8577\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 723.5517 - val_loss: 58.7059\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 662.5996 - val_loss: 56.9299\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 852.7328 - val_loss: 8.0097\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.5576 - val_loss: 7.5932\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 28.5256 - val_loss: 7.7990\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.4760 - val_loss: 8.0014\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5445 - val_loss: 8.1152\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.1533 - val_loss: 7.7381\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 27.7807 - val_loss: 7.4589\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 488.8883 - val_loss: 20.7600\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 53.9448 - val_loss: 8.0702\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 31.1839 - val_loss: 7.4215\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 26.1645 - val_loss: 6.6056\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 22.9011 - val_loss: 6.3577\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 21.0999 - val_loss: 5.5591\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 18.2714 - val_loss: 5.7832\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 1284.4686 - val_loss: 161.8734\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1050.3479 - val_loss: 117.7822\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 1011.4471 - val_loss: 102.2604\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 947.3106 - val_loss: 92.8299\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 885.3870 - val_loss: 95.7938\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 876.2420 - val_loss: 86.1872\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 341ms/step - loss: 917.9731 - val_loss: 86.4196\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1139.1712 - val_loss: 91.8254\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 969.4386 - val_loss: 78.0519\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 916.7809 - val_loss: 73.3539\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 884.0480 - val_loss: 71.9462\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 846.4095 - val_loss: 65.2024\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 800.4191 - val_loss: 62.2245\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 729.9021 - val_loss: 58.7010\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 694.6913 - val_loss: 43.1727\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 278.3463 - val_loss: 26.1089\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 140.6680 - val_loss: 16.7698\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 82.0725 - val_loss: 13.8831\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 59.9925 - val_loss: 11.9033\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 45.7180 - val_loss: 10.0177\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 38.0607 - val_loss: 9.5074\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 659.4417 - val_loss: 8.1121\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.8184 - val_loss: 7.9197\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.4980 - val_loss: 7.4594\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.2993 - val_loss: 7.5963\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 27.9638 - val_loss: 7.9221\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 27.7956 - val_loss: 7.7170\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 27.1478 - val_loss: 7.5682\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 1138.2578 - val_loss: 90.9067\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 966.4581 - val_loss: 71.9533\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 842.8800 - val_loss: 69.9589\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 865.7900 - val_loss: 64.3195\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 813.6504 - val_loss: 65.7833\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 838.5579 - val_loss: 60.4233\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 751.2611 - val_loss: 58.7679\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 923.1444 - val_loss: 70.7927\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 722.3331 - val_loss: 57.3341\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 709.7534 - val_loss: 52.7973\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 582.4482 - val_loss: 46.7546\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 533.9243 - val_loss: 45.4180\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 481.6314 - val_loss: 45.1163\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 418.3467 - val_loss: 35.7805\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 1197.1374 - val_loss: 80.7280\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 877.8353 - val_loss: 72.7628\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 748.6908 - val_loss: 64.4503\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 634.1286 - val_loss: 55.3895\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 589.7811 - val_loss: 53.2034\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 533.5682 - val_loss: 49.5194\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 544.4147 - val_loss: 45.4032\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 1481.7685 - val_loss: 204.3628\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 970.3136 - val_loss: 133.7655\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 912.3939 - val_loss: 108.2930\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 857.7391 - val_loss: 99.8148\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 820.4874 - val_loss: 85.7734\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 799.9869 - val_loss: 78.8227\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 674.9042 - val_loss: 77.8747\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 3043.9237 - val_loss: 8.0376\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.7231 - val_loss: 7.9533\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.6825 - val_loss: 8.0398\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.6587 - val_loss: 8.0742\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.6375 - val_loss: 8.0225\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.6186 - val_loss: 7.8683\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5282 - val_loss: 7.7711\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 952.6502 - val_loss: 88.1847\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 693.4289 - val_loss: 69.0063\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 582.2871 - val_loss: 56.9444\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 499.0915 - val_loss: 47.2275\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 413.9371 - val_loss: 40.8884\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 367.9501 - val_loss: 34.5988\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 301.5123 - val_loss: 31.4584\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 826.1629 - val_loss: 52.4235\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 427.5438 - val_loss: 33.3933\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 249.6039 - val_loss: 24.1736\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 160.1834 - val_loss: 19.2008\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 118.5201 - val_loss: 15.7147\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 85.3971 - val_loss: 13.4447\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 68.9268 - val_loss: 11.2543\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 943.3483 - val_loss: 94.3211\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 847.9159 - val_loss: 76.3948\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 766.3345 - val_loss: 75.9603\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 765.0151 - val_loss: 67.4590\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 671.3500 - val_loss: 68.6174\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 641.4544 - val_loss: 61.8385\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 609.9543 - val_loss: 58.8888\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 591.1852 - val_loss: 37.2669\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 158.8496 - val_loss: 17.1865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 61.5756 - val_loss: 11.9334\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 39.9983 - val_loss: 9.6141\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 31.7811 - val_loss: 9.0612\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.4389 - val_loss: 8.0216\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 25.1180 - val_loss: 7.6947\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 1031.9112 - val_loss: 86.3283\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 920.7062 - val_loss: 84.0414\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 911.8156 - val_loss: 74.2072\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 873.0102 - val_loss: 66.6486\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 767.1748 - val_loss: 66.8472\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 719.6670 - val_loss: 64.9638\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 669.9767 - val_loss: 63.0771\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 476ms/step - loss: 730.0373 - val_loss: 62.8109\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 453.7702 - val_loss: 36.7297\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 246.8267 - val_loss: 28.0591\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 156.2840 - val_loss: 17.4919\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 114.3476 - val_loss: 14.9902\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 82.1088 - val_loss: 12.3366\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 64.2801 - val_loss: 10.6158\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1026.3765 - val_loss: 85.3683\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 876.8597 - val_loss: 71.0534\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 843.4235 - val_loss: 60.3331\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 732.0821 - val_loss: 59.3744\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 689.6499 - val_loss: 52.9891\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 622.0752 - val_loss: 49.9943\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 581.1294 - val_loss: 48.2791\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 1071.2731 - val_loss: 120.7695\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 994.8072 - val_loss: 101.4289\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 985.0076 - val_loss: 83.1873\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 913.3511 - val_loss: 82.4559\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 764.5411 - val_loss: 74.0311\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 796.9778 - val_loss: 73.5489\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 773.7534 - val_loss: 70.2137\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 2563.8512 - val_loss: 11.5446\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 30.0910 - val_loss: 7.9996\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5800 - val_loss: 8.0001\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.7055 - val_loss: 8.0052\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.4177 - val_loss: 8.0153\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.2345 - val_loss: 8.2194\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.4161 - val_loss: 7.9659\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 937.3337 - val_loss: 64.2189\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 621.3793 - val_loss: 58.4513\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 447.2125 - val_loss: 47.4538\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 352.9877 - val_loss: 39.4425\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 271.2530 - val_loss: 30.3006\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 226.4362 - val_loss: 24.8282\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 191.0984 - val_loss: 22.8366\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 467ms/step - loss: 3149.8303 - val_loss: 7.6784\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 28.8952 - val_loss: 7.8747\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.7667 - val_loss: 8.1747\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.6381 - val_loss: 7.7384\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 28.7032 - val_loss: 7.6653\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5892 - val_loss: 7.6117\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.7006 - val_loss: 8.0182\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 1096.9828 - val_loss: 98.5518\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 965.3197 - val_loss: 86.9398\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 910.1629 - val_loss: 87.0689\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 967.3490 - val_loss: 80.8469\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 870.6965 - val_loss: 83.0454\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 915.4945 - val_loss: 78.0971\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 852.5657 - val_loss: 74.4908\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 553.1982 - val_loss: 8.2205\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 28.0691 - val_loss: 7.4634\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 27.4861 - val_loss: 7.2138\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 25.2072 - val_loss: 6.7861\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 23.7525 - val_loss: 5.8687\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 21.5096 - val_loss: 4.9509\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 18.3461 - val_loss: 4.2113\n",
      "lr:  0.0017843954056631377 loss:  4.21126081943512\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 1430.3696 - val_loss: 181.3818\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1187.0752 - val_loss: 143.6735\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1046.4634 - val_loss: 121.0392\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 1015.7087 - val_loss: 109.7373\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 914.0540 - val_loss: 99.4533\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 897.6749 - val_loss: 96.8109\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 879.9133 - val_loss: 86.4031\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 433.0305 - val_loss: 14.9768\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 38.6187 - val_loss: 7.9904\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 28.8977 - val_loss: 7.8321\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 26.5701 - val_loss: 7.0227\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 347ms/step - loss: 23.9745 - val_loss: 7.1170\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 21.5583 - val_loss: 6.5318\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 19.3038 - val_loss: 6.2139\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 845.7564 - val_loss: 65.9016\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 483.6609 - val_loss: 41.3377\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 287.3231 - val_loss: 30.1029\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 192.5322 - val_loss: 21.8907\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 142.3933 - val_loss: 19.0270\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 95.6610 - val_loss: 16.0238\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 77.6076 - val_loss: 12.2800\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 587.3364 - val_loss: 10.7981\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 31.9824 - val_loss: 7.5497\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 27.0162 - val_loss: 6.8518\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 24.1975 - val_loss: 6.5791\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 20.9342 - val_loss: 6.0882\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 18.8274 - val_loss: 5.6388\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 17.2724 - val_loss: 5.3435\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 1081.4053 - val_loss: 82.8647\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 885.0722 - val_loss: 74.3274\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 740.9374 - val_loss: 67.1913\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 663.9843 - val_loss: 57.8751\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 602.6938 - val_loss: 54.7641\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 530.1864 - val_loss: 47.3204\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 504.3090 - val_loss: 41.4731\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 2055.3143 - val_loss: 9.8649\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 30.2106 - val_loss: 8.2576\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.8312 - val_loss: 8.1676\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.3690 - val_loss: 7.9258\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.0994 - val_loss: 7.8451\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.1233 - val_loss: 7.6858\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 27.5963 - val_loss: 7.7695\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 918.2519 - val_loss: 63.3764\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 468.5306 - val_loss: 44.8575\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 281.4483 - val_loss: 34.8505\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 190.7741 - val_loss: 26.4442\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 136.4486 - val_loss: 19.4712\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 95.5885 - val_loss: 16.0964\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 72.6243 - val_loss: 13.6468\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 987.2508 - val_loss: 118.1740\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 933.1947 - val_loss: 98.8893\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 977.5279 - val_loss: 93.2408\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 955.7020 - val_loss: 85.9881\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 873.3952 - val_loss: 86.9883\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 821.3611 - val_loss: 85.2981\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 795.4358 - val_loss: 84.1197\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 1082.6260 - val_loss: 104.8418\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 1001.1673 - val_loss: 81.9822\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 909.1664 - val_loss: 83.7830\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 751.0743 - val_loss: 76.1559\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 755.1248 - val_loss: 72.5313\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 687.4758 - val_loss: 68.1986\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 705.7924 - val_loss: 61.8240\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 6801.1885 - val_loss: 7.9254\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.9419 - val_loss: 7.9653\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 28.8592 - val_loss: 7.7992\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.7715 - val_loss: 7.8852\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 28.7941 - val_loss: 7.7058\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.6708 - val_loss: 7.5841\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 28.6496 - val_loss: 8.0592\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 419.0095 - val_loss: 10.4932\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 34.1529 - val_loss: 8.0657\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.7258 - val_loss: 7.5994\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 26.7841 - val_loss: 7.6088\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 23.8147 - val_loss: 7.3928\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 23.0757 - val_loss: 6.8932\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 21.3564 - val_loss: 6.8146\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1695.3242 - val_loss: 186.2426\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1258.6605 - val_loss: 129.3834\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 1168.6418 - val_loss: 113.5065\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 1105.3492 - val_loss: 108.6705\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1064.9858 - val_loss: 102.5361\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 999.7572 - val_loss: 93.0711\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1001.9199 - val_loss: 86.9719\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 1243.8463 - val_loss: 138.7650\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1107.0352 - val_loss: 122.1948\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 375ms/step - loss: 1066.1328 - val_loss: 105.9425\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1050.3564 - val_loss: 89.0770\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 944.5240 - val_loss: 91.0688\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 1021.7941 - val_loss: 80.4896\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 942.6640 - val_loss: 79.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 776.3096 - val_loss: 85.9132\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 428.2589 - val_loss: 50.2141\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 246.1374 - val_loss: 28.2406\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 160.1177 - val_loss: 20.1138\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 112.1489 - val_loss: 15.7720\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 79.7823 - val_loss: 13.8119\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 64.2031 - val_loss: 11.7397\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1269.6952 - val_loss: 154.9929\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 1028.7163 - val_loss: 115.0987\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 981.3619 - val_loss: 100.8425\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 948.0894 - val_loss: 88.6045\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 818.1916 - val_loss: 86.1222\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 879.8381 - val_loss: 79.5173\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 878.7053 - val_loss: 78.1538\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 491ms/step - loss: 334.9322 - val_loss: 9.1742\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 29.5459 - val_loss: 7.6316\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 27.3829 - val_loss: 7.5504\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 25.3982 - val_loss: 7.0936\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 23.6633 - val_loss: 6.5624\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 20.0894 - val_loss: 6.2130\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 18.0960 - val_loss: 5.5135\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 1126.4992 - val_loss: 102.1445\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 900.6407 - val_loss: 85.9136\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 877.3566 - val_loss: 77.2296\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 804.0696 - val_loss: 75.3438\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 822.9438 - val_loss: 69.8965\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 808.7869 - val_loss: 67.8976\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 764.8224 - val_loss: 68.1694\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 709.6669 - val_loss: 8.3106\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 29.8599 - val_loss: 8.0686\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 28.4552 - val_loss: 8.0489\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 27.9983 - val_loss: 7.8925\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 27.8518 - val_loss: 7.7681\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 27.6527 - val_loss: 7.1454\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 26.8476 - val_loss: 8.0031\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 473ms/step - loss: 486.5224 - val_loss: 8.1372\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.6974 - val_loss: 7.9692\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.3083 - val_loss: 7.8935\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.0387 - val_loss: 7.8419\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 28.1793 - val_loss: 7.9191\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 27.7548 - val_loss: 7.6735\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 27.7116 - val_loss: 7.9903\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 1051.7386 - val_loss: 102.6852\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 983.4326 - val_loss: 94.0654\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 962.3756 - val_loss: 82.2303\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 969.5201 - val_loss: 87.4042\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 911.5221 - val_loss: 80.7003\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 881.9380 - val_loss: 77.6606\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 902.2491 - val_loss: 71.6598\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 990.8303 - val_loss: 75.2381\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 899.1310 - val_loss: 75.9302\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 854.1453 - val_loss: 67.6164\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 834.9575 - val_loss: 64.2553\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 785.6809 - val_loss: 63.8134\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 756.4111 - val_loss: 61.6010\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 702.2839 - val_loss: 59.6252\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 948.6467 - val_loss: 73.8559\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 828.1675 - val_loss: 60.7598\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 757.7887 - val_loss: 59.6953\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 664.3864 - val_loss: 53.0037\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 607.4828 - val_loss: 49.3742\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 501.5650 - val_loss: 45.6852\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 462.0691 - val_loss: 41.8796\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 3807.0865 - val_loss: 8.0638\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.8023 - val_loss: 7.6050\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.6777 - val_loss: 8.2601\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.6904 - val_loss: 8.0506\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.6451 - val_loss: 8.1004\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.5840 - val_loss: 7.7906\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.5405 - val_loss: 7.8901\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 799.5298 - val_loss: 54.3218\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 383.6553 - val_loss: 28.8486\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 204.2578 - val_loss: 22.4540\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 132.3384 - val_loss: 16.3778\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 89.3223 - val_loss: 14.9570\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 69.8800 - val_loss: 11.7171\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 55.1458 - val_loss: 10.4507\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1189.9099 - val_loss: 84.8453\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1003.0040 - val_loss: 74.0536\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 915.7103 - val_loss: 73.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 878.1840 - val_loss: 68.7403\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 805.7207 - val_loss: 67.6805\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 857.7246 - val_loss: 63.6143\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 787.0254 - val_loss: 60.1780\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 371.0817 - val_loss: 9.0012\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 29.7955 - val_loss: 7.5700\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.0802 - val_loss: 7.5340\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 27.3894 - val_loss: 7.7895\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 27.2032 - val_loss: 7.8206\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 25.6964 - val_loss: 7.5920\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 24.9342 - val_loss: 7.2945\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 477ms/step - loss: 3505.7714 - val_loss: 8.0699\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.5269 - val_loss: 7.7811\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.5882 - val_loss: 7.6774\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5493 - val_loss: 7.8100\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5088 - val_loss: 7.9147\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.5242 - val_loss: 7.7062\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 28.5000 - val_loss: 8.0224\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 936.8165 - val_loss: 69.2078\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 840.3098 - val_loss: 66.3408\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 812.5744 - val_loss: 64.1919\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 750.5040 - val_loss: 57.6721\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 684.7164 - val_loss: 57.7546\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 633.6837 - val_loss: 52.6762\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 609.1936 - val_loss: 52.0405\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1117.1288 - val_loss: 68.6342\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 811.6231 - val_loss: 60.0059\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 669.4758 - val_loss: 53.9698\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 623.0870 - val_loss: 50.4063\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 535.0057 - val_loss: 46.8695\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 480.8768 - val_loss: 43.7073\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 421.7453 - val_loss: 39.8508\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 506ms/step - loss: 525.1967 - val_loss: 8.2428\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 29.0914 - val_loss: 7.8757\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.3273 - val_loss: 7.8428\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 27.2018 - val_loss: 7.4003\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 26.7911 - val_loss: 7.9840\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 25.3597 - val_loss: 7.2581\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 23.3926 - val_loss: 6.6982\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 2407.7716 - val_loss: 7.6595\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.8420 - val_loss: 7.8811\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.5206 - val_loss: 7.5379\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.2718 - val_loss: 7.9418\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 27.8267 - val_loss: 7.6264\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 27.6239 - val_loss: 7.5822\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 26.9731 - val_loss: 7.6910\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1065.8128 - val_loss: 81.9004\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 763.4454 - val_loss: 74.4320\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 663.8069 - val_loss: 71.6596\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 622.7336 - val_loss: 58.5010\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 571.7561 - val_loss: 56.2901\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 448.8806 - val_loss: 51.8848\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 389.8046 - val_loss: 45.0486\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1089.6542 - val_loss: 7.6068\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.5065 - val_loss: 7.5410\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 28.4520 - val_loss: 7.5184\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.4635 - val_loss: 8.0557\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.4672 - val_loss: 8.0669\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.4763 - val_loss: 7.8331\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.2569 - val_loss: 8.0182\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 776.7686 - val_loss: 50.8619\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 331.0917 - val_loss: 30.5714\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 172.6703 - val_loss: 19.8062\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 105.5574 - val_loss: 15.1254\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 73.6721 - val_loss: 12.9146\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 59.1585 - val_loss: 11.1953\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 46.8290 - val_loss: 10.0072\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 687.7190 - val_loss: 7.9043\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 29.6006 - val_loss: 7.7320\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.0188 - val_loss: 8.0018\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 27.4781 - val_loss: 7.5860\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 26.2665 - val_loss: 7.8885\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 24.8332 - val_loss: 7.1936\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 23.0532 - val_loss: 7.0349\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 550.4226 - val_loss: 19.5497\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 62.0735 - val_loss: 8.6475\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 35.8213 - val_loss: 7.9085\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.0478 - val_loss: 7.5568\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 25.9527 - val_loss: 7.2186\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 24.3942 - val_loss: 7.1962\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 353ms/step - loss: 21.6645 - val_loss: 6.9496\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 494.7003 - val_loss: 10.8596\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 31.0095 - val_loss: 8.2060\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 27.6039 - val_loss: 7.5435\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 26.9918 - val_loss: 7.2144\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 25.5652 - val_loss: 7.4062\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 23.1124 - val_loss: 7.1701\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 21.0831 - val_loss: 6.7450\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1091.6282 - val_loss: 8.2344\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.6181 - val_loss: 7.8548\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.4399 - val_loss: 7.9539\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.3755 - val_loss: 7.3879\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.0640 - val_loss: 7.9140\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 27.0823 - val_loss: 8.1526\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 23.4883 - val_loss: 6.5112\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 1081.6259 - val_loss: 85.3205\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 934.4717 - val_loss: 73.2336\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 847.8346 - val_loss: 67.1171\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 793.9951 - val_loss: 65.1716\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 697.0713 - val_loss: 57.8229\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 692.9102 - val_loss: 57.4747\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 644.5416 - val_loss: 59.8305\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 1061.5746 - val_loss: 140.2933\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 1026.0008 - val_loss: 114.2462\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 937.4955 - val_loss: 101.1416\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 898.9472 - val_loss: 92.1587\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 816.7390 - val_loss: 86.4825\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 827.8995 - val_loss: 80.9970\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 771.2695 - val_loss: 74.9175\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 779.2621 - val_loss: 56.7900\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 397.1644 - val_loss: 45.8552\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 225.3183 - val_loss: 23.5313\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 136.2601 - val_loss: 18.2095\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 90.2520 - val_loss: 15.0374\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 69.2811 - val_loss: 12.1473\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 56.9121 - val_loss: 10.9302\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 597.1827 - val_loss: 39.0043\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 110.6118 - val_loss: 14.1066\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 46.2299 - val_loss: 9.6627\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 33.1621 - val_loss: 8.6899\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 27.2555 - val_loss: 8.0306\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 24.6741 - val_loss: 7.8954\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 23.6135 - val_loss: 7.3515\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 475ms/step - loss: 1575.1131 - val_loss: 8.5301\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 28.8450 - val_loss: 7.8991\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.4686 - val_loss: 7.9302\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.3675 - val_loss: 7.6817\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 27.8814 - val_loss: 7.8903\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 27.5164 - val_loss: 7.8465\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 27.2541 - val_loss: 7.5562\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 909.3126 - val_loss: 63.5306\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 815.0133 - val_loss: 59.9236\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 748.8073 - val_loss: 54.8596\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 684.4809 - val_loss: 48.8052\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 663.4469 - val_loss: 47.9878\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 583.5540 - val_loss: 44.5546\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 571.8082 - val_loss: 44.9106\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 1036.6968 - val_loss: 77.4555\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 879.3080 - val_loss: 69.4910\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 809.9282 - val_loss: 59.7428\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 735.4251 - val_loss: 55.7800\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 708.1521 - val_loss: 55.9419\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 655.4805 - val_loss: 55.1826\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 611.5217 - val_loss: 50.9029\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 493.7952 - val_loss: 25.1428\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 59.4195 - val_loss: 8.2852\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 33.2054 - val_loss: 7.6849\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.4087 - val_loss: 6.8694\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 25.0181 - val_loss: 6.4850\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 21.6262 - val_loss: 5.9233\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 20.5872 - val_loss: 5.5389\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1442.5417 - val_loss: 122.0139\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 944.7080 - val_loss: 81.5129\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 863.9640 - val_loss: 73.3767\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 857.6526 - val_loss: 72.1657\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 811.8350 - val_loss: 68.3415\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 799.7120 - val_loss: 69.8936\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 727.8255 - val_loss: 66.4141\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 416.2099 - val_loss: 8.2125\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 28.5645 - val_loss: 7.3652\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 359ms/step - loss: 27.8637 - val_loss: 7.9439\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 27.6606 - val_loss: 7.4131\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 26.6663 - val_loss: 7.3316\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 25.4728 - val_loss: 6.8478\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 22.8240 - val_loss: 6.0263\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 840.9485 - val_loss: 56.7186\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 433.5326 - val_loss: 37.3087\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 288.1630 - val_loss: 32.3374\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 167.1849 - val_loss: 22.0946\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 113.9349 - val_loss: 18.1460\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 86.9370 - val_loss: 15.5491\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 74.1288 - val_loss: 13.1195\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 4999.3423 - val_loss: 7.8532\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.8576 - val_loss: 7.7059\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.9415 - val_loss: 7.9639\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.7472 - val_loss: 7.8972\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 28.7241 - val_loss: 7.7229\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.6548 - val_loss: 7.8276\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.6451 - val_loss: 7.9038\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 1265.8939 - val_loss: 171.0004\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1148.1494 - val_loss: 146.7766\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1206.4548 - val_loss: 132.4688\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 1096.7824 - val_loss: 114.3992\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 1165.9063 - val_loss: 111.5389\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1101.3872 - val_loss: 106.7668\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 1043.8057 - val_loss: 103.2577\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 746.5573 - val_loss: 56.7158\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 272.2037 - val_loss: 23.1485\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 123.9768 - val_loss: 14.7773\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 85.7887 - val_loss: 11.4989\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 60.1470 - val_loss: 9.6449\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 44.5325 - val_loss: 9.1356\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 36.6722 - val_loss: 8.3684\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 1228.6646 - val_loss: 8.2329\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 386ms/step - loss: 28.6692 - val_loss: 7.6777\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 28.6128 - val_loss: 7.4989\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5319 - val_loss: 7.8199\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.5205 - val_loss: 7.9096\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 28.3765 - val_loss: 8.0051\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.2537 - val_loss: 8.0144\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 742.7198 - val_loss: 75.6141\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 335.1782 - val_loss: 46.7723\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 192.2938 - val_loss: 24.3805\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 106.5586 - val_loss: 18.0609\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 79.7046 - val_loss: 13.9043\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 60.4326 - val_loss: 11.3808\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 50.2366 - val_loss: 9.9869\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 548.0995 - val_loss: 9.5514\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 32.8378 - val_loss: 7.9609\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 29.4241 - val_loss: 7.6815\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 27.5742 - val_loss: 8.0557\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 26.2697 - val_loss: 7.8705\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 25.6918 - val_loss: 7.5333\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 24.4058 - val_loss: 7.1553\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 908.0823 - val_loss: 80.8785\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 811.1088 - val_loss: 74.0543\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 703.6263 - val_loss: 64.5882\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 669.3490 - val_loss: 56.5023\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 597.7609 - val_loss: 53.2647\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 524.6679 - val_loss: 50.2417\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 459.1663 - val_loss: 45.3517\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 2352.0519 - val_loss: 7.7685\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.6658 - val_loss: 7.8663\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.4206 - val_loss: 7.8886\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 28.5481 - val_loss: 7.7949\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.3937 - val_loss: 7.8442\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 27.9485 - val_loss: 7.4730\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 26.7677 - val_loss: 7.1137\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 6086.9945 - val_loss: 8.1151\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.7961 - val_loss: 7.9207\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.7247 - val_loss: 7.9015\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.6385 - val_loss: 8.0734\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.5477 - val_loss: 8.0436\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.5104 - val_loss: 8.0220\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.7217 - val_loss: 7.7465\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 472.9718 - val_loss: 17.5877\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 48.0132 - val_loss: 9.2899\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 30.5022 - val_loss: 8.3745\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 27.3503 - val_loss: 8.0754\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 25.0603 - val_loss: 7.7561\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 363ms/step - loss: 23.7925 - val_loss: 7.4722\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 22.3456 - val_loss: 7.1776\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 978.0291 - val_loss: 66.0159\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 805.3998 - val_loss: 58.1877\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 620.2101 - val_loss: 48.4485\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 506.6393 - val_loss: 44.7300\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 453.4227 - val_loss: 37.4638\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 355.7781 - val_loss: 33.3718\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 303.8234 - val_loss: 30.9504\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 1193.5402 - val_loss: 135.3203\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1057.2442 - val_loss: 109.4530\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 965.4153 - val_loss: 103.2961\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 889.2370 - val_loss: 101.6490\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 984.8041 - val_loss: 88.6074\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 832.2073 - val_loss: 87.4156\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 863.2915 - val_loss: 87.4051\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 1131.0686 - val_loss: 111.2197\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1126.5120 - val_loss: 98.9288\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1121.1578 - val_loss: 92.2868\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1012.6480 - val_loss: 90.4912\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 980.3573 - val_loss: 83.4207\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 927.2905 - val_loss: 78.6164\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 897.5602 - val_loss: 78.0560\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 19722.9110 - val_loss: 9.7550\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 29.5689 - val_loss: 8.0212\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 29.3466 - val_loss: 7.8045\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 29.1822 - val_loss: 8.0306\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 29.0307 - val_loss: 7.9507\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 29.0070 - val_loss: 8.1146\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.7532 - val_loss: 7.9763\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 475ms/step - loss: 1958.1435 - val_loss: 312.8490\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1471.5677 - val_loss: 193.7165\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 1385.1608 - val_loss: 148.0156\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1162.7170 - val_loss: 123.5624\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1079.3183 - val_loss: 113.8349\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 1060.5919 - val_loss: 100.4938\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1003.8235 - val_loss: 95.4770\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1001.4341 - val_loss: 73.8030\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 552.0320 - val_loss: 72.5977\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 356.7612 - val_loss: 34.7722\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 221.7808 - val_loss: 29.0421\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 168.3317 - val_loss: 20.5652\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 121.9366 - val_loss: 17.1718\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 98.5223 - val_loss: 14.0908\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 725.0162 - val_loss: 46.1301\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 282.0473 - val_loss: 23.8319\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 131.9154 - val_loss: 14.9161\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 83.5171 - val_loss: 11.6831\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 53.4134 - val_loss: 10.2508\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 43.7491 - val_loss: 9.6227\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 37.3094 - val_loss: 8.6932\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 847.7623 - val_loss: 75.3339\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 479.9762 - val_loss: 46.5372\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 286.9198 - val_loss: 28.9909\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 170.3867 - val_loss: 18.3667\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 119.8628 - val_loss: 15.5745\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 87.0142 - val_loss: 13.7788\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 68.2691 - val_loss: 11.6667\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 8735.4759 - val_loss: 9.4129\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 29.3086 - val_loss: 8.0217\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 29.1153 - val_loss: 8.0258\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.9405 - val_loss: 7.9536\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.8311 - val_loss: 7.8268\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.7367 - val_loss: 7.5210\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.6252 - val_loss: 7.9275\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1099.8094 - val_loss: 130.0389\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 1009.6611 - val_loss: 117.4828\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 896.6409 - val_loss: 114.9336\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 879.2162 - val_loss: 103.0479\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 911.4595 - val_loss: 104.7405\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 909.9530 - val_loss: 97.8929\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 848.8475 - val_loss: 97.7496\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 900.0681 - val_loss: 78.8921\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 850.0293 - val_loss: 72.5958\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 815.9038 - val_loss: 70.4676\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 778.1178 - val_loss: 70.1571\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 763.4907 - val_loss: 64.8896\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 723.3848 - val_loss: 59.8752\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 678.6842 - val_loss: 58.9443\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 19s 487ms/step - loss: 1159.1315 - val_loss: 7.5753\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5761 - val_loss: 7.7450\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.3486 - val_loss: 7.7490\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 28.3578 - val_loss: 7.7754\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.2148 - val_loss: 7.8501\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 27.5073 - val_loss: 7.8827\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 26.9389 - val_loss: 7.8634\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 661.3812 - val_loss: 7.9422\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.9661 - val_loss: 7.9383\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.0160 - val_loss: 7.6335\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 25.7408 - val_loss: 6.5524\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 23.2279 - val_loss: 6.0378\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 21.1980 - val_loss: 5.4315\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 20.0975 - val_loss: 5.3139\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 469.1555 - val_loss: 12.4470\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 36.4343 - val_loss: 8.7414\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.2396 - val_loss: 7.9565\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 26.8853 - val_loss: 7.1354\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 25.3310 - val_loss: 7.2035\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 22.3891 - val_loss: 6.8306\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 20.6956 - val_loss: 6.5886\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1847.0910 - val_loss: 8.6394\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5953 - val_loss: 8.1099\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.5551 - val_loss: 7.9582\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.6094 - val_loss: 7.8879\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 28.4830 - val_loss: 7.9948\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.5188 - val_loss: 7.8641\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5699 - val_loss: 7.7769\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 1011.2551 - val_loss: 84.9229\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 888.9528 - val_loss: 80.6071\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 805.7590 - val_loss: 71.7637\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 766.1003 - val_loss: 67.8984\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 733.4224 - val_loss: 66.9061\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 677.7526 - val_loss: 67.1575\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 668.9665 - val_loss: 62.4639\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 855.4740 - val_loss: 71.5851\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 477.6110 - val_loss: 56.7162\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 324.9935 - val_loss: 37.7907\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 212.3642 - val_loss: 29.1381\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 143.7070 - val_loss: 20.7965\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 113.9529 - val_loss: 18.8872\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 84.7745 - val_loss: 14.5594\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 523.7424 - val_loss: 8.2849\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 29.2185 - val_loss: 7.6522\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 27.9035 - val_loss: 7.1991\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 26.1325 - val_loss: 6.9805\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 25.1300 - val_loss: 6.4837\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 22.1335 - val_loss: 5.7222\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 20.4672 - val_loss: 5.1426\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 1167.0736 - val_loss: 110.6499\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1066.1696 - val_loss: 103.1625\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 991.9589 - val_loss: 94.7863\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 971.5060 - val_loss: 92.8137\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 931.7804 - val_loss: 90.6664\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 971.0108 - val_loss: 84.3923\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 929.9771 - val_loss: 83.4448\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 1055.1521 - val_loss: 102.5882\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 925.8060 - val_loss: 73.9146\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 744.4163 - val_loss: 72.4210\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 640.2233 - val_loss: 56.9206\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 599.0627 - val_loss: 51.4883\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 538.3364 - val_loss: 45.0543\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 489.4972 - val_loss: 43.4477\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 473ms/step - loss: 1231.3115 - val_loss: 106.6349\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1047.0418 - val_loss: 91.7335\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 953.7207 - val_loss: 84.4736\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 942.5422 - val_loss: 75.1296\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 841.9974 - val_loss: 76.3278\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 877.5785 - val_loss: 71.7511\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 814.4769 - val_loss: 65.2009\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 9403.0880 - val_loss: 7.8569\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 29.1658 - val_loss: 7.7737\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.9923 - val_loss: 8.1687\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.8160 - val_loss: 7.5136\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.7277 - val_loss: 8.0040\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 28.7078 - val_loss: 7.9286\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.6541 - val_loss: 7.8817\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 1051.1967 - val_loss: 89.3597\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 947.1889 - val_loss: 83.9482\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 936.0242 - val_loss: 77.5611\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 365ms/step - loss: 883.7413 - val_loss: 72.2141\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 934.7149 - val_loss: 69.5203\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 925.3093 - val_loss: 66.5614\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 903.5500 - val_loss: 68.0870\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 404.0321 - val_loss: 8.3167\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.3826 - val_loss: 7.9876\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 27.8301 - val_loss: 8.1390\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 27.4153 - val_loss: 7.8043\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 25.6346 - val_loss: 7.4969\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 23.9410 - val_loss: 7.2405\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 21.6344 - val_loss: 6.0947\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 588.3889 - val_loss: 51.6175\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 128.2941 - val_loss: 13.3010\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 51.3135 - val_loss: 9.6104\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 39.6371 - val_loss: 7.9038\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 30.4452 - val_loss: 7.6324\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 26.3830 - val_loss: 6.7674\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 23.7464 - val_loss: 6.5362\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 489ms/step - loss: 1285.2747 - val_loss: 102.8808\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 825.1575 - val_loss: 92.1770\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 752.0440 - val_loss: 77.9421\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 673.1320 - val_loss: 73.3857\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 614.5061 - val_loss: 66.6777\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 518.1494 - val_loss: 58.7186\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 466.1413 - val_loss: 51.4575\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 424.4042 - val_loss: 9.6055\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 31.4772 - val_loss: 7.8179\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 27.0239 - val_loss: 7.4689\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 24.3786 - val_loss: 6.3974\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 21.2360 - val_loss: 5.7649\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 16.8128 - val_loss: 5.6187\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 16.3057 - val_loss: 4.3790\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 904.9353 - val_loss: 7.7055\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 28.4521 - val_loss: 8.0815\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.6145 - val_loss: 7.8294\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.3408 - val_loss: 7.4518\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.5978 - val_loss: 7.6628\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.4855 - val_loss: 7.7075\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.4739 - val_loss: 7.7907\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 470.1773 - val_loss: 14.1606\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 34.0452 - val_loss: 8.3823\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 29.4033 - val_loss: 8.0828\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 26.9972 - val_loss: 7.0888\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 25.0776 - val_loss: 6.9047\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 22.3309 - val_loss: 6.1094\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 19.5788 - val_loss: 5.7252\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1136.5698 - val_loss: 93.7635\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 974.3451 - val_loss: 73.3376\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 993.2546 - val_loss: 68.7140\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 908.3508 - val_loss: 62.6561\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 890.1636 - val_loss: 63.6735\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 868.5268 - val_loss: 60.1319\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 885.7855 - val_loss: 61.6188\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 812.0659 - val_loss: 7.9772\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.4199 - val_loss: 7.7548\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.5816 - val_loss: 7.3712\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 28.2867 - val_loss: 7.5804\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.5640 - val_loss: 7.5475\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.5014 - val_loss: 7.5916\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.2917 - val_loss: 8.1419\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 954.4950 - val_loss: 85.5937\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 876.1491 - val_loss: 88.3237\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 827.8304 - val_loss: 80.6595\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 844.7243 - val_loss: 72.7242\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 807.7334 - val_loss: 76.2089\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 736.5985 - val_loss: 72.4924\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 720.9675 - val_loss: 68.6394\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 510.2573 - val_loss: 36.3535\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 72.3378 - val_loss: 10.3305\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 35.2063 - val_loss: 8.8214\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.5945 - val_loss: 8.0048\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 25.3842 - val_loss: 7.8794\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 23.9358 - val_loss: 7.2917\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 20.3741 - val_loss: 6.9873\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 1099.7407 - val_loss: 98.7720\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 980.5298 - val_loss: 84.3169\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 901.4280 - val_loss: 79.8263\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 831.5159 - val_loss: 74.1881\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 760.5433 - val_loss: 70.5141\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 746.4857 - val_loss: 66.3446\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 346ms/step - loss: 720.3796 - val_loss: 67.7495\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 923.9711 - val_loss: 67.1343\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 666.5619 - val_loss: 57.4678\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 483.2359 - val_loss: 48.1817\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 363.5350 - val_loss: 37.0165\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 273.6852 - val_loss: 30.6220\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 214.7320 - val_loss: 25.8714\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 175.5454 - val_loss: 20.7560\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 506ms/step - loss: 678.3404 - val_loss: 42.3570\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 112.2435 - val_loss: 11.4474\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 48.4964 - val_loss: 9.0482\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 37.1686 - val_loss: 8.0740\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 30.6667 - val_loss: 8.0929\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 27.0493 - val_loss: 7.2441\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 23.6548 - val_loss: 6.8024\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 671.1218 - val_loss: 45.7433\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 124.8885 - val_loss: 14.2039\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 52.9460 - val_loss: 9.0046\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 34.5689 - val_loss: 8.3495\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 28.8167 - val_loss: 7.7004\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 25.1341 - val_loss: 7.2310\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 23.4862 - val_loss: 6.4954\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 539.2334 - val_loss: 26.1527\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 70.8563 - val_loss: 9.6529\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 36.5761 - val_loss: 8.4228\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.6095 - val_loss: 7.8632\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 23.9936 - val_loss: 7.4408\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 22.4937 - val_loss: 6.6510\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 20.0415 - val_loss: 6.6991\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1026.6543 - val_loss: 103.5282\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 952.8776 - val_loss: 86.0841\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 930.5112 - val_loss: 81.1124\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 926.6433 - val_loss: 75.6248\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 848.4962 - val_loss: 73.6655\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 865.4363 - val_loss: 68.9731\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 799.2227 - val_loss: 66.5226\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 1064.5211 - val_loss: 8.2518\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.5998 - val_loss: 7.5328\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.5082 - val_loss: 7.9112\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.4603 - val_loss: 7.8435\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.4574 - val_loss: 7.9731\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 28.2872 - val_loss: 7.8791\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 27.9125 - val_loss: 7.8566\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 1750.8272 - val_loss: 7.6645\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.5698 - val_loss: 7.8212\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 28.3317 - val_loss: 7.8831\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.6055 - val_loss: 7.8777\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 27.9705 - val_loss: 7.4382\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.0412 - val_loss: 7.3409\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.0484 - val_loss: 7.6816\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 494ms/step - loss: 1084.6394 - val_loss: 105.4320\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 930.7401 - val_loss: 89.5192\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 872.2870 - val_loss: 78.1409\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 795.1776 - val_loss: 70.0130\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 739.8728 - val_loss: 65.5735\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 732.2486 - val_loss: 63.5891\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 629.3531 - val_loss: 57.4551\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 1204.9195 - val_loss: 92.8616\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 834.8025 - val_loss: 78.1061\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 874.6129 - val_loss: 67.9631\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 784.4120 - val_loss: 65.9630\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 664.8788 - val_loss: 61.2098\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 630.4976 - val_loss: 59.0933\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 602.0952 - val_loss: 58.7538\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 11159.4203 - val_loss: 8.0968\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 29.5763 - val_loss: 7.9530\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 29.2962 - val_loss: 7.9136\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.9963 - val_loss: 7.5146\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.8462 - val_loss: 7.9127\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.7789 - val_loss: 7.8278\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 28.7151 - val_loss: 7.8050\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 977.3767 - val_loss: 78.6770\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 722.6734 - val_loss: 68.6653\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 608.2402 - val_loss: 59.2093\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 506.4434 - val_loss: 49.7906\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 428.9788 - val_loss: 49.4179\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 406.6560 - val_loss: 41.2848\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 325.9116 - val_loss: 37.8622\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 687.9743 - val_loss: 51.5391\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 331.9813 - val_loss: 29.2276\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 363ms/step - loss: 170.6780 - val_loss: 20.7780\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 102.4302 - val_loss: 13.4782\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 66.3572 - val_loss: 11.5930\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 56.0938 - val_loss: 10.4345\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 46.0366 - val_loss: 9.8629\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 942.3576 - val_loss: 80.2696\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 703.8312 - val_loss: 74.0628\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 608.2992 - val_loss: 57.7551\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 499.6534 - val_loss: 48.1425\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 405.1647 - val_loss: 40.5838\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 374.3041 - val_loss: 39.9840\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 307.9908 - val_loss: 37.1001\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 1018.8321 - val_loss: 80.3314\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 674.8859 - val_loss: 69.8052\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 549.4106 - val_loss: 52.7845\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 473.4828 - val_loss: 49.6288\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 372.0807 - val_loss: 40.8576\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 314.3442 - val_loss: 41.8997\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 245.7085 - val_loss: 33.1354\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 511.7551 - val_loss: 21.0967\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 67.7362 - val_loss: 10.0639\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 35.2168 - val_loss: 7.7287\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.4865 - val_loss: 7.7150\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 25.8381 - val_loss: 7.3926\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 22.3040 - val_loss: 6.8866\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 20.7102 - val_loss: 6.6068\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 613.7405 - val_loss: 42.5127\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 184.9523 - val_loss: 16.8281\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 77.1734 - val_loss: 11.2217\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 49.2905 - val_loss: 8.6259\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 35.8445 - val_loss: 8.1429\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 32.8894 - val_loss: 7.7798\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 26.2362 - val_loss: 7.4143\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 586.5988 - val_loss: 35.7430\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 176.2050 - val_loss: 19.9682\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 74.8870 - val_loss: 13.9553\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 50.0747 - val_loss: 10.2902\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 36.0119 - val_loss: 9.7827\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 32.3897 - val_loss: 8.4222\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 27.0374 - val_loss: 7.8477\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 555.6747 - val_loss: 27.1054\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 95.3621 - val_loss: 10.8220\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 40.3982 - val_loss: 8.4185\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 32.9201 - val_loss: 7.7121\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.6180 - val_loss: 7.5142\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 26.1011 - val_loss: 7.3704\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 25.2071 - val_loss: 6.9415\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 1056.9535 - val_loss: 66.3416\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 765.5893 - val_loss: 56.4798\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 602.4340 - val_loss: 52.5295\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 502.3579 - val_loss: 43.0214\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 431.0392 - val_loss: 37.9719\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 387.2454 - val_loss: 35.5907\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 331.6419 - val_loss: 30.3573\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 485ms/step - loss: 2356.7803 - val_loss: 435.1419\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 1790.0158 - val_loss: 303.9106\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 1418.4702 - val_loss: 225.8279\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1186.3961 - val_loss: 169.4093\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1164.2005 - val_loss: 146.4252\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1041.2915 - val_loss: 126.5854\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 969.1398 - val_loss: 111.6911\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 475ms/step - loss: 712.5026 - val_loss: 8.2225\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 29.1059 - val_loss: 7.7969\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.0004 - val_loss: 7.7154\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 26.5223 - val_loss: 7.6271\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 25.2196 - val_loss: 7.1401\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 22.4059 - val_loss: 6.5793\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 20.6674 - val_loss: 6.6962\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 481ms/step - loss: 2684.1151 - val_loss: 8.0865\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.7618 - val_loss: 7.6285\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.6927 - val_loss: 7.7019\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.6291 - val_loss: 7.8528\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 28.5938 - val_loss: 7.9113\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.5528 - val_loss: 7.9726\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.5771 - val_loss: 7.9266\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 864.8876 - val_loss: 65.4963\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 675.7906 - val_loss: 51.6793\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 533.5298 - val_loss: 46.6086\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 440.9119 - val_loss: 39.9084\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 372.0475 - val_loss: 34.0954\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 339ms/step - loss: 304.4858 - val_loss: 32.6568\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 241.7371 - val_loss: 27.3008\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 476ms/step - loss: 969.3677 - val_loss: 63.5891\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 539.5179 - val_loss: 59.3940\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 391.0004 - val_loss: 41.4167\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 315.7123 - val_loss: 38.4154\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 219.4546 - val_loss: 27.9289\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 171.9448 - val_loss: 22.3931\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 132.3986 - val_loss: 18.5401\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 1249.8403 - val_loss: 115.9083\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1108.0759 - val_loss: 101.6459\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1063.8134 - val_loss: 95.4461\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1034.8089 - val_loss: 92.6815\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 1027.7977 - val_loss: 86.4867\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 1030.7869 - val_loss: 86.0729\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 908.9911 - val_loss: 78.8229\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 472ms/step - loss: 7643.9499 - val_loss: 8.0990\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 29.0279 - val_loss: 8.0521\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.9278 - val_loss: 7.8674\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.7794 - val_loss: 7.9696\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.7306 - val_loss: 7.8308\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.6505 - val_loss: 7.9043\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.6135 - val_loss: 7.7406\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 1077.5363 - val_loss: 84.0003\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 896.2640 - val_loss: 83.1139\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 872.7860 - val_loss: 79.3156\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 816.2382 - val_loss: 71.2285\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 789.7992 - val_loss: 70.2404\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 734.2763 - val_loss: 69.4607\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 705.3040 - val_loss: 62.7668\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 2403.1895 - val_loss: 8.0075\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.7059 - val_loss: 7.8309\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 28.5779 - val_loss: 7.9155\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 28.6269 - val_loss: 7.8929\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.5617 - val_loss: 7.4872\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.4916 - val_loss: 8.0638\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 28.5371 - val_loss: 7.8121\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 475ms/step - loss: 566.4976 - val_loss: 8.0280\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 29.4819 - val_loss: 8.0775\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.2991 - val_loss: 7.6663\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 27.4248 - val_loss: 7.5173\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 25.6728 - val_loss: 7.0452\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 23.0943 - val_loss: 6.3177\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 20.7853 - val_loss: 5.4833\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 447.2196 - val_loss: 11.8963\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 36.0278 - val_loss: 8.0417\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 28.7936 - val_loss: 7.5680\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 26.0265 - val_loss: 7.7357\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 23.3260 - val_loss: 7.0236\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 22.7722 - val_loss: 7.0964\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 20.6902 - val_loss: 6.6747\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 472ms/step - loss: 2681.4778 - val_loss: 7.9046\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.7417 - val_loss: 7.9172\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.3594 - val_loss: 7.6104\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.3789 - val_loss: 7.8684\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.4337 - val_loss: 7.5901\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.3487 - val_loss: 7.7098\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 27.9705 - val_loss: 7.6009\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 468ms/step - loss: 474.5541 - val_loss: 8.7282\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 29.9910 - val_loss: 7.7631\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 27.1693 - val_loss: 7.8554\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 26.6989 - val_loss: 7.3891\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 24.3608 - val_loss: 7.4187\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 22.7523 - val_loss: 6.8712\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 20.2682 - val_loss: 6.6694\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 1254.2433 - val_loss: 108.8943\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1081.1552 - val_loss: 92.5684\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 992.7486 - val_loss: 83.5892\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 984.9582 - val_loss: 78.9351\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 903.3064 - val_loss: 67.4003\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 874.8583 - val_loss: 68.4856\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 786.3021 - val_loss: 65.7519\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 464ms/step - loss: 492.1399 - val_loss: 24.8229\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 63.4982 - val_loss: 9.0716\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 32.7718 - val_loss: 7.7587\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 26.9725 - val_loss: 6.9524\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 22.8236 - val_loss: 6.4791\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 19.9344 - val_loss: 5.4092\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 17.7284 - val_loss: 5.2149\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 1877.7212 - val_loss: 7.7454\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 342ms/step - loss: 28.5866 - val_loss: 7.7848\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.5560 - val_loss: 7.9758\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 28.5236 - val_loss: 7.6814\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.5250 - val_loss: 7.7132\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 28.5649 - val_loss: 7.7253\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 28.5230 - val_loss: 7.7433\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 1182.9856 - val_loss: 98.5373\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 916.9076 - val_loss: 88.8370\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 879.6897 - val_loss: 82.7549\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 846.5897 - val_loss: 81.5773\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 850.8038 - val_loss: 80.7473\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 737.3689 - val_loss: 77.4729\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 784.2999 - val_loss: 69.8512\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 2083.8826 - val_loss: 367.4625\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1702.8159 - val_loss: 277.6910\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1498.2981 - val_loss: 224.9827\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 1238.1355 - val_loss: 203.3631\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 1173.1300 - val_loss: 181.4327\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1156.4558 - val_loss: 156.2325\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 1062.3169 - val_loss: 141.4082\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 1193.2790 - val_loss: 7.5428\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 28.6085 - val_loss: 7.6466\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5393 - val_loss: 7.5339\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.5724 - val_loss: 7.8834\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.5696 - val_loss: 7.4344\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.4845 - val_loss: 8.0513\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 28.5431 - val_loss: 7.6288\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 1114.2091 - val_loss: 111.8018\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 947.3965 - val_loss: 97.4673\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 899.6224 - val_loss: 87.5515\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 821.9864 - val_loss: 77.0072\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 738.5706 - val_loss: 68.8601\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 646.1797 - val_loss: 67.1906\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 631.6953 - val_loss: 67.1711\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 463ms/step - loss: 454.2839 - val_loss: 8.2689\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.4830 - val_loss: 7.6434\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 27.9460 - val_loss: 7.5821\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 26.4405 - val_loss: 7.3088\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 24.9013 - val_loss: 6.7623\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 21.3919 - val_loss: 5.9124\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 19.0872 - val_loss: 4.8736\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 951.1411 - val_loss: 77.8608\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 553.5248 - val_loss: 49.1133\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 364.3316 - val_loss: 36.6259\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 281.1774 - val_loss: 29.7122\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 209.2805 - val_loss: 23.6384\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 146.9529 - val_loss: 18.7916\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 116.3669 - val_loss: 16.9014\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 1438.0710 - val_loss: 8.0320\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.6396 - val_loss: 8.1020\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.5339 - val_loss: 7.8149\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.5358 - val_loss: 7.7034\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 28.4324 - val_loss: 7.7720\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.4310 - val_loss: 7.7553\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.1870 - val_loss: 7.8311\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 891.7369 - val_loss: 79.1813\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 640.1840 - val_loss: 62.2739\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 423.5326 - val_loss: 47.9757\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 342.6107 - val_loss: 37.3450\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 237.3820 - val_loss: 33.2064\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 200.9047 - val_loss: 25.4276\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 163.0321 - val_loss: 23.0871\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 589.3563 - val_loss: 19.0592\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 41.1219 - val_loss: 8.1357\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 28.6441 - val_loss: 7.4370\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 26.1901 - val_loss: 7.4107\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 25.0775 - val_loss: 6.9351\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 23.1970 - val_loss: 6.9287\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 21.7997 - val_loss: 6.3154\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 464ms/step - loss: 1003.4981 - val_loss: 76.8520\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 877.3459 - val_loss: 64.1971\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 751.9377 - val_loss: 63.2991\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 648.9432 - val_loss: 57.7078\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 664.8451 - val_loss: 55.1994\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 562.6222 - val_loss: 52.2761\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 532.3799 - val_loss: 48.2893\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 459ms/step - loss: 509.1557 - val_loss: 12.9590\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 40.7620 - val_loss: 8.4195\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 28.5032 - val_loss: 8.1450\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 23.9677 - val_loss: 7.7017\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 323ms/step - loss: 21.4184 - val_loss: 6.9388\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 19.8322 - val_loss: 6.5725\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 18.0516 - val_loss: 6.4423\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 607.9028 - val_loss: 27.2578\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 106.0106 - val_loss: 11.2111\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 47.7551 - val_loss: 8.8119\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 35.6453 - val_loss: 8.4339\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 30.6621 - val_loss: 7.9057\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 27.2255 - val_loss: 7.4982\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 24.8165 - val_loss: 6.9693\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 1031.1876 - val_loss: 96.9386\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 922.6348 - val_loss: 87.4956\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 836.8319 - val_loss: 84.9245\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 828.8650 - val_loss: 78.5323\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 803.6170 - val_loss: 75.8231\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 821.8513 - val_loss: 75.8714\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 776.9284 - val_loss: 71.6456\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 1127.4278 - val_loss: 94.9807\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 979.0806 - val_loss: 75.4463\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 861.2671 - val_loss: 68.6573\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 812.3897 - val_loss: 62.5644\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 736.8449 - val_loss: 61.4840\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 700.1927 - val_loss: 55.2453\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 634.1005 - val_loss: 55.0086\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 567.1244 - val_loss: 10.4335\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 28.7251 - val_loss: 7.8465\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 27.1249 - val_loss: 7.6695\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 25.7214 - val_loss: 7.2740\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 23.7494 - val_loss: 7.3839\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 22.3953 - val_loss: 6.6564\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 19.8211 - val_loss: 5.8213\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 1080.1684 - val_loss: 79.0171\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 845.3941 - val_loss: 64.3918\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 759.9810 - val_loss: 56.4744\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 618.5957 - val_loss: 56.9441\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 554.1423 - val_loss: 53.9945\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 536.2923 - val_loss: 45.1888\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 471.4885 - val_loss: 44.0054\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 467ms/step - loss: 1199.2566 - val_loss: 8.0193\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.6073 - val_loss: 7.6591\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 28.5944 - val_loss: 7.8304\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 28.5996 - val_loss: 8.1596\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 28.4892 - val_loss: 7.8945\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 28.5597 - val_loss: 7.7253\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 28.5482 - val_loss: 8.0622\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 995.4041 - val_loss: 63.5257\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 704.1228 - val_loss: 49.5451\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 557.0625 - val_loss: 39.0792\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 471.5602 - val_loss: 37.2323\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 375.3901 - val_loss: 33.5805\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 335.2398 - val_loss: 29.5754\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 274.1109 - val_loss: 25.2225\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 538.0716 - val_loss: 10.3083\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 32.1978 - val_loss: 8.0360\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 29.0422 - val_loss: 7.4824\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 27.4410 - val_loss: 7.6915\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 26.4835 - val_loss: 7.1760\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 24.6082 - val_loss: 7.4944\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 23.2080 - val_loss: 6.4921\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 923.9455 - val_loss: 80.6332\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 730.4416 - val_loss: 62.9821\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 660.1626 - val_loss: 63.0708\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 544.0033 - val_loss: 53.0006\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 478.3478 - val_loss: 45.1373\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 403.3691 - val_loss: 42.5195\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 366.5313 - val_loss: 40.4831\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 455ms/step - loss: 630.5713 - val_loss: 11.0459\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 30.7570 - val_loss: 8.0151\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 28.1134 - val_loss: 7.6318\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 26.8249 - val_loss: 7.7504\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 25.8737 - val_loss: 7.6138\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 25.6490 - val_loss: 7.4347\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 24.1670 - val_loss: 7.5360\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 6167.9672 - val_loss: 7.6496\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 28.7033 - val_loss: 7.7477\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 28.6457 - val_loss: 7.9694\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.6646 - val_loss: 7.9671\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 28.6120 - val_loss: 7.9512\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 28.7069 - val_loss: 7.4754\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.5848 - val_loss: 7.8539\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 18s 452ms/step - loss: 982.8288 - val_loss: 115.5381\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 989.5911 - val_loss: 97.9269\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 986.4697 - val_loss: 94.3415\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 919.9088 - val_loss: 90.6008\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 902.2139 - val_loss: 89.6476\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 882.8723 - val_loss: 84.2159\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 869.7801 - val_loss: 82.9418\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 449ms/step - loss: 442.2428 - val_loss: 9.5720\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 33.1018 - val_loss: 7.7953\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 27.8581 - val_loss: 7.2036\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 25.5743 - val_loss: 6.7862\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 23.7424 - val_loss: 6.4222\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 21.3664 - val_loss: 6.8204\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 20.1212 - val_loss: 5.7618\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 1572.7712 - val_loss: 153.3888\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 1228.0717 - val_loss: 108.1281\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 985.7943 - val_loss: 96.0194\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 1069.2548 - val_loss: 89.8318\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 970.4158 - val_loss: 86.2299\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 982.6125 - val_loss: 80.7293\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 996.3861 - val_loss: 81.6566\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 449ms/step - loss: 532.2732 - val_loss: 8.2948\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 29.1746 - val_loss: 8.0137\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 28.2814 - val_loss: 8.0278\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.2536 - val_loss: 7.8204\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 28.2376 - val_loss: 7.9618\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 27.8978 - val_loss: 8.1722\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 27.6042 - val_loss: 7.6872\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 441ms/step - loss: 1294.6512 - val_loss: 83.4755\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 900.7165 - val_loss: 65.3843\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 811.6631 - val_loss: 63.1015\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 791.4496 - val_loss: 60.3618\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 763.2061 - val_loss: 62.7733\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 748.6884 - val_loss: 56.7269\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 675.4936 - val_loss: 55.0371\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 445ms/step - loss: 1810.6493 - val_loss: 286.7931\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 1420.3256 - val_loss: 195.1292\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 1145.9582 - val_loss: 136.4145\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 1025.2895 - val_loss: 105.4279\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 984.9308 - val_loss: 97.9651\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 864.2183 - val_loss: 90.8888\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 906.7573 - val_loss: 86.6157\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 1086.0268 - val_loss: 91.0056\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 973.7786 - val_loss: 83.2097\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 862.5984 - val_loss: 81.8930\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 802.3092 - val_loss: 74.1046\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 677.7958 - val_loss: 66.9277\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 656.9293 - val_loss: 64.0556\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 579.9952 - val_loss: 62.6634\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 1088.3806 - val_loss: 85.1640\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 917.5582 - val_loss: 73.1936\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 874.4431 - val_loss: 62.6154\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 777.0345 - val_loss: 62.5808\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 726.7112 - val_loss: 58.0970\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 730.4509 - val_loss: 55.2229\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 668.5975 - val_loss: 54.1033\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 463ms/step - loss: 1144.3634 - val_loss: 81.8208\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 850.8027 - val_loss: 67.8593\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 776.4966 - val_loss: 60.1308\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 672.4879 - val_loss: 55.3569\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 605.7019 - val_loss: 51.7409\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 556.0441 - val_loss: 46.4923\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 517.4508 - val_loss: 45.2971\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 546.6755 - val_loss: 8.1924\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 28.9100 - val_loss: 7.6983\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.5087 - val_loss: 7.8549\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 28.1367 - val_loss: 7.9209\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.2020 - val_loss: 7.4365\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 27.5794 - val_loss: 7.9965\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 27.0375 - val_loss: 7.8805\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 737.6812 - val_loss: 46.2210\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 165.5542 - val_loss: 20.3160\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 70.2157 - val_loss: 10.9388\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 41.6824 - val_loss: 8.7569\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 33.7930 - val_loss: 8.1927\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 30.6548 - val_loss: 7.7632\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 27.3828 - val_loss: 7.4728\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 782.8791 - val_loss: 51.9113\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 382.0634 - val_loss: 36.5508\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 228.7438 - val_loss: 23.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 123.1746 - val_loss: 17.4335\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 91.8191 - val_loss: 13.2894\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 71.2424 - val_loss: 10.9918\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 55.6101 - val_loss: 9.3863\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 1207.1632 - val_loss: 7.2900\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 28.5757 - val_loss: 7.8078\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 28.5417 - val_loss: 7.8316\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 28.5431 - val_loss: 8.0803\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.5445 - val_loss: 7.7162\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 28.5476 - val_loss: 7.5511\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 28.5486 - val_loss: 8.0422\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 782.0157 - val_loss: 61.9832\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 475.6754 - val_loss: 45.9754\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 332.6928 - val_loss: 36.4610\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 242.4117 - val_loss: 27.2022\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 168.3031 - val_loss: 24.1801\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 132.7080 - val_loss: 18.1651\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 107.2506 - val_loss: 15.9882\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 441ms/step - loss: 882.8091 - val_loss: 63.7500\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 619.9138 - val_loss: 55.1995\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 460.9449 - val_loss: 40.1883\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 374.3310 - val_loss: 36.6523\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 278.0809 - val_loss: 29.8168\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 234.0684 - val_loss: 25.0623\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 177.1999 - val_loss: 22.5867\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 988.9697 - val_loss: 84.9416\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 816.2961 - val_loss: 73.0984\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 680.7057 - val_loss: 61.3964\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 563.8365 - val_loss: 55.6971\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 306ms/step - loss: 519.5219 - val_loss: 51.6111\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 479.6853 - val_loss: 44.7337\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 387.6466 - val_loss: 40.9760\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 1321.6692 - val_loss: 138.4845\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 1161.0527 - val_loss: 103.9847\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 1085.7441 - val_loss: 98.1587\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 998.3427 - val_loss: 88.4262\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 992.8315 - val_loss: 88.4569\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 936.7475 - val_loss: 85.6494\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 933.8576 - val_loss: 83.3828\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 10443.1161 - val_loss: 8.3241\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 28.8419 - val_loss: 8.0504\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 28.5884 - val_loss: 8.1825\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.6665 - val_loss: 8.0076\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 306ms/step - loss: 28.6095 - val_loss: 7.7286\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 28.5350 - val_loss: 8.1804\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 28.4631 - val_loss: 7.9175\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 460ms/step - loss: 527.3890 - val_loss: 11.5478\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 38.6023 - val_loss: 8.2913\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 28.9238 - val_loss: 8.0954\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 26.6850 - val_loss: 7.5605\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 25.3305 - val_loss: 7.2054\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 22.6715 - val_loss: 7.1687\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 21.7838 - val_loss: 6.8456\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 453ms/step - loss: 859.0640 - val_loss: 63.4244\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 635.5704 - val_loss: 44.3882\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 508.8150 - val_loss: 34.4733\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 387.2245 - val_loss: 33.5310\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 296.7864 - val_loss: 28.0753\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 248.2822 - val_loss: 28.3502\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 208.1188 - val_loss: 20.9310\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 438ms/step - loss: 721.8644 - val_loss: 64.4857\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 309.4516 - val_loss: 25.0434\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 148.9013 - val_loss: 17.6409\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 92.6087 - val_loss: 13.5382\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 65.6857 - val_loss: 10.7917\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 50.3548 - val_loss: 10.3475\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 40.5894 - val_loss: 9.0982\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 461ms/step - loss: 1882.2866 - val_loss: 274.4624\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 1409.8416 - val_loss: 209.9024\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 1214.1857 - val_loss: 172.4040\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 1077.6128 - val_loss: 147.9538\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 1046.0694 - val_loss: 139.9831\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 306ms/step - loss: 1062.9573 - val_loss: 128.6123\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 966.2318 - val_loss: 103.3090\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 541.5143 - val_loss: 30.1569\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 49.3016 - val_loss: 9.1963\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 32.4482 - val_loss: 7.3758\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 27.5387 - val_loss: 7.4731\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 25.6716 - val_loss: 7.0567\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 23.4470 - val_loss: 6.9159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 21.9408 - val_loss: 6.2483\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 893.3753 - val_loss: 88.8564\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 387.5753 - val_loss: 41.0158\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 226.7951 - val_loss: 26.3369\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 142.3413 - val_loss: 20.3258\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 99.5548 - val_loss: 16.0961\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 69.7795 - val_loss: 12.1370\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 56.5924 - val_loss: 11.3272\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 1150.8439 - val_loss: 114.5314\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 995.0900 - val_loss: 100.5027\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 957.6598 - val_loss: 90.7888\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 966.3847 - val_loss: 86.5171\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 865.6601 - val_loss: 81.0762\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 873.2528 - val_loss: 80.5544\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 886.2067 - val_loss: 79.2051\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 1007.0058 - val_loss: 81.4086\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 987.2324 - val_loss: 75.2569\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 923.9779 - val_loss: 72.0398\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 850.9281 - val_loss: 67.8249\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 855.2429 - val_loss: 66.5347\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 789.0114 - val_loss: 59.3197\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 835.8050 - val_loss: 57.5793\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 437ms/step - loss: 826.6913 - val_loss: 62.7660\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 519.3546 - val_loss: 44.2049\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 356.2870 - val_loss: 31.2028\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 241.8270 - val_loss: 27.9802\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 177.6582 - val_loss: 21.6554\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 141.7156 - val_loss: 21.0473\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 107.3221 - val_loss: 15.6997\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 729.8303 - val_loss: 47.1675\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 310.4850 - val_loss: 26.3641\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 165.5682 - val_loss: 18.2130\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 100.8622 - val_loss: 13.4487\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 76.3701 - val_loss: 11.7337\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 56.1181 - val_loss: 10.3652\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 45.5662 - val_loss: 9.5902\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 463ms/step - loss: 1223.3877 - val_loss: 74.2062\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 838.3614 - val_loss: 58.2425\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 661.9024 - val_loss: 46.8228\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 566.2497 - val_loss: 38.5698\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 483.7785 - val_loss: 38.7467\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 406.5702 - val_loss: 33.0677\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 337.1345 - val_loss: 31.5651\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 782.2727 - val_loss: 71.4781\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 618.1078 - val_loss: 55.0304\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 533.0621 - val_loss: 55.0649\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 417.4897 - val_loss: 44.1906\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 379.9325 - val_loss: 40.4001\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 309.2411 - val_loss: 33.9835\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 253.3188 - val_loss: 29.5086\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 1130.4328 - val_loss: 103.5053\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 927.0172 - val_loss: 87.5348\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 849.0564 - val_loss: 81.8346\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 848.6926 - val_loss: 76.9563\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 816.0157 - val_loss: 73.8085\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 772.4282 - val_loss: 74.5382\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 735.0429 - val_loss: 66.3694\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 461ms/step - loss: 788.1746 - val_loss: 63.6399\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 333.0969 - val_loss: 52.9394\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 190.7513 - val_loss: 25.6989\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 115.5042 - val_loss: 18.8407\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 76.1292 - val_loss: 14.3133\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 55.3434 - val_loss: 12.7169\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 49.0491 - val_loss: 11.5434\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 1024.9404 - val_loss: 81.1258\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 734.8797 - val_loss: 58.2139\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 613.0241 - val_loss: 48.0762\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 496.9945 - val_loss: 42.7310\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 446.0476 - val_loss: 36.8632\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 360.8172 - val_loss: 31.7024\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 299.6218 - val_loss: 29.5427\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 455ms/step - loss: 1060.5794 - val_loss: 104.4055\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 966.4019 - val_loss: 84.6201\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 923.9596 - val_loss: 79.8258\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 893.3623 - val_loss: 73.0290\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 901.5836 - val_loss: 70.3866\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 835.0939 - val_loss: 68.7248\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 789.5775 - val_loss: 64.9742\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 463ms/step - loss: 1145.7594 - val_loss: 106.3199\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 339ms/step - loss: 1032.0410 - val_loss: 87.5612\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 989.9604 - val_loss: 89.8894\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 1044.8042 - val_loss: 86.3525\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 1093.2880 - val_loss: 84.4026\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 984.1339 - val_loss: 79.4489\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 1024.0797 - val_loss: 73.6147\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 550.1486 - val_loss: 14.5597\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 39.9483 - val_loss: 7.7658\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 30.0742 - val_loss: 7.5231\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 26.6212 - val_loss: 7.2038\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 24.8941 - val_loss: 7.1094\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 23.4019 - val_loss: 6.9399\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 21.4571 - val_loss: 6.2962\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 445ms/step - loss: 743.0276 - val_loss: 55.1927\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 285.2889 - val_loss: 24.8954\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 135.6800 - val_loss: 17.3368\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 82.2302 - val_loss: 12.5663\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 58.2584 - val_loss: 10.1858\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 46.9291 - val_loss: 9.8179\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 39.7493 - val_loss: 8.8259\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 518.8118 - val_loss: 8.7086\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 30.7350 - val_loss: 7.9704\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 25.8827 - val_loss: 7.1794\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 24.3229 - val_loss: 6.9502\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 21.8041 - val_loss: 6.7128\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 19.2773 - val_loss: 5.6433\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 17.4001 - val_loss: 5.3597\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1061.9289 - val_loss: 117.6375\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 1035.5397 - val_loss: 98.6240\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 1043.4482 - val_loss: 91.7135\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 976.2535 - val_loss: 86.3418\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 974.1925 - val_loss: 82.3163\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 958.8389 - val_loss: 79.1621\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 977.6292 - val_loss: 81.0273\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 1006.5592 - val_loss: 60.9876\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 719.2234 - val_loss: 54.1070\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 594.5132 - val_loss: 49.4652\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 495.6977 - val_loss: 44.6290\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 413.6476 - val_loss: 39.5684\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 342.2282 - val_loss: 35.2369\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 284.5618 - val_loss: 31.8103\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 894.6663 - val_loss: 60.3591\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 616.6804 - val_loss: 46.6954\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 449.8849 - val_loss: 38.9037\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 355.4199 - val_loss: 31.5897\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 279.7036 - val_loss: 25.6571\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 209.2731 - val_loss: 22.1329\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 169.2304 - val_loss: 20.2533\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 455ms/step - loss: 1155.4868 - val_loss: 152.4294\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 1048.1436 - val_loss: 121.3214\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 939.3230 - val_loss: 107.6200\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 902.4735 - val_loss: 97.5972\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 875.9228 - val_loss: 96.4347\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 882.0766 - val_loss: 86.5941\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 304ms/step - loss: 838.0293 - val_loss: 84.4463\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 449ms/step - loss: 1068.5027 - val_loss: 75.0993\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 962.6309 - val_loss: 68.3798\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 881.0423 - val_loss: 64.9709\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 821.2607 - val_loss: 62.8986\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 778.5520 - val_loss: 54.9282\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 775.0862 - val_loss: 57.7640\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 824.1120 - val_loss: 56.4841\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 673.9745 - val_loss: 53.4398\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 242.4695 - val_loss: 20.0880\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 98.4387 - val_loss: 12.8571\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 58.4581 - val_loss: 10.1732\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 45.0980 - val_loss: 8.4690\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 36.5882 - val_loss: 7.8057\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 30.2580 - val_loss: 7.2659\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 1101.5803 - val_loss: 80.0628\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 904.9139 - val_loss: 72.0639\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 780.0591 - val_loss: 65.8786\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 321ms/step - loss: 713.8261 - val_loss: 57.2313\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 644.1868 - val_loss: 53.8373\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 541.2677 - val_loss: 48.2378\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 475.9230 - val_loss: 42.2658\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 1169.6282 - val_loss: 88.7446\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 985.2180 - val_loss: 75.5635\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 866.5399 - val_loss: 71.6256\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 790.5149 - val_loss: 68.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 793.7292 - val_loss: 62.8282\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 758.2231 - val_loss: 60.2286\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 702.6644 - val_loss: 59.5149\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 831.4795 - val_loss: 7.8766\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 28.6479 - val_loss: 7.9624\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 28.7007 - val_loss: 7.9841\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 28.3993 - val_loss: 7.9384\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 28.4756 - val_loss: 8.0200\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 28.2390 - val_loss: 7.9111\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 28.3271 - val_loss: 7.6188\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 974.2396 - val_loss: 90.4210\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 853.5290 - val_loss: 82.0949\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 821.8593 - val_loss: 74.6125\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 801.0481 - val_loss: 68.9004\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 750.6355 - val_loss: 67.3589\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 718.2070 - val_loss: 61.7084\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 633.1711 - val_loss: 60.0053\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 887.3075 - val_loss: 61.9620\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 545.9680 - val_loss: 54.5402\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 400.4300 - val_loss: 39.7131\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 277.0328 - val_loss: 32.7161\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 198.6087 - val_loss: 22.7947\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 143.1083 - val_loss: 19.1801\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 117.0946 - val_loss: 19.4995\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 843.1161 - val_loss: 54.1818\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 476.3963 - val_loss: 39.1979\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 325.7695 - val_loss: 35.8090\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 217.1496 - val_loss: 29.4231\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 150.1825 - val_loss: 21.0240\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 128.6873 - val_loss: 16.3427\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 94.3489 - val_loss: 13.5376\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 449ms/step - loss: 939.4421 - val_loss: 57.5893\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 408.4362 - val_loss: 41.8092\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 223.6353 - val_loss: 22.2296\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 125.4151 - val_loss: 19.9303\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 94.6224 - val_loss: 14.3905\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 68.1334 - val_loss: 11.8202\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 54.3064 - val_loss: 10.7083\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 903.3937 - val_loss: 68.7397\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 610.1240 - val_loss: 52.5029\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 423.9545 - val_loss: 39.1028\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 333.8632 - val_loss: 32.2710\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 236.5144 - val_loss: 25.1930\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 187.1301 - val_loss: 22.3961\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 152.9742 - val_loss: 19.1363\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 1123.6061 - val_loss: 72.3830\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 959.4358 - val_loss: 62.7969\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 870.2093 - val_loss: 57.5245\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 871.9379 - val_loss: 58.8094\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 770.7832 - val_loss: 55.2930\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 765.4334 - val_loss: 49.4463\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 756.0641 - val_loss: 52.2111\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 1160.8935 - val_loss: 96.0583\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 867.1238 - val_loss: 79.9789\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 821.0538 - val_loss: 71.4835\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 823.5031 - val_loss: 66.5231\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 751.5677 - val_loss: 62.4410\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 689.8604 - val_loss: 57.3470\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 663.3941 - val_loss: 50.0383\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 971.7699 - val_loss: 8.0820\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.6709 - val_loss: 8.0013\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 28.5548 - val_loss: 7.8817\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.4897 - val_loss: 7.6631\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.1919 - val_loss: 8.0221\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 28.4711 - val_loss: 8.0527\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 28.4102 - val_loss: 7.8322\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 431.5970 - val_loss: 10.6400\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 31.9876 - val_loss: 8.1716\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 27.2206 - val_loss: 7.4634\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 25.3236 - val_loss: 7.2533\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 22.3183 - val_loss: 6.5165\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 19.7599 - val_loss: 5.6039\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 17.7736 - val_loss: 5.2292\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 910.8576 - val_loss: 66.8743\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 720.9533 - val_loss: 54.1480\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 587.9574 - val_loss: 47.9218\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 479.3446 - val_loss: 39.0445\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 373.0574 - val_loss: 33.7561\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 327.8866 - val_loss: 29.9735\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 245.1759 - val_loss: 28.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 856.8612 - val_loss: 59.0983\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 563.5426 - val_loss: 48.9777\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 435.6415 - val_loss: 40.6492\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 296.1282 - val_loss: 33.6773\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 254.2840 - val_loss: 29.6426\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 200.5539 - val_loss: 26.1529\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 164.7854 - val_loss: 22.1831\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1057.6377 - val_loss: 126.3876\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 980.1041 - val_loss: 102.1294\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 940.3832 - val_loss: 88.2905\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 895.6376 - val_loss: 80.2507\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 845.2846 - val_loss: 72.6693\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 746.1431 - val_loss: 66.8666\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 768.0590 - val_loss: 66.3001\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 1065.4477 - val_loss: 132.6974\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 971.6530 - val_loss: 117.7905\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 961.8893 - val_loss: 100.2398\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 928.9521 - val_loss: 102.5811\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 883.0818 - val_loss: 96.3403\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 863.3190 - val_loss: 86.7066\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 854.6094 - val_loss: 88.3839\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 910.8042 - val_loss: 67.8629\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 631.4395 - val_loss: 52.8739\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 465.1039 - val_loss: 45.0717\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 369.4050 - val_loss: 35.9840\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 262.6056 - val_loss: 30.7636\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 209.0969 - val_loss: 26.3432\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 185.7479 - val_loss: 20.6816\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 460ms/step - loss: 848.9569 - val_loss: 7.8574\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.6927 - val_loss: 7.4624\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 28.5692 - val_loss: 7.7607\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.4652 - val_loss: 7.6949\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 28.4215 - val_loss: 7.9422\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.2259 - val_loss: 8.0290\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 28.4676 - val_loss: 8.1681\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 1288.5762 - val_loss: 146.0409\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 1162.9669 - val_loss: 131.6759\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 1140.3686 - val_loss: 121.5962\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 1096.0122 - val_loss: 113.3534\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 1068.9682 - val_loss: 100.1962\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 1060.2795 - val_loss: 99.8515\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 971.8335 - val_loss: 95.3483\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 1341.0859 - val_loss: 92.2237\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 944.2875 - val_loss: 74.5340\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 810.4510 - val_loss: 68.3916\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 818.1853 - val_loss: 60.6523\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 808.9448 - val_loss: 58.0053\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 677.4120 - val_loss: 56.1051\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 677.8884 - val_loss: 51.5689\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 14708.4836 - val_loss: 7.9000\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 29.1278 - val_loss: 7.8507\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.9081 - val_loss: 8.0959\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 28.9554 - val_loss: 7.6534\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 28.8843 - val_loss: 7.9588\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 28.7996 - val_loss: 8.0129\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 28.7077 - val_loss: 7.7019\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 465ms/step - loss: 4628.2750 - val_loss: 10.8393\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 28.8429 - val_loss: 7.9677\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 28.5961 - val_loss: 7.7346\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.5709 - val_loss: 7.9014\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 28.5891 - val_loss: 7.7173\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 28.5854 - val_loss: 8.0949\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.5041 - val_loss: 7.9173\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 1375.0435 - val_loss: 164.7325\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 1165.9100 - val_loss: 137.7553\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1120.8427 - val_loss: 119.2951\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 1073.6395 - val_loss: 110.0829\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 1046.1723 - val_loss: 98.4198\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 1100.6876 - val_loss: 97.6338\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 981.1201 - val_loss: 98.7297\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 1261.0528 - val_loss: 169.4343\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 1089.2412 - val_loss: 131.8282\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 975.9482 - val_loss: 101.6619\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 939.1402 - val_loss: 94.1197\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 894.0030 - val_loss: 88.3628\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 906.6611 - val_loss: 83.5160\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 852.1673 - val_loss: 81.8375\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 441ms/step - loss: 1545.3696 - val_loss: 87.2827\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 920.4676 - val_loss: 72.1442\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 332ms/step - loss: 781.4258 - val_loss: 66.3993\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 777.1434 - val_loss: 56.3410\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 648.9209 - val_loss: 54.6082\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 614.5447 - val_loss: 50.5659\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 592.7995 - val_loss: 46.7520\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 461ms/step - loss: 798.2283 - val_loss: 50.5812\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 420.0185 - val_loss: 36.9504\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 269.0253 - val_loss: 25.9130\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 170.2448 - val_loss: 19.7557\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 120.1367 - val_loss: 15.4985\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 88.5085 - val_loss: 13.5251\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 68.5044 - val_loss: 11.7478\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 1028.2794 - val_loss: 80.6640\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 948.6513 - val_loss: 78.6069\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 930.6887 - val_loss: 73.1759\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 858.9353 - val_loss: 67.6360\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 812.8942 - val_loss: 65.4284\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 769.9816 - val_loss: 62.8454\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 742.1876 - val_loss: 61.4452\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 809.0233 - val_loss: 59.8317\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 388.2922 - val_loss: 33.2286\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 210.7394 - val_loss: 21.7326\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 126.2936 - val_loss: 17.3344\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 86.5809 - val_loss: 14.1906\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 67.1354 - val_loss: 12.2395\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 55.4970 - val_loss: 10.9606\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 463ms/step - loss: 827.2382 - val_loss: 63.2339\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 490.0074 - val_loss: 47.9465\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 319.0076 - val_loss: 33.5801\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 227.6237 - val_loss: 25.1913\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 160.2412 - val_loss: 19.0296\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 117.4509 - val_loss: 15.7940\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 97.2320 - val_loss: 13.7689\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 468ms/step - loss: 485.7904 - val_loss: 19.1184\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 35.0055 - val_loss: 8.1748\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 26.7627 - val_loss: 6.7786\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 24.5936 - val_loss: 6.5180\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 22.1360 - val_loss: 5.9317\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 19.0599 - val_loss: 5.8798\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 18.8491 - val_loss: 5.7437\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 461ms/step - loss: 793.7320 - val_loss: 49.1149\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 394.3789 - val_loss: 36.0915\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 233.9244 - val_loss: 25.2616\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 151.2553 - val_loss: 18.7724\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 110.5066 - val_loss: 17.1146\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 85.8409 - val_loss: 13.8047\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 65.2462 - val_loss: 12.1732\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 468ms/step - loss: 312.5651 - val_loss: 9.4569\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 29.9088 - val_loss: 7.6263\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 25.5125 - val_loss: 6.6883\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 22.6873 - val_loss: 6.5332\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 18.6600 - val_loss: 5.2080\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 15.6866 - val_loss: 4.8877\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 14.0809 - val_loss: 4.4195\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 33865.3341 - val_loss: 208.4072\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 29.9347 - val_loss: 19.2508\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 29.7941 - val_loss: 15.1158\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 29.4491 - val_loss: 16.5424\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 29.3486 - val_loss: 8.1904\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.9819 - val_loss: 7.9018\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 28.6313 - val_loss: 7.9517\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 521.7713 - val_loss: 24.0240\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 75.0572 - val_loss: 12.0751\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 38.6593 - val_loss: 8.6850\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 30.0532 - val_loss: 8.1131\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 25.6339 - val_loss: 7.3066\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 24.3515 - val_loss: 7.2872\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 21.9969 - val_loss: 6.7691\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 963.5850 - val_loss: 70.3386\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 767.2705 - val_loss: 61.5669\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 663.4473 - val_loss: 52.0502\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 576.9267 - val_loss: 46.1733\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 489.4279 - val_loss: 41.7077\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 404.9402 - val_loss: 39.8879\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 365.6923 - val_loss: 36.9432\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 1117.4392 - val_loss: 124.7402\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 1026.7943 - val_loss: 111.6539\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 956.2252 - val_loss: 110.7342\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 905.0199 - val_loss: 97.8447\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 925.0313 - val_loss: 96.8207\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 12s 318ms/step - loss: 873.1807 - val_loss: 97.0545\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 847.4529 - val_loss: 91.8930\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 455ms/step - loss: 895.1264 - val_loss: 57.9738\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 473.9571 - val_loss: 42.3879\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 258.4329 - val_loss: 26.2708\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 179.2963 - val_loss: 19.5124\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 124.3077 - val_loss: 16.9844\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 86.2490 - val_loss: 15.6354\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 63.9318 - val_loss: 11.7828\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1634.2635 - val_loss: 167.6610\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 1212.6927 - val_loss: 106.5798\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 1082.3118 - val_loss: 87.6839\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 987.4494 - val_loss: 80.3990\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 979.2274 - val_loss: 77.8447\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 982.9295 - val_loss: 74.5345\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 929.4910 - val_loss: 75.9367\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 1425.3401 - val_loss: 157.6932\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 1142.6905 - val_loss: 111.1196\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 1051.0813 - val_loss: 99.3697\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 965.4275 - val_loss: 94.7411\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 951.3981 - val_loss: 91.6826\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 1004.3915 - val_loss: 81.5685\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 919.3158 - val_loss: 86.1077\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 453ms/step - loss: 571.4052 - val_loss: 32.6253\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 112.6471 - val_loss: 12.3742\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 44.4040 - val_loss: 9.6243\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 33.6187 - val_loss: 7.9838\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 28.0175 - val_loss: 7.8377\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 26.4165 - val_loss: 7.5874\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 23.7721 - val_loss: 7.2629\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 466ms/step - loss: 1197.7032 - val_loss: 7.9646\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 28.5452 - val_loss: 7.7173\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 28.5374 - val_loss: 7.7598\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 28.5699 - val_loss: 7.6906\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 28.5649 - val_loss: 7.9432\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.5120 - val_loss: 8.0481\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.6340 - val_loss: 8.0021\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 460ms/step - loss: 801.6626 - val_loss: 62.8915\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 322.6744 - val_loss: 34.3481\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 176.2416 - val_loss: 20.1825\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 112.8811 - val_loss: 16.7342\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 73.6789 - val_loss: 13.6350\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 56.3735 - val_loss: 12.1954\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 46.2541 - val_loss: 11.1051\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 1017.7948 - val_loss: 74.7453\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 814.0006 - val_loss: 68.5063\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 693.5789 - val_loss: 62.7743\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 624.9610 - val_loss: 53.5365\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 536.9537 - val_loss: 50.7008\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 464.8243 - val_loss: 45.3698\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 438.2167 - val_loss: 44.6970\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1241.6684 - val_loss: 152.1356\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 1107.7219 - val_loss: 129.2986\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 1043.5502 - val_loss: 112.8905\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 1008.5700 - val_loss: 103.4471\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 1016.3978 - val_loss: 104.1852\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 938.9298 - val_loss: 103.9190\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 986.1150 - val_loss: 93.7636\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 1023.4751 - val_loss: 151.8717\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 999.1901 - val_loss: 131.1091\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 966.8684 - val_loss: 112.5660\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 982.3110 - val_loss: 107.5333\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 916.3181 - val_loss: 100.3668\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 860.6396 - val_loss: 99.5765\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 843.7084 - val_loss: 90.6551\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 683.1223 - val_loss: 50.2569\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 240.6235 - val_loss: 21.8398\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 106.2898 - val_loss: 16.3911\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 72.5108 - val_loss: 11.9102\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 49.6118 - val_loss: 9.9887\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 38.4835 - val_loss: 9.0275\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 32.0786 - val_loss: 8.1117\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 455ms/step - loss: 613.2077 - val_loss: 8.2617\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 30.2174 - val_loss: 7.7325\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 28.5436 - val_loss: 7.7109\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 27.5053 - val_loss: 7.6309\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 26.5384 - val_loss: 7.4283\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 25.5445 - val_loss: 7.6811\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 24.3801 - val_loss: 7.1541\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 9316.0505 - val_loss: 8.0643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 28.9349 - val_loss: 7.9353\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 28.8984 - val_loss: 8.0335\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 28.7642 - val_loss: 8.1417\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 28.7595 - val_loss: 7.8760\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.6925 - val_loss: 8.0066\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 28.6533 - val_loss: 7.8642\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 2812.0531 - val_loss: 8.0735\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 28.8074 - val_loss: 7.7530\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 28.7072 - val_loss: 7.6066\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 28.6360 - val_loss: 7.8018\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 28.5523 - val_loss: 7.6193\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.6206 - val_loss: 7.8188\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 28.6612 - val_loss: 7.6597\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 441ms/step - loss: 788.3213 - val_loss: 74.0899\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 616.3225 - val_loss: 51.0809\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 466.3351 - val_loss: 38.3705\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 363.0741 - val_loss: 31.0316\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 281.9769 - val_loss: 29.3607\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 240.1275 - val_loss: 25.5683\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 177.1318 - val_loss: 21.2775\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 445ms/step - loss: 1080.4019 - val_loss: 121.6450\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 922.1188 - val_loss: 101.6427\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 931.3216 - val_loss: 91.3040\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 837.0494 - val_loss: 82.7076\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 758.2163 - val_loss: 85.0106\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 828.1512 - val_loss: 81.7130\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 797.9434 - val_loss: 76.1498\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 450ms/step - loss: 1369.6907 - val_loss: 7.6311\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.5851 - val_loss: 7.6639\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 28.6025 - val_loss: 7.9441\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 28.5664 - val_loss: 7.9769\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 28.5168 - val_loss: 7.8331\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 28.3380 - val_loss: 7.9330\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 28.3543 - val_loss: 7.7322\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 171707.7211 - val_loss: 7.9772\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 29.5404 - val_loss: 8.3036\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 29.5002 - val_loss: 7.9906\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 29.4449 - val_loss: 8.1307\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 29.3963 - val_loss: 8.0934\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 29.3343 - val_loss: 7.7861\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 29.2681 - val_loss: 8.1478\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 435ms/step - loss: 606.9928 - val_loss: 7.8221\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 321ms/step - loss: 29.0386 - val_loss: 7.7918\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 28.6290 - val_loss: 7.9231\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 306ms/step - loss: 28.0407 - val_loss: 7.8374\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 27.6872 - val_loss: 8.0115\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 27.6206 - val_loss: 7.7537\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 26.4253 - val_loss: 7.8056\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 820.3828 - val_loss: 53.7376\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 215.1189 - val_loss: 21.0384\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 95.5369 - val_loss: 12.3331\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 59.9784 - val_loss: 10.6680\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 45.4472 - val_loss: 9.0021\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 37.6585 - val_loss: 7.9593\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 32.7613 - val_loss: 7.2284\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 806.3373 - val_loss: 71.4251\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 569.3197 - val_loss: 55.8346\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 403.2895 - val_loss: 36.6651\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 264.1721 - val_loss: 32.3526\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 196.5468 - val_loss: 21.6573\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 139.5544 - val_loss: 19.2780\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 124.5258 - val_loss: 16.1131\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 581.1958 - val_loss: 20.7359\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 57.9735 - val_loss: 8.5604\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 33.8547 - val_loss: 7.4957\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 305ms/step - loss: 28.1277 - val_loss: 7.1373\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 25.1277 - val_loss: 7.0946\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 309ms/step - loss: 22.3345 - val_loss: 6.3434\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 20.8050 - val_loss: 6.3816\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 985.1875 - val_loss: 75.6245\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 25s 634ms/step - loss: 955.9423 - val_loss: 66.1715\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 843.0019 - val_loss: 59.7193\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 762.0519 - val_loss: 53.8290\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 735.0421 - val_loss: 48.2105\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 655.8442 - val_loss: 50.7932\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 616.8983 - val_loss: 48.0220\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 17s 437ms/step - loss: 492.7990 - val_loss: 40.5401\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 63.8435 - val_loss: 10.1330\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 33.9066 - val_loss: 8.1670\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 29.6992 - val_loss: 7.5691\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 12s 310ms/step - loss: 25.3355 - val_loss: 7.6122\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 22.1699 - val_loss: 7.1021\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 20.3844 - val_loss: 6.4729\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 765.8963 - val_loss: 7.8391\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 24s 616ms/step - loss: 28.7181 - val_loss: 7.7097\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 28.5940 - val_loss: 7.6288\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 28.3048 - val_loss: 7.6841\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 28.3091 - val_loss: 7.5987\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 28.2060 - val_loss: 7.9332\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 27.9874 - val_loss: 7.5805\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 459ms/step - loss: 1121.0884 - val_loss: 117.2526\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 1022.7936 - val_loss: 101.6914\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 1030.0093 - val_loss: 96.7622\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 974.7423 - val_loss: 91.3246\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 871.7121 - val_loss: 88.6499\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 927.7682 - val_loss: 85.8939\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 961.4119 - val_loss: 85.3048\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 984.7988 - val_loss: 71.5411\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 893.7082 - val_loss: 65.2447\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 765.6666 - val_loss: 57.8554\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 780.9583 - val_loss: 55.0445\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 645.6845 - val_loss: 48.3694\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 608.7249 - val_loss: 46.4186\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 312ms/step - loss: 537.4975 - val_loss: 42.7615\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 457ms/step - loss: 662.0265 - val_loss: 7.4937\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 28.6213 - val_loss: 7.8119\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 28.3701 - val_loss: 7.7607\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 28.5278 - val_loss: 7.5504\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.1032 - val_loss: 7.2429\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 387ms/step - loss: 27.5790 - val_loss: 7.5269\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 28.0438 - val_loss: 7.7411\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 22s 555ms/step - loss: 1157.5537 - val_loss: 84.8389\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 817.4072 - val_loss: 77.9671\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 804.0292 - val_loss: 65.6717\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 667.7212 - val_loss: 59.8634\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 642.5128 - val_loss: 53.0484\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 601.7520 - val_loss: 47.9465\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 536.8453 - val_loss: 45.2173\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 515ms/step - loss: 919.6965 - val_loss: 76.1222\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 776.5876 - val_loss: 65.7531\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 669.2980 - val_loss: 66.1529\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 586.7413 - val_loss: 51.4596\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 518.3109 - val_loss: 51.3378\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 445.7110 - val_loss: 43.3186\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 376.7244 - val_loss: 44.8147\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 477.1934 - val_loss: 26.7908\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 70.9834 - val_loss: 11.0225\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 46s 1s/step - loss: 34.7737 - val_loss: 9.0304\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 27.2333 - val_loss: 7.8177\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 34s 873ms/step - loss: 25.3229 - val_loss: 6.9624\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 21.2403 - val_loss: 6.7067\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 19.7447 - val_loss: 6.5235\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 45s 1s/step - loss: 1139.9937 - val_loss: 101.4250\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 956.8582 - val_loss: 96.7809\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 871.4969 - val_loss: 88.4267\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 877.9635 - val_loss: 73.8963\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 862.9555 - val_loss: 70.2187\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 785.2441 - val_loss: 77.1610\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 816.1715 - val_loss: 72.7655\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 956.2011 - val_loss: 81.0210\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 783.7279 - val_loss: 68.4518\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 24s 619ms/step - loss: 668.7395 - val_loss: 54.3502\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 519.8562 - val_loss: 48.9296\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 469.7489 - val_loss: 47.6184\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 451.3889 - val_loss: 44.9701\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 375.5021 - val_loss: 37.6169\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 1049.4235 - val_loss: 84.1134\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 885.9071 - val_loss: 75.8366\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 20s 508ms/step - loss: 883.2828 - val_loss: 68.2108\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 813.7994 - val_loss: 65.6769\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 713.0147 - val_loss: 62.6956\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 735.4948 - val_loss: 56.8106\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 679.3947 - val_loss: 55.3943\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 24s 627ms/step - loss: 1076.1516 - val_loss: 110.6570\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 1011.9470 - val_loss: 102.8581\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 967.8009 - val_loss: 90.3179\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 922.0947 - val_loss: 84.1202\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 863.6181 - val_loss: 82.2312\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 761.3205 - val_loss: 76.4958\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 789.8558 - val_loss: 71.4790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 453ms/step - loss: 1020.6704 - val_loss: 76.8635\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 984.0563 - val_loss: 70.9734\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 925.2960 - val_loss: 67.8063\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 875.8558 - val_loss: 61.3082\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 802.7960 - val_loss: 60.8977\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 770.7912 - val_loss: 58.0802\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 774.0250 - val_loss: 58.9760\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 471ms/step - loss: 724.3514 - val_loss: 39.7194\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 202.3631 - val_loss: 20.9407\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 93.1292 - val_loss: 13.5611\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 57.2786 - val_loss: 10.0005\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 43.2437 - val_loss: 8.9281\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 35.4804 - val_loss: 8.7128\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 30.2903 - val_loss: 8.0226\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 7125.7125 - val_loss: 7.8780\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 28.6335 - val_loss: 7.7164\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 28.6493 - val_loss: 7.9908\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 24s 613ms/step - loss: 28.5555 - val_loss: 7.8867\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 308ms/step - loss: 28.5214 - val_loss: 8.0222\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 28.1068 - val_loss: 7.5545\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 27.9117 - val_loss: 8.0028\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 892.5837 - val_loss: 64.5110\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 679.4913 - val_loss: 58.3992\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 533.2817 - val_loss: 46.9529\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 502.9005 - val_loss: 42.6728\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 404.9996 - val_loss: 38.1503\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 351.2119 - val_loss: 38.0015\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 283.3217 - val_loss: 30.8882\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 36s 934ms/step - loss: 1362.5728 - val_loss: 176.7166\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 27s 681ms/step - loss: 1220.2351 - val_loss: 132.8603\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 1034.8714 - val_loss: 104.8612\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 981.3109 - val_loss: 94.3013\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 1048.9531 - val_loss: 90.1087\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 319ms/step - loss: 967.2159 - val_loss: 87.1660\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 981.8459 - val_loss: 80.4935\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 28s 727ms/step - loss: 1390.9459 - val_loss: 8.4716\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 19s 494ms/step - loss: 28.7129 - val_loss: 7.5806\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.6055 - val_loss: 7.9214\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 17s 429ms/step - loss: 28.5985 - val_loss: 7.9776\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 28.4168 - val_loss: 7.4194\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 28.4910 - val_loss: 7.7158\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 28.4924 - val_loss: 7.7748\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 47s 1s/step - loss: 1216.8521 - val_loss: 98.7265\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 1012.0049 - val_loss: 77.6120\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 988.3970 - val_loss: 75.8026\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 25s 644ms/step - loss: 979.5388 - val_loss: 72.3969\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 939.7119 - val_loss: 69.9497\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 26s 676ms/step - loss: 858.1340 - val_loss: 65.8393\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 890.2984 - val_loss: 65.8829\n",
      "Epoch 1/7\n",
      " 3/39 [=>............................] - ETA: 2:07 - loss: 1053.1813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.308377). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 85s 2s/step - loss: 926.0572 - val_loss: 69.7975\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 45s 1s/step - loss: 790.5540 - val_loss: 63.0027\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 20s 524ms/step - loss: 690.5294 - val_loss: 59.8261\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 15s 392ms/step - loss: 636.9644 - val_loss: 54.0483\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 518.7723 - val_loss: 51.2296\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 318ms/step - loss: 585.2824 - val_loss: 47.1079\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 18s 455ms/step - loss: 526.6226 - val_loss: 45.9824\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 33s 837ms/step - loss: 744.5094 - val_loss: 64.1634\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 349.5935 - val_loss: 34.8319\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 185.4493 - val_loss: 25.8042\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 21s 527ms/step - loss: 112.1212 - val_loss: 15.4047\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 69.6860 - val_loss: 13.7326\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 25s 644ms/step - loss: 52.2645 - val_loss: 10.3259\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 45.5810 - val_loss: 8.9559\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 3:38 - loss: 2239.1210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.460849). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 82s 2s/step - loss: 568.4871 - val_loss: 12.0785\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 43s 1s/step - loss: 39.5353 - val_loss: 8.4000\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 22s 551ms/step - loss: 30.4317 - val_loss: 7.8717\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 26.3048 - val_loss: 7.3234\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 26s 666ms/step - loss: 24.7501 - val_loss: 7.0013\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 22.9257 - val_loss: 7.0510\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 390ms/step - loss: 21.7867 - val_loss: 6.7383\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 42s 1s/step - loss: 533.7459 - val_loss: 30.1225\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 23s 592ms/step - loss: 58.4070 - val_loss: 8.6972\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 378ms/step - loss: 32.9670 - val_loss: 7.5859\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 27.3301 - val_loss: 7.2724\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 23.3901 - val_loss: 7.0953\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 21.7086 - val_loss: 6.6062\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 311ms/step - loss: 19.9000 - val_loss: 5.6756\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 70s 2s/step - loss: 477.7548 - val_loss: 19.6667\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 32s 818ms/step - loss: 56.7416 - val_loss: 8.7955\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 23s 595ms/step - loss: 33.9140 - val_loss: 8.4260\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 26s 670ms/step - loss: 27.9812 - val_loss: 7.7281\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 36s 923ms/step - loss: 23.9457 - val_loss: 7.5980\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 20s 511ms/step - loss: 21.3390 - val_loss: 7.0084\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 22s 557ms/step - loss: 19.4598 - val_loss: 6.4229\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 99s 3s/step - loss: 1540.7678 - val_loss: 159.9477\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 52s 1s/step - loss: 1074.6022 - val_loss: 124.3883\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 18s 449ms/step - loss: 1002.7818 - val_loss: 109.2307\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 966.3645 - val_loss: 102.9576\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 23s 598ms/step - loss: 936.4100 - val_loss: 96.8861\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 879.3277 - val_loss: 95.5285\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 20s 514ms/step - loss: 843.2969 - val_loss: 84.7740\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 101s 3s/step - loss: 812.3072 - val_loss: 61.3188\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 52s 1s/step - loss: 467.4536 - val_loss: 52.9470\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 31s 797ms/step - loss: 309.9487 - val_loss: 33.5074\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 217.1501 - val_loss: 25.9878\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 154.1706 - val_loss: 20.3128\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 116.7575 - val_loss: 16.8995\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 18s 472ms/step - loss: 91.2878 - val_loss: 14.2980\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 94s 2s/step - loss: 343.8698 - val_loss: 8.6034\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 50s 1s/step - loss: 27.8133 - val_loss: 7.9606\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 29s 739ms/step - loss: 24.6605 - val_loss: 6.4277\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 20s 519ms/step - loss: 20.7180 - val_loss: 5.9198\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 32s 831ms/step - loss: 18.2093 - val_loss: 4.7813\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 32s 819ms/step - loss: 15.6145 - val_loss: 3.7840\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 29s 748ms/step - loss: 14.9818 - val_loss: 4.1180\n",
      "lr:  0.0014083946687389207 loss:  4.117955207824707\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 91s 2s/step - loss: 832.3382 - val_loss: 55.2250\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 50s 1s/step - loss: 581.1943 - val_loss: 45.6515\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 26s 675ms/step - loss: 415.0554 - val_loss: 43.0046\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 26s 669ms/step - loss: 317.1417 - val_loss: 36.5258\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 250.0110 - val_loss: 32.7472\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 203.4132 - val_loss: 24.6991\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 166.5504 - val_loss: 20.9978\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 104s 3s/step - loss: 669.6909 - val_loss: 8.8460\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 59s 2s/step - loss: 29.9606 - val_loss: 8.0224\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 28s 710ms/step - loss: 28.9018 - val_loss: 7.6888\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 33s 852ms/step - loss: 27.9825 - val_loss: 7.9058\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 26.9977 - val_loss: 7.9670\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 320ms/step - loss: 26.8681 - val_loss: 7.8382\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 20s 524ms/step - loss: 25.6513 - val_loss: 7.7828\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 8:11 - loss: 11979.2695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.381055). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 112s 3s/step - loss: 1183.7583 - val_loss: 7.8337\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 51s 1s/step - loss: 29.3965 - val_loss: 7.9436\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 32s 826ms/step - loss: 28.2438 - val_loss: 8.0149\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 27.5987 - val_loss: 7.5481\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 36s 931ms/step - loss: 26.7770 - val_loss: 7.6513\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 25.8707 - val_loss: 7.5404\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 20s 517ms/step - loss: 24.0615 - val_loss: 7.0209\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 88s 2s/step - loss: 597.0037 - val_loss: 42.7747\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 57s 1s/step - loss: 151.2013 - val_loss: 14.4643\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 31s 802ms/step - loss: 66.0662 - val_loss: 11.2794\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 41.6128 - val_loss: 8.6594\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 34s 873ms/step - loss: 34.1493 - val_loss: 8.4724\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 30s 766ms/step - loss: 29.1112 - val_loss: 8.0431\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 26.2554 - val_loss: 7.6132\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 97s 2s/step - loss: 1224.2043 - val_loss: 115.7982\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 67s 2s/step - loss: 1109.7991 - val_loss: 100.7653\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 32s 813ms/step - loss: 1082.7913 - val_loss: 95.6557\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 1157.5717 - val_loss: 87.5343\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 29s 731ms/step - loss: 942.7504 - val_loss: 85.8481\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 382ms/step - loss: 1004.1184 - val_loss: 87.4865\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 396ms/step - loss: 995.8945 - val_loss: 85.6201\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 180s 5s/step - loss: 28949.2891 - val_loss: 7.2569\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 103s 3s/step - loss: 28.6572 - val_loss: 8.0259\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 44s 1s/step - loss: 28.7413 - val_loss: 7.9281\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 37s 945ms/step - loss: 28.7367 - val_loss: 8.0687\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 18s 462ms/step - loss: 28.7112 - val_loss: 7.8287\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 28.7038 - val_loss: 8.0509\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 21s 546ms/step - loss: 28.6744 - val_loss: 7.8602\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 19:00 - loss: 914.0994 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.564961). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 152s 4s/step - loss: 468.6804 - val_loss: 28.3063\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 63s 2s/step - loss: 70.1090 - val_loss: 10.0472\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 36.7483 - val_loss: 8.1347\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 32s 811ms/step - loss: 28.8725 - val_loss: 7.3869\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 40s 1s/step - loss: 24.9459 - val_loss: 6.7526\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 34s 880ms/step - loss: 23.2715 - val_loss: 6.7124\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 20.0948 - val_loss: 6.2176\n",
      "Epoch 1/7\n",
      " 3/39 [=>............................] - ETA: 10:19 - loss: 1625.5696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.442709). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 150s 4s/step - loss: 706.7055 - val_loss: 55.1738\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 75s 2s/step - loss: 206.6980 - val_loss: 18.6737\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 31s 801ms/step - loss: 77.3759 - val_loss: 12.5468\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 49.8044 - val_loss: 10.3226\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 23s 588ms/step - loss: 37.8094 - val_loss: 9.0763\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 304ms/step - loss: 30.4455 - val_loss: 8.0541\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 27.5655 - val_loss: 7.8651\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 13:26 - loss: 1401.6819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.421314). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 150s 4s/step - loss: 797.3780 - val_loss: 56.5270\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 65s 2s/step - loss: 457.8062 - val_loss: 39.1772\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 31s 808ms/step - loss: 285.7529 - val_loss: 26.5280\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 301ms/step - loss: 180.7190 - val_loss: 21.0114\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 29s 747ms/step - loss: 121.8490 - val_loss: 18.0866\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 98.4017 - val_loss: 14.1694\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 78.6363 - val_loss: 13.0400\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 114s 3s/step - loss: 848.1867 - val_loss: 8.5016\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 64s 2s/step - loss: 28.8607 - val_loss: 8.4048\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 28.7047 - val_loss: 7.7577\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 28.3973 - val_loss: 7.9523\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 29s 739ms/step - loss: 28.3803 - val_loss: 7.5995\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 28.0566 - val_loss: 7.6896\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 27.4189 - val_loss: 7.7934\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 4:59 - loss: 1308.0695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.272354). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 74s 2s/step - loss: 505.2650 - val_loss: 26.0222\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 29s 754ms/step - loss: 57.2421 - val_loss: 8.2257\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 32.3585 - val_loss: 7.5931\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 27.4904 - val_loss: 7.0983\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 41s 1s/step - loss: 25.4035 - val_loss: 7.0368\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 51s 1s/step - loss: 23.4020 - val_loss: 6.5092\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 21s 549ms/step - loss: 21.5320 - val_loss: 6.5710\n",
      "Epoch 1/7\n",
      " 3/39 [=>............................] - ETA: 3:00 - loss: 1434.4259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.175275). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 150s 4s/step - loss: 1113.3334 - val_loss: 101.4993\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 74s 2s/step - loss: 882.6682 - val_loss: 84.2097\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 35s 910ms/step - loss: 819.5679 - val_loss: 78.2428\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 24s 627ms/step - loss: 735.7919 - val_loss: 66.5642\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 690.9943 - val_loss: 64.8164\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 30s 779ms/step - loss: 579.6788 - val_loss: 58.8871\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 511.8630 - val_loss: 56.7366\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 101s 3s/step - loss: 908.4484 - val_loss: 74.9039\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 67s 2s/step - loss: 661.8511 - val_loss: 60.6141\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 30s 765ms/step - loss: 540.2939 - val_loss: 56.8218\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 26s 678ms/step - loss: 446.2828 - val_loss: 46.3032\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 18s 472ms/step - loss: 345.6353 - val_loss: 41.2250\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 292.0009 - val_loss: 34.1289\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 18s 449ms/step - loss: 263.4826 - val_loss: 31.8127\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 84s 2s/step - loss: 1793.1957 - val_loss: 267.5525\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 62s 2s/step - loss: 1406.6176 - val_loss: 195.3012\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 27s 686ms/step - loss: 1195.0832 - val_loss: 158.0131\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 19s 490ms/step - loss: 1166.4000 - val_loss: 127.8785\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 36s 923ms/step - loss: 1052.1306 - val_loss: 109.5448\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 53s 1s/step - loss: 1003.0590 - val_loss: 97.2674\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 92s 2s/step - loss: 970.3206 - val_loss: 84.6942\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 92s 2s/step - loss: 460.3772 - val_loss: 14.1828\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 56s 1s/step - loss: 44.2973 - val_loss: 8.0118\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 47s 1s/step - loss: 29.5658 - val_loss: 7.6934\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 22s 556ms/step - loss: 25.7304 - val_loss: 7.1036\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 19s 475ms/step - loss: 23.0987 - val_loss: 6.7494\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 17s 432ms/step - loss: 21.7448 - val_loss: 6.6702\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 19.7267 - val_loss: 5.8985\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 41s 1s/step - loss: 534.7300 - val_loss: 32.4571\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 20s 515ms/step - loss: 67.4834 - val_loss: 11.2124\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 37.6421 - val_loss: 8.3263\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 17s 438ms/step - loss: 29.4154 - val_loss: 7.5876\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 19s 487ms/step - loss: 26.6714 - val_loss: 8.0104\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 25s 643ms/step - loss: 24.9450 - val_loss: 7.3948\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 390ms/step - loss: 21.3493 - val_loss: 6.8295\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 61s 2s/step - loss: 948.9685 - val_loss: 78.8433\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 24s 611ms/step - loss: 807.8176 - val_loss: 65.5618\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 386ms/step - loss: 792.7350 - val_loss: 63.7689\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 733.3962 - val_loss: 66.5562\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 26s 677ms/step - loss: 664.6825 - val_loss: 59.8773\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 25s 651ms/step - loss: 701.0409 - val_loss: 58.6335\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 615.1067 - val_loss: 53.4428\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 38s 978ms/step - loss: 1310.5066 - val_loss: 140.4603\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 18s 464ms/step - loss: 1077.4661 - val_loss: 114.8158\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 17s 441ms/step - loss: 997.0356 - val_loss: 97.9866\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 25s 636ms/step - loss: 985.7155 - val_loss: 95.0510\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 925.7384 - val_loss: 95.2490\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 18s 467ms/step - loss: 817.0087 - val_loss: 86.3487\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 22s 552ms/step - loss: 888.9174 - val_loss: 79.2485\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 2:46 - loss: 2194.9478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.382466). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 96s 2s/step - loss: 1127.6326 - val_loss: 76.9180\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 47s 1s/step - loss: 813.2460 - val_loss: 64.9593\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 23s 591ms/step - loss: 747.6402 - val_loss: 63.4476\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 17s 445ms/step - loss: 673.2085 - val_loss: 52.7267\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 627.1130 - val_loss: 56.0497\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 584.5747 - val_loss: 52.4388\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 23s 589ms/step - loss: 554.9324 - val_loss: 48.9294\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 3:01 - loss: 990.1639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.592068). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 100s 3s/step - loss: 796.4669 - val_loss: 71.9791\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 58s 1s/step - loss: 578.8989 - val_loss: 61.5184\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 42s 1s/step - loss: 429.8639 - val_loss: 43.4471\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 24s 613ms/step - loss: 366.9691 - val_loss: 36.6889\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 31s 788ms/step - loss: 256.8662 - val_loss: 31.3952\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 225.7515 - val_loss: 26.1605\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 35s 892ms/step - loss: 194.9740 - val_loss: 21.7996\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 5:29 - loss: 16724747.4555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.630246). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 117s 3s/step - loss: 929266.4676 - val_loss: 76.9836\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 69s 2s/step - loss: 30.4226 - val_loss: 10.7326\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 29s 736ms/step - loss: 29.5028 - val_loss: 8.3486\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 29.6554 - val_loss: 8.1296\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 29.4945 - val_loss: 8.0318\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 29.1828 - val_loss: 7.7643\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 386ms/step - loss: 29.0887 - val_loss: 7.8223\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 3:43 - loss: 17546.9314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.210141). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 97s 2s/step - loss: 1030.3876 - val_loss: 7.6369\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 54s 1s/step - loss: 28.6683 - val_loss: 7.6500\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 26s 669ms/step - loss: 28.5505 - val_loss: 7.8105\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 19s 493ms/step - loss: 28.5814 - val_loss: 8.1404\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 28s 720ms/step - loss: 28.5096 - val_loss: 7.7502\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 28.5296 - val_loss: 7.6289\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 388ms/step - loss: 28.5755 - val_loss: 7.9112\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 94s 2s/step - loss: 830.2043 - val_loss: 55.5526\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 51s 1s/step - loss: 475.5532 - val_loss: 34.4383\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 27s 695ms/step - loss: 302.0805 - val_loss: 32.3758\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 303ms/step - loss: 218.5601 - val_loss: 25.0927\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 150.8730 - val_loss: 16.4129\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 307ms/step - loss: 105.4928 - val_loss: 15.2522\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 23s 585ms/step - loss: 82.9209 - val_loss: 13.5302\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 4:03 - loss: 1769.3069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.854791). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 102s 3s/step - loss: 487.8954 - val_loss: 15.6686\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 53s 1s/step - loss: 47.5011 - val_loss: 8.6336\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 27s 685ms/step - loss: 31.3493 - val_loss: 7.9996\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 25s 646ms/step - loss: 26.6363 - val_loss: 7.6163\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 17s 424ms/step - loss: 25.2401 - val_loss: 7.2251\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 21s 548ms/step - loss: 22.6175 - val_loss: 7.0707\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 20.9672 - val_loss: 6.8932\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 86s 2s/step - loss: 1197.7773 - val_loss: 125.5247\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 48s 1s/step - loss: 1038.2209 - val_loss: 109.7493\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 28s 712ms/step - loss: 910.8940 - val_loss: 89.0922\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 902.6630 - val_loss: 85.7483\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 21s 546ms/step - loss: 773.7970 - val_loss: 80.3066\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 31s 804ms/step - loss: 841.4881 - val_loss: 75.8730\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 809.1163 - val_loss: 74.4812\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 68s 2s/step - loss: 1016.1962 - val_loss: 80.9388\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 31s 798ms/step - loss: 846.8470 - val_loss: 74.1007\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 381ms/step - loss: 841.2234 - val_loss: 73.0606\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 803.4698 - val_loss: 68.4156\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 756.6529 - val_loss: 64.2134\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 314ms/step - loss: 800.3537 - val_loss: 65.4842\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 26s 668ms/step - loss: 720.4444 - val_loss: 60.1605\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 3:20 - loss: 1127.6920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.340286). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 87s 2s/step - loss: 1151.0994 - val_loss: 102.0719\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 54s 1s/step - loss: 1062.6062 - val_loss: 92.2804\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 25s 649ms/step - loss: 1010.8797 - val_loss: 87.3314\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 990.1291 - val_loss: 76.1474\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 20s 522ms/step - loss: 861.1919 - val_loss: 74.1579\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 850.7201 - val_loss: 66.2284\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 379ms/step - loss: 848.3429 - val_loss: 68.3007\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 8:53 - loss: 23816.2423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.034942). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 115s 3s/step - loss: 2354.8334 - val_loss: 8.7490\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 53s 1s/step - loss: 28.6130 - val_loss: 8.1284\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 36s 915ms/step - loss: 28.6969 - val_loss: 7.8121\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 315ms/step - loss: 28.5582 - val_loss: 7.7674\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 23s 585ms/step - loss: 28.4409 - val_loss: 7.6651\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 19s 482ms/step - loss: 28.3924 - val_loss: 7.8991\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 27s 697ms/step - loss: 28.4793 - val_loss: 7.5896\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 76s 2s/step - loss: 1281.0632 - val_loss: 113.8477\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 45s 1s/step - loss: 958.6146 - val_loss: 86.1240\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 801.7752 - val_loss: 79.3740\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 739.7675 - val_loss: 65.2762\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 658.3567 - val_loss: 70.3341\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 12s 317ms/step - loss: 632.9999 - val_loss: 61.2057\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 12s 306ms/step - loss: 571.6438 - val_loss: 54.1812\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 50s 1s/step - loss: 1217.5245 - val_loss: 146.1070\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 1099.6236 - val_loss: 126.7776\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 23s 601ms/step - loss: 1021.6688 - val_loss: 117.1467\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 54s 1s/step - loss: 986.1443 - val_loss: 106.3117\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 28s 710ms/step - loss: 912.4864 - val_loss: 105.7058\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 42s 1s/step - loss: 923.8208 - val_loss: 95.5825\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 906.7290 - val_loss: 97.4279\n",
      "Epoch 1/7\n",
      " 2/39 [>.............................] - ETA: 9:44 - loss: 1149.4969 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippoc/anaconda3/envs/schen-cpu/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.501119). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 131s 3s/step - loss: 855.3905 - val_loss: 62.0510\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 67s 2s/step - loss: 498.9301 - val_loss: 41.0802\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 27s 690ms/step - loss: 296.2935 - val_loss: 29.4720\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 15s 386ms/step - loss: 212.6401 - val_loss: 20.3369\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 23s 597ms/step - loss: 153.7429 - val_loss: 16.7285\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 11s 295ms/step - loss: 113.5413 - val_loss: 13.6476\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 88.6745 - val_loss: 12.3595\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 155s 4s/step - loss: 759.5265 - val_loss: 37.1792\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 149s 4s/step - loss: 103.8374 - val_loss: 10.8226\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 168s 4s/step - loss: 43.5676 - val_loss: 9.0067\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 169s 4s/step - loss: 33.3046 - val_loss: 7.7417\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 172s 4s/step - loss: 27.9787 - val_loss: 7.7828\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 187s 5s/step - loss: 26.2655 - val_loss: 7.3213\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 176s 5s/step - loss: 23.4540 - val_loss: 6.9038\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 210s 5s/step - loss: 887.8668 - val_loss: 76.5425\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 186s 5s/step - loss: 722.9130 - val_loss: 59.7285\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 147s 4s/step - loss: 613.8203 - val_loss: 59.2280\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 100s 3s/step - loss: 563.4886 - val_loss: 50.8888\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 90s 2s/step - loss: 467.1803 - val_loss: 46.4773\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 88s 2s/step - loss: 440.4958 - val_loss: 43.6823\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 96s 2s/step - loss: 370.0942 - val_loss: 38.1122\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 97s 2s/step - loss: 969.4666 - val_loss: 75.2776\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 90s 2s/step - loss: 672.8854 - val_loss: 64.3358\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 90s 2s/step - loss: 518.2688 - val_loss: 46.7367\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 93s 2s/step - loss: 401.0394 - val_loss: 37.3520\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 89s 2s/step - loss: 345.1575 - val_loss: 31.1653\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 88s 2s/step - loss: 269.5330 - val_loss: 26.4078\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 100s 3s/step - loss: 211.6052 - val_loss: 23.6450\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 98s 3s/step - loss: 759.6653 - val_loss: 8.2554\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 93s 2s/step - loss: 28.3590 - val_loss: 7.9495\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 97s 2s/step - loss: 28.2142 - val_loss: 7.3984\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 97s 2s/step - loss: 27.8253 - val_loss: 7.5259\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 98s 3s/step - loss: 26.1851 - val_loss: 6.9469\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 104s 3s/step - loss: 24.7749 - val_loss: 6.1248\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 101s 3s/step - loss: 23.7565 - val_loss: 6.1330\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 112s 3s/step - loss: 1675.5610 - val_loss: 208.3391\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 101s 3s/step - loss: 1210.5096 - val_loss: 128.7360\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 102s 3s/step - loss: 1001.6103 - val_loss: 103.6354\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 110s 3s/step - loss: 1023.5320 - val_loss: 87.9682\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 112s 3s/step - loss: 932.1886 - val_loss: 78.6424\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 102s 3s/step - loss: 928.5117 - val_loss: 83.9954\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 107s 3s/step - loss: 892.9949 - val_loss: 80.6271\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 120s 3s/step - loss: 651.5164 - val_loss: 7.6757\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 104s 3s/step - loss: 28.3556 - val_loss: 7.6551\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 97s 2s/step - loss: 28.4223 - val_loss: 7.7265\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 114s 3s/step - loss: 28.1806 - val_loss: 7.5498\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 111s 3s/step - loss: 28.1088 - val_loss: 7.7321\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 97s 2s/step - loss: 28.0939 - val_loss: 7.8585\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 98s 3s/step - loss: 28.0217 - val_loss: 7.5766\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 113s 3s/step - loss: 638.9413 - val_loss: 7.9479\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 102s 3s/step - loss: 28.5239 - val_loss: 7.7155\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 116s 3s/step - loss: 28.2430 - val_loss: 7.3136\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 102s 3s/step - loss: 28.2882 - val_loss: 7.4797\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 116s 3s/step - loss: 28.0379 - val_loss: 8.0095\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 116s 3s/step - loss: 26.7612 - val_loss: 7.4532\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 117s 3s/step - loss: 25.5009 - val_loss: 7.2748\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 120s 3s/step - loss: 956.4742 - val_loss: 76.9838\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 102s 3s/step - loss: 804.4992 - val_loss: 66.1264\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 90s 2s/step - loss: 682.8707 - val_loss: 61.9750\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 85s 2s/step - loss: 619.2038 - val_loss: 58.4503\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 545.6718 - val_loss: 49.9533\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 535.8405 - val_loss: 45.4745\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 465.5863 - val_loss: 46.3007\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 30s 765ms/step - loss: 1425.1984 - val_loss: 7.6949\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 28.5119 - val_loss: 8.0255\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.5618 - val_loss: 7.9798\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5055 - val_loss: 7.8430\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.5153 - val_loss: 7.9422\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.4345 - val_loss: 7.5714\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.4593 - val_loss: 7.7800\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 1193.7894 - val_loss: 7.9896\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.4190 - val_loss: 7.9922\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 28.4155 - val_loss: 7.6356\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 28.4458 - val_loss: 7.8671\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.2069 - val_loss: 7.6993\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 27.9320 - val_loss: 7.3658\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 27.0616 - val_loss: 7.3995\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 1045.5258 - val_loss: 78.0974\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 822.3599 - val_loss: 75.1212\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 767.0147 - val_loss: 53.8099\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 660.0013 - val_loss: 56.0627\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 370ms/step - loss: 563.7063 - val_loss: 53.2429\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 501.3810 - val_loss: 47.2271\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 437.9416 - val_loss: 43.6673\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 497ms/step - loss: 1776.2124 - val_loss: 278.6746\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 1447.5895 - val_loss: 217.9062\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 1290.9892 - val_loss: 163.7175\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1193.9511 - val_loss: 151.1220\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 1042.6568 - val_loss: 119.7639\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1042.8563 - val_loss: 117.5730\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 986.8127 - val_loss: 104.8536\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 508ms/step - loss: 512.3696 - val_loss: 23.5878\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 50.9454 - val_loss: 8.3959\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 375ms/step - loss: 30.2738 - val_loss: 7.4620\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 26.2440 - val_loss: 7.4285\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 15s 379ms/step - loss: 25.2946 - val_loss: 7.6308\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 23.1727 - val_loss: 7.2646\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 20.2894 - val_loss: 6.7783\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 786.5012 - val_loss: 54.2311\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 461.0552 - val_loss: 34.7452\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 265.8643 - val_loss: 25.8397\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 183.7721 - val_loss: 19.8511\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 137.1567 - val_loss: 16.5860\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 92.3532 - val_loss: 15.8448\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 78.9449 - val_loss: 12.8246\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 508ms/step - loss: 467.1959 - val_loss: 21.7303\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 48.8409 - val_loss: 9.4176\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 31.2127 - val_loss: 8.1412\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 26.8829 - val_loss: 7.9495\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 25.0090 - val_loss: 7.5735\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 23.4612 - val_loss: 7.3903\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 21.2430 - val_loss: 6.6896\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 492ms/step - loss: 1097.7631 - val_loss: 7.9085\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 28.4169 - val_loss: 8.0909\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.5566 - val_loss: 7.9363\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 28.5618 - val_loss: 7.5633\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.4979 - val_loss: 7.9041\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 28.4964 - val_loss: 7.7754\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 28.5391 - val_loss: 7.8589\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 508ms/step - loss: 885.2908 - val_loss: 83.8567\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 800.5345 - val_loss: 71.2261\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 702.8783 - val_loss: 65.5493\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 656.2297 - val_loss: 61.2794\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 622.9213 - val_loss: 57.7908\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 546.3976 - val_loss: 52.5775\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 515.8020 - val_loss: 49.3738\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 513ms/step - loss: 1188.2075 - val_loss: 129.7875\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 377ms/step - loss: 1182.2924 - val_loss: 110.6324\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 1140.3108 - val_loss: 99.5566\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 1030.8267 - val_loss: 99.3371\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 372ms/step - loss: 1033.5075 - val_loss: 91.8445\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 967.8805 - val_loss: 87.2022\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 1006.3420 - val_loss: 86.5880\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 3084.4506 - val_loss: 8.0091\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 28.5134 - val_loss: 8.0945\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 28.6584 - val_loss: 8.1685\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 28.5657 - val_loss: 7.7481\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 28.5716 - val_loss: 7.7195\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.5826 - val_loss: 7.7265\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.4061 - val_loss: 7.6049\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 1284.7636 - val_loss: 112.8606\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 946.2948 - val_loss: 79.4979\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 822.4621 - val_loss: 77.7141\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 796.5375 - val_loss: 73.7051\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 777.6356 - val_loss: 67.0264\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 763.6502 - val_loss: 64.0279\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 684.9859 - val_loss: 60.8116\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 1341.4796 - val_loss: 7.5895\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.5377 - val_loss: 7.9351\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 28.5537 - val_loss: 7.7833\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 28.5609 - val_loss: 7.4972\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 28.5672 - val_loss: 8.0112\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 28.5497 - val_loss: 7.7457\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 28.5433 - val_loss: 7.7603\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 484ms/step - loss: 1290.0396 - val_loss: 132.4023\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 954.9214 - val_loss: 103.7474\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 908.8309 - val_loss: 94.7479\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 823.0575 - val_loss: 87.4026\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 835.6199 - val_loss: 82.7672\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 841.4276 - val_loss: 80.2631\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 764.3736 - val_loss: 79.0895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "39/39 [==============================] - 18s 474ms/step - loss: 1220.1964 - val_loss: 125.8741\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 1032.5008 - val_loss: 113.7945\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 1045.9808 - val_loss: 107.5294\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 1023.7381 - val_loss: 99.0454\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 1048.8645 - val_loss: 102.0623\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 986.6292 - val_loss: 101.1661\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 1038.7692 - val_loss: 99.2473\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 483ms/step - loss: 483.6513 - val_loss: 14.4981\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 42.0153 - val_loss: 7.7618\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 29.9893 - val_loss: 7.6232\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 26.2975 - val_loss: 7.3234\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 12s 296ms/step - loss: 24.8150 - val_loss: 7.0047\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 23.2761 - val_loss: 6.6402\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 22.1211 - val_loss: 6.0954\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 509ms/step - loss: 944.4162 - val_loss: 71.9588\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 871.8579 - val_loss: 59.0973\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 734.2849 - val_loss: 56.4992\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 679.0502 - val_loss: 50.8379\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 643.6909 - val_loss: 47.4116\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 582.9460 - val_loss: 42.9949\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 555.2722 - val_loss: 39.5411\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 1055.3800 - val_loss: 78.7134\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 745.4725 - val_loss: 60.2519\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 678.9371 - val_loss: 58.7830\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 533.2383 - val_loss: 54.2309\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 492.6010 - val_loss: 44.9854\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 427.3290 - val_loss: 39.9115\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 363.5426 - val_loss: 36.0844\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 510ms/step - loss: 712.7600 - val_loss: 7.8820\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 28.5307 - val_loss: 7.4857\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 28.1735 - val_loss: 7.9019\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 28.0304 - val_loss: 7.5811\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 27.5883 - val_loss: 7.5458\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 26.4620 - val_loss: 7.4042\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 24.6637 - val_loss: 6.6947\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 614.8387 - val_loss: 53.0471\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 191.8166 - val_loss: 20.3065\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 83.6135 - val_loss: 13.9294\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 15s 383ms/step - loss: 53.9888 - val_loss: 10.8475\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 40.5882 - val_loss: 9.4545\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 32.7896 - val_loss: 8.3569\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 29.1713 - val_loss: 8.2490\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 430.8057 - val_loss: 11.2223\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 36.3811 - val_loss: 8.4938\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 28.3703 - val_loss: 7.6945\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 25.2946 - val_loss: 7.2553\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 22.1039 - val_loss: 6.9665\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 20.9328 - val_loss: 6.2400\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 15s 384ms/step - loss: 18.8856 - val_loss: 6.1378\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 507ms/step - loss: 888.6389 - val_loss: 58.6621\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 467.4857 - val_loss: 37.7007\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 263.5880 - val_loss: 28.1589\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 15s 382ms/step - loss: 178.9671 - val_loss: 21.3031\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 134.2847 - val_loss: 17.4508\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 99.2660 - val_loss: 14.8478\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 70.0254 - val_loss: 13.1098\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 519ms/step - loss: 415.0717 - val_loss: 11.6142\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 31.4040 - val_loss: 7.6553\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.6430 - val_loss: 7.5045\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 27.2574 - val_loss: 7.5340\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 25.6470 - val_loss: 7.6223\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 24.8499 - val_loss: 7.1891\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 22.9767 - val_loss: 6.9899\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 516ms/step - loss: 772.5331 - val_loss: 74.6552\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 536.7280 - val_loss: 53.6344\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 394.4422 - val_loss: 39.1957\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 286.2740 - val_loss: 30.7917\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 213.2629 - val_loss: 24.3728\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 169.0958 - val_loss: 20.9559\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 140.6334 - val_loss: 19.5974\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 496ms/step - loss: 688.9919 - val_loss: 50.8591\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 209.8606 - val_loss: 28.5086\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 375ms/step - loss: 96.1901 - val_loss: 13.8835\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 60.0958 - val_loss: 11.1738\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 40.5436 - val_loss: 9.9359\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 33.2000 - val_loss: 8.5468\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 30.0118 - val_loss: 8.1569\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 513ms/step - loss: 659.5711 - val_loss: 37.7385\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 163.1726 - val_loss: 15.3055\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 375ms/step - loss: 70.3918 - val_loss: 10.9375\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 368ms/step - loss: 46.1725 - val_loss: 8.7400\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 34.9078 - val_loss: 7.7566\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 29.9900 - val_loss: 7.2636\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 26.6997 - val_loss: 6.9860\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 1137.0870 - val_loss: 137.2997\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 1084.9334 - val_loss: 121.8376\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 1033.3125 - val_loss: 109.2005\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 1031.6622 - val_loss: 102.0989\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 990.1347 - val_loss: 96.5325\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 953.4959 - val_loss: 95.4281\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 346ms/step - loss: 933.8027 - val_loss: 97.0764\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 488ms/step - loss: 6536.6328 - val_loss: 8.8400\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 29.2578 - val_loss: 7.8625\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 29.0203 - val_loss: 8.0564\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 28.8203 - val_loss: 8.0230\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.8091 - val_loss: 7.6754\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.7007 - val_loss: 7.7062\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 28.6295 - val_loss: 7.6402\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 971.5859 - val_loss: 92.5561\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 847.9358 - val_loss: 84.3811\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 807.4684 - val_loss: 76.0207\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 757.3012 - val_loss: 77.7170\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 717.9927 - val_loss: 73.7242\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 701.4138 - val_loss: 68.4257\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 619.8577 - val_loss: 65.9623\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 499ms/step - loss: 1035.5218 - val_loss: 75.1067\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 822.7926 - val_loss: 64.1419\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 719.6153 - val_loss: 50.3775\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 634.2783 - val_loss: 49.8119\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 526.7138 - val_loss: 47.2366\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 510.1454 - val_loss: 38.4572\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 423.1560 - val_loss: 39.9082\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 646.7011 - val_loss: 47.9386\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 230.8605 - val_loss: 24.7952\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 106.9606 - val_loss: 16.6445\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 64.2736 - val_loss: 11.8379\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 46.9001 - val_loss: 10.4404\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 37.4750 - val_loss: 9.3983\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 30.9107 - val_loss: 8.4732\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 495ms/step - loss: 948.5393 - val_loss: 67.6561\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 679.4879 - val_loss: 64.3611\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 498.7835 - val_loss: 50.1598\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 375.2446 - val_loss: 36.3792\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 318.8892 - val_loss: 36.6940\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 258.2817 - val_loss: 28.8885\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 350ms/step - loss: 210.1695 - val_loss: 25.8348\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 19s 498ms/step - loss: 611.6476 - val_loss: 7.9106\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 18s 468ms/step - loss: 28.7079 - val_loss: 7.7441\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 28.6829 - val_loss: 7.6713\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 28.4278 - val_loss: 7.7861\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 28.2998 - val_loss: 7.7602\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 28.2936 - val_loss: 8.1015\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 27.8648 - val_loss: 7.6550\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 20s 504ms/step - loss: 1251.6262 - val_loss: 171.2274\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1109.6182 - val_loss: 144.0089\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 1226.9694 - val_loss: 128.3434\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1105.3698 - val_loss: 108.6475\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 1051.5091 - val_loss: 110.5373\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 1024.0046 - val_loss: 107.0979\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 11s 293ms/step - loss: 939.2605 - val_loss: 100.3136\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 1714.1855 - val_loss: 230.0679\n",
      "Epoch 2/7\n",
      "39/39 [==============================] - 11s 287ms/step - loss: 1453.3887 - val_loss: 173.8403\n",
      "Epoch 3/7\n",
      "39/39 [==============================] - 11s 294ms/step - loss: 1263.9917 - val_loss: 145.3439\n",
      "Epoch 4/7\n",
      "39/39 [==============================] - 11s 288ms/step - loss: 1134.4664 - val_loss: 117.6839\n",
      "Epoch 5/7\n",
      "39/39 [==============================] - 11s 287ms/step - loss: 1076.8956 - val_loss: 101.0689\n",
      "Epoch 6/7\n",
      "39/39 [==============================] - 11s 288ms/step - loss: 1027.5923 - val_loss: 88.9030\n",
      "Epoch 7/7\n",
      "39/39 [==============================] - 11s 286ms/step - loss: 938.4931 - val_loss: 82.6320\n",
      "Epoch 1/7\n",
      "39/39 [==============================] - 16s 398ms/step - loss: 606.5933 - val_loss: 26.8911\n",
      "Epoch 2/7\n",
      " 6/39 [===>..........................] - ETA: 9s - loss: 175.3329 "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 7\n",
    "\n",
    "# hyperparameter tuning\n",
    "\n",
    "lr_dict = {}\n",
    "best_lr = 0\n",
    "best_loss = np.inf\n",
    "\n",
    "for lr in 10 ** np.random.uniform(-6, -2, 1000):\n",
    "    # input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[5,5], strides=2, padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=2)(x)\n",
    "\n",
    "    x = ResLayer(x, 32)\n",
    "    x = ResLayer(x, 64)\n",
    "    x = ResLayer(x, 128)\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(2)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    #odel.summary()\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(lr=lr),\n",
    "                  )\n",
    "\n",
    "    hist = model.fit_generator(generator=training_generator,\n",
    "                               validation_data=validation_generator,\n",
    "                               use_multiprocessing=False,\n",
    "                               epochs=epochs,\n",
    "                               callbacks=[history],\n",
    "                               )\n",
    "    loss = hist.history['val_loss'][-1]\n",
    "    lr_dict[lr] = loss\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_lr = lr\n",
    "        best_loss = loss\n",
    "        print(\"lr: \", lr, \"loss: \", loss)\n",
    "        \n",
    "    if K.backend() == 'tensorflow':\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009508087977693204\n",
      "2.9634355306625366\n"
     ]
    }
   ],
   "source": [
    "#print(lr_dict.items())\n",
    "print(best_lr)\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1671/1671 [==============================] - 5649s 3s/step - loss: 116530160.4651 - mean_mse: 8179.6774 - val_loss: 115.8147 - val_mean_mse: 0.0927\n",
      "Epoch 2/10\n",
      "1671/1671 [==============================] - 5785s 3s/step - loss: 1292.6003 - mean_mse: 0.0963 - val_loss: 110.9730 - val_mean_mse: 0.0888\n",
      "Epoch 3/10\n",
      "1671/1671 [==============================] - 5680s 3s/step - loss: 1229.8088 - mean_mse: 0.0917 - val_loss: 110.0499 - val_mean_mse: 0.0879\n",
      "Epoch 4/10\n",
      "1671/1671 [==============================] - 5608s 3s/step - loss: 1206.3686 - mean_mse: 0.0900 - val_loss: 109.6012 - val_mean_mse: 0.0875\n",
      "Epoch 5/10\n",
      "1671/1671 [==============================] - 5555s 3s/step - loss: 1196.2886 - mean_mse: 0.0893 - val_loss: 109.2794 - val_mean_mse: 0.0873\n",
      "Epoch 6/10\n",
      "1671/1671 [==============================] - 5537s 3s/step - loss: 1190.4537 - mean_mse: 0.0888 - val_loss: 109.2516 - val_mean_mse: 0.0872\n",
      "Epoch 7/10\n",
      "1671/1671 [==============================] - 5534s 3s/step - loss: 1188.9917 - mean_mse: 0.0888 - val_loss: 109.1572 - val_mean_mse: 0.0871\n",
      "Epoch 8/10\n",
      "1671/1671 [==============================] - 5526s 3s/step - loss: 1188.1620 - mean_mse: 0.0887 - val_loss: 109.3090 - val_mean_mse: 0.0872\n",
      "Epoch 9/10\n",
      "1671/1671 [==============================] - 5517s 3s/step - loss: 1189.9725 - mean_mse: 0.0888 - val_loss: 109.9725 - val_mean_mse: 0.0878\n",
      "Epoch 10/10\n",
      "1671/1671 [==============================] - 5518s 3s/step - loss: 1191.3571 - mean_mse: 0.0889 - val_loss: 110.0648 - val_mean_mse: 0.0879\n"
     ]
    }
   ],
   "source": [
    "# actual model fitting using tuned hyperparameters\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 0.0015\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=lr),\n",
    "              metrics=[mean_mse]\n",
    "              )\n",
    "\n",
    "hist = model.fit_generator(generator=training_generator,\n",
    "                           validation_data=validation_generator,\n",
    "                           use_multiprocessing=False,\n",
    "                           epochs=epochs,\n",
    "                           callbacks=[history],\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# making annotations on validation data\n",
    "\n",
    "#image_num = validation_labels[1] - validation_labels[0]\n",
    "image_num = 100\n",
    "images = np.zeros((image_num, input_shape[0], input_shape[1], input_shape[2]))\n",
    "for i in range(image_num):\n",
    "    img = preprocess.load_img(path + str(i+validation_labels[0])+'.png')\n",
    "    img_array = preprocess.img_to_array(img)\n",
    "    images[i] = img_array\n",
    "    \n",
    "# preprocessing images (range from 0 to 1)\n",
    "images /= 255.0\n",
    "\n",
    "\n",
    "x_pred = images\n",
    "y_pred = labels[validation_labels[0]:validation_labels[0]+image_num]\n",
    "preds = model.predict(x_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [153. 103.]\n",
      " [153. 103.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 103.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [154. 103.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [153. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [153. 103.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [153. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [151. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]]\n"
     ]
    }
   ],
   "source": [
    "preds[:,0] = preds[:,0]*150 + 150\n",
    "preds[:,1] = preds[:,1]*-100 + 100\n",
    "preds = np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.  79.] [152. 102.] [-34. -23.]\n",
      "[122.  78.] [152. 102.] [-30. -24.]\n",
      "[143. 139.] [152. 102.] [-9. 37.]\n",
      "[127. 100.] [152. 102.] [-25.  -2.]\n",
      "[159. 109.] [152. 102.] [7. 7.]\n",
      "[159.  81.] [152. 102.] [  7. -21.]\n",
      "[170. 105.] [152. 102.] [18.  3.]\n",
      "[143.  90.] [153. 103.] [-10. -13.]\n",
      "[226. 127.] [153. 103.] [73. 24.]\n",
      "[122. 130.] [152. 102.] [-30.  28.]\n",
      "[ 88. 132.] [152. 102.] [-64.  30.]\n",
      "[130.  65.] [152. 102.] [-22. -37.]\n",
      "[157.  82.] [152. 102.] [  5. -20.]\n",
      "[155.  97.] [152. 102.] [ 3. -5.]\n",
      "[142. 122.] [152. 102.] [-10.  20.]\n",
      "[176.  98.] [152. 102.] [24. -4.]\n",
      "[186.  99.] [152. 102.] [34. -3.]\n",
      "[213.  70.] [152. 102.] [ 61. -32.]\n",
      "[189.  94.] [152. 102.] [37. -8.]\n",
      "[140.  85.] [152. 102.] [-12. -17.]\n",
      "[155.  72.] [152. 102.] [  3. -30.]\n",
      "[126.  77.] [152. 102.] [-26. -25.]\n",
      "[145.  97.] [152. 103.] [-7. -6.]\n",
      "[179.  92.] [152. 102.] [ 27. -10.]\n",
      "[187. 111.] [152. 102.] [35.  9.]\n",
      "[132.  83.] [152. 102.] [-20. -19.]\n",
      "[162.  97.] [152. 102.] [10. -5.]\n",
      "[165. 104.] [152. 102.] [13.  2.]\n",
      "[135.  75.] [152. 102.] [-17. -27.]\n",
      "[118.  94.] [152. 102.] [-34.  -8.]\n",
      "[131.  63.] [152. 102.] [-21. -39.]\n",
      "[170.  82.] [152. 102.] [ 18. -20.]\n",
      "[160.  76.] [152. 102.] [  8. -26.]\n",
      "[195.  90.] [152. 102.] [ 43. -12.]\n",
      "[157. 149.] [152. 102.] [ 5. 47.]\n",
      "[161.  69.] [152. 102.] [  9. -33.]\n",
      "[137. 132.] [152. 102.] [-15.  30.]\n",
      "[175.  81.] [152. 102.] [ 23. -21.]\n",
      "[151. 116.] [152. 102.] [-1. 14.]\n",
      "[150.  72.] [152. 102.] [ -2. -30.]\n",
      "[164. 107.] [152. 102.] [12.  5.]\n",
      "[126. 155.] [152. 102.] [-26.  53.]\n",
      "[171. 117.] [152. 102.] [19. 15.]\n",
      "[153. 111.] [152. 102.] [1. 9.]\n",
      "[166.  88.] [152. 102.] [ 14. -14.]\n",
      "[121. 127.] [152. 102.] [-31.  25.]\n",
      "[187.  89.] [152. 102.] [ 35. -13.]\n",
      "[151. 127.] [152. 102.] [-1. 25.]\n",
      "[122. 131.] [152. 102.] [-30.  29.]\n",
      "[108. 119.] [154. 103.] [-46.  16.]\n",
      "[124. 126.] [152. 102.] [-28.  24.]\n",
      "[159. 109.] [152. 102.] [7. 7.]\n",
      "[110. 151.] [152. 102.] [-42.  49.]\n",
      "[142.  71.] [152. 102.] [-10. -31.]\n",
      "[168. 124.] [152. 102.] [16. 22.]\n",
      "[107.  73.] [152. 102.] [-45. -29.]\n",
      "[150. 107.] [152. 102.] [-2.  5.]\n",
      "[210.  65.] [152. 102.] [ 58. -37.]\n",
      "[84. 97.] [152. 102.] [-68.  -5.]\n",
      "[136. 119.] [153. 102.] [-17.  17.]\n",
      "[161. 119.] [152. 102.] [ 9. 17.]\n",
      "[112.  90.] [152. 102.] [-40. -12.]\n",
      "[141. 118.] [153. 103.] [-12.  15.]\n",
      "[110. 106.] [152. 102.] [-42.   4.]\n",
      "[187.  83.] [152. 102.] [ 35. -19.]\n",
      "[115. 140.] [152. 102.] [-37.  38.]\n",
      "[118.  86.] [152. 102.] [-34. -16.]\n",
      "[118.  87.] [152. 102.] [-34. -15.]\n",
      "[171. 105.] [152. 102.] [19.  3.]\n",
      "[140. 102.] [152. 102.] [-12.   0.]\n",
      "[140. 141.] [152. 102.] [-12.  39.]\n",
      "[128. 109.] [152. 102.] [-24.   7.]\n",
      "[169.  96.] [152. 102.] [17. -6.]\n",
      "[130. 152.] [152. 102.] [-22.  50.]\n",
      "[147. 104.] [152. 102.] [-5.  2.]\n",
      "[133. 116.] [152. 102.] [-19.  14.]\n",
      "[175.  93.] [152. 102.] [23. -9.]\n",
      "[125. 105.] [152. 102.] [-27.   3.]\n",
      "[129. 132.] [152. 102.] [-23.  30.]\n",
      "[164. 117.] [152. 102.] [12. 15.]\n",
      "[179.  73.] [152. 102.] [ 27. -29.]\n",
      "[139.  58.] [153. 102.] [-14. -44.]\n",
      "[166.  66.] [152. 102.] [ 14. -36.]\n",
      "[193.  76.] [152. 102.] [ 41. -26.]\n",
      "[178. 110.] [152. 102.] [26.  8.]\n",
      "[150.  76.] [152. 102.] [ -2. -26.]\n",
      "[118. 105.] [152. 102.] [-34.   3.]\n",
      "[159. 121.] [152. 102.] [ 7. 19.]\n",
      "[104. 105.] [152. 102.] [-48.   3.]\n",
      "[136. 130.] [152. 102.] [-16.  28.]\n",
      "[115. 128.] [152. 102.] [-37.  26.]\n",
      "[141.  80.] [152. 102.] [-11. -22.]\n",
      "[166.  77.] [152. 102.] [ 14. -25.]\n",
      "[153.  71.] [152. 102.] [  1. -31.]\n",
      "[134.  84.] [152. 102.] [-18. -18.]\n",
      "[159.  49.] [152. 102.] [  7. -53.]\n",
      "[176. 117.] [151. 102.] [25. 15.]\n",
      "[117.  84.] [152. 102.] [-35. -18.]\n",
      "[161.  76.] [152. 102.] [  9. -26.]\n",
      "[177.  83.] [152. 102.] [ 25. -19.]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "for i in range(validation_labels[0],validation_labels[0]+image_num):\n",
    "    img = Image.open(path + str(i)+'.png')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    pred = preds[i-validation_labels[0]]\n",
    "    \n",
    "    draw.line([tuple(pred - [10, 0]), tuple(pred + [10, 0])], fill=\"blue\", width=3)\n",
    "    draw.line([tuple(pred - [0, 10]), tuple(pred + [0, 10])], fill=\"red\", width=3)\n",
    "\n",
    "#    draw.point(labels_orig[i], fill=\"blue\")\n",
    "#    draw.point(preds[i-15840], fill=\"black\")\n",
    "    print(labels_orig[i], pred, labels_orig[i]- pred)\n",
    "    img.save(path + \"preds_cpu/\" + str(i) + \"_pred.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on test data\n",
    "\n",
    "test_image_num = 4500\n",
    "\n",
    "test_images = np.zeros((test_image_num, input_shape[0], input_shape[1], input_shape[2]))\n",
    "for i in range(test_image_num):\n",
    "    img = preprocess.load_img(path + \"test/\" + str(i)+'.png')\n",
    "    img_array = preprocess.img_to_array(img)\n",
    "    test_images[i] = img_array\n",
    "    \n",
    "# preprocessing images (range from 0 to 1)\n",
    "test_images /= 255.0\n",
    "\n",
    "\n",
    "test_x_pred = test_images\n",
    "\n",
    "\n",
    "# importing test labels\n",
    "f = open(path + \"test/\" + 'labels.txt', 'r')\n",
    "test_labels = f.readlines()\n",
    "test_labels = [eval(x.strip()) for x in test_labels]\n",
    "\n",
    "# change labels to range from 0-num of pixels\n",
    "test_labels = [(x[0] * 300, x[1] * 200) for x in test_labels]\n",
    "\n",
    "test_y_pred = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 194s 43ms/step\n",
      "[[152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " ...\n",
      " [152. 102.]\n",
      " [152. 102.]\n",
      " [152. 102.]]\n"
     ]
    }
   ],
   "source": [
    "# making predictions on test data\n",
    "test_preds = model.predict(test_x_pred, verbose=1)\n",
    "\n",
    "# converting to pixel locations\n",
    "test_preds[:,0] = test_preds[:,0]*150 + 150\n",
    "test_preds[:,1] = test_preds[:,1]*-100 + 100\n",
    "test_preds = np.round(test_preds)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating and printing results on test data\n",
    "test_results = model.evaluate(x=test_x_pred, y=test_y_pred)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106.  50.] [104. 138.] [  2. -88.]\n",
      "[156. 115.] [154.  93.] [ 2. 22.]\n",
      "[127. 114.] [123.  94.] [ 4. 20.]\n",
      "[124.  68.] [121. 111.] [  3. -43.]\n",
      "[164.  83.] [154. 100.] [ 10. -17.]\n",
      "[153.  63.] [153. 131.] [  0. -68.]\n",
      "[163.  69.] [148. 124.] [ 15. -55.]\n",
      "[132.  90.] [159. 117.] [-27. -27.]\n",
      "[198. 102.] [166.  97.] [32.  5.]\n",
      "[132.  66.] [143. 114.] [-11. -48.]\n",
      "[116.  80.] [146. 106.] [-30. -26.]\n",
      "[133. 101.] [142. 101.] [-9.  0.]\n",
      "[193. 125.] [181.  94.] [12. 31.]\n",
      "[141.  96.] [126. 101.] [15. -5.]\n",
      "[137.  82.] [141. 118.] [ -4. -36.]\n",
      "[115.  79.] [128. 105.] [-13. -26.]\n",
      "[195.  71.] [184. 123.] [ 11. -52.]\n",
      "[97. 64.] [117. 125.] [-20. -61.]\n",
      "[163. 152.] [150.  73.] [13. 79.]\n",
      "[165.  85.] [153. 109.] [ 12. -24.]\n",
      "[140. 100.] [116. 102.] [24. -2.]\n",
      "[145.  71.] [137. 116.] [  8. -45.]\n",
      "[ 89. 100.] [117. 106.] [-28.  -6.]\n",
      "[166.  90.] [162. 102.] [  4. -12.]\n",
      "[130. 156.] [117.  59.] [13. 97.]\n",
      "[148.  82.] [149. 112.] [ -1. -30.]\n",
      "[122. 128.] [122.  74.] [ 0. 54.]\n",
      "[79. 84.] [ 91. 120.] [-12. -36.]\n",
      "[137.  76.] [135. 110.] [  2. -34.]\n",
      "[190.  86.] [181. 122.] [  9. -36.]\n",
      "[173. 100.] [244. 122.] [-71. -22.]\n",
      "[151. 109.] [158.  95.] [-7. 14.]\n",
      "[169. 111.] [152.  96.] [17. 15.]\n",
      "[140.  61.] [149. 109.] [ -9. -48.]\n",
      "[104. 100.] [49. 72.] [55. 28.]\n",
      "[166. 100.] [157. 103.] [ 9. -3.]\n",
      "[156. 112.] [145.  98.] [11. 14.]\n",
      "[175. 128.] [203.  59.] [-28.  69.]\n",
      "[202.  54.] [160. 103.] [ 42. -49.]\n",
      "[154.  89.] [139.  96.] [15. -7.]\n",
      "[157.  95.] [149.  98.] [ 8. -3.]\n",
      "[142.  67.] [153. 106.] [-11. -39.]\n",
      "[151.  99.] [152. 100.] [-1. -1.]\n",
      "[74. 59.] [ 82. 117.] [ -8. -58.]\n",
      "[155. 100.] [149.  99.] [6. 1.]\n",
      "[145. 124.] [148.  49.] [-3. 75.]\n",
      "[150.  79.] [147. 109.] [  3. -30.]\n",
      "[155. 114.] [148.  77.] [ 7. 37.]\n",
      "[170. 144.] [148.  40.] [ 22. 104.]\n",
      "[134. 143.] [145.  69.] [-11.  74.]\n",
      "[188.  91.] [192. 116.] [ -4. -25.]\n",
      "[96. 79.] [124. 120.] [-28. -41.]\n",
      "[198. 113.] [181.  55.] [17. 58.]\n",
      "[124. 138.] [149.  45.] [-25.  93.]\n",
      "[209. 111.] [175.  90.] [34. 21.]\n",
      "[176.  72.] [156. 111.] [ 20. -39.]\n",
      "[152.  96.] [152. 132.] [  0. -36.]\n",
      "[131. 137.] [154.  60.] [-23.  77.]\n",
      "[101.  76.] [145. 104.] [-44. -28.]\n",
      "[96. 90.] [135. 104.] [-39. -14.]\n",
      "[139. 137.] [143.  73.] [-4. 64.]\n",
      "[113.  67.] [123. 120.] [-10. -53.]\n",
      "[162.  81.] [145. 112.] [ 17. -31.]\n",
      "[154. 125.] [156.  79.] [-2. 46.]\n",
      "[112. 125.] [139.  68.] [-27.  57.]\n",
      "[149.  51.] [147. 122.] [  2. -71.]\n",
      "[149. 156.] [151.  69.] [-2. 87.]\n",
      "[163. 131.] [147.  64.] [16. 67.]\n",
      "[140.  87.] [125. 111.] [ 15. -24.]\n",
      "[150. 112.] [150.  87.] [ 0. 25.]\n",
      "[109.  96.] [135. 108.] [-26. -12.]\n",
      "[158. 130.] [185.  47.] [-27.  83.]\n",
      "[ 75. 114.] [95. 82.] [-20.  32.]\n",
      "[225. 109.] [180.  88.] [45. 21.]\n",
      "[162.  71.] [163. 114.] [ -1. -43.]\n",
      "[179.  97.] [152.  96.] [27.  1.]\n",
      "[130. 104.] [141. 104.] [-11.   0.]\n",
      "[182.  79.] [155. 101.] [ 27. -22.]\n",
      "[168. 125.] [188.  63.] [-20.  62.]\n",
      "[127. 100.] [141. 101.] [-14.  -1.]\n",
      "[159. 107.] [164. 100.] [-5.  7.]\n",
      "[152. 108.] [155.  85.] [-3. 23.]\n",
      "[190. 142.] [151.  60.] [39. 82.]\n",
      "[83. 80.] [ 71. 138.] [ 12. -58.]\n",
      "[108.  80.] [109. 114.] [ -1. -34.]\n",
      "[111. 143.] [116.  65.] [-5. 78.]\n",
      "[112.  72.] [142. 112.] [-30. -40.]\n",
      "[136.  67.] [132. 115.] [  4. -48.]\n",
      "[170. 105.] [154. 100.] [16.  5.]\n",
      "[ 86. 132.] [113.  65.] [-27.  67.]\n",
      "[137. 113.] [146.  97.] [-9. 16.]\n",
      "[159.  96.] [148.  99.] [11. -3.]\n",
      "[105. 126.] [137.  92.] [-32.  34.]\n",
      "[209. 142.] [181.  74.] [28. 68.]\n",
      "[132.  99.] [151. 109.] [-19. -10.]\n",
      "[151. 106.] [170.  91.] [-19.  15.]\n",
      "[187. 128.] [165.  86.] [22. 42.]\n",
      "[140.  71.] [125. 123.] [ 15. -52.]\n",
      "[184. 106.] [166.  77.] [18. 29.]\n",
      "[135.  53.] [145. 108.] [-10. -55.]\n",
      "[161. 108.] [189. 108.] [-28.   0.]\n",
      "[87. 83.] [148. 101.] [-61. -18.]\n",
      "[202. 132.] [151.  98.] [51. 34.]\n",
      "[128. 108.] [101.  74.] [27. 34.]\n",
      "[166.  64.] [183. 147.] [-17. -83.]\n",
      "[112.  97.] [131.  85.] [-19.  12.]\n",
      "[167.  69.] [166. 130.] [  1. -61.]\n",
      "[154. 107.] [155.  97.] [-1. 10.]\n",
      "[139.  63.] [152. 159.] [-13. -96.]\n",
      "[167. 146.] [145.  87.] [22. 59.]\n",
      "[144.  88.] [150. 100.] [ -6. -12.]\n",
      "[171.  77.] [185. 190.] [ -14. -113.]\n",
      "[106.  78.] [114. 121.] [ -8. -43.]\n",
      "[166. 126.] [158.  91.] [ 8. 35.]\n",
      "[186.  58.] [155. 125.] [ 31. -67.]\n",
      "[162. 135.] [155.  60.] [ 7. 75.]\n",
      "[152.  72.] [176. 162.] [-24. -90.]\n",
      "[101. 105.] [123.  85.] [-22.  20.]\n",
      "[178. 135.] [179.  67.] [-1. 68.]\n",
      "[139.  82.] [130.  95.] [  9. -13.]\n",
      "[171.  84.] [168. 118.] [  3. -34.]\n",
      "[121.  68.] [115. 182.] [   6. -114.]\n",
      "[177.  89.] [166. 104.] [ 11. -15.]\n",
      "[218.  97.] [165.  95.] [53.  2.]\n",
      "[191.  85.] [170. 107.] [ 21. -22.]\n",
      "[146. 126.] [145.  85.] [ 1. 41.]\n",
      "[177. 138.] [156.  65.] [21. 73.]\n",
      "[146.  86.] [130. 133.] [ 16. -47.]\n",
      "[168. 120.] [182.  55.] [-14.  65.]\n",
      "[123.  51.] [125. 118.] [ -2. -67.]\n",
      "[114.  97.] [145.  98.] [-31.  -1.]\n",
      "[130.  50.] [140. 130.] [-10. -80.]\n",
      "[116. 127.] [135.  99.] [-19.  28.]\n",
      "[166. 141.] [172.  71.] [-6. 70.]\n",
      "[149. 104.] [149.  96.] [0. 8.]\n",
      "[133.  90.] [142. 121.] [ -9. -31.]\n",
      "[ 73. 102.] [ 36. 117.] [ 37. -15.]\n",
      "[133.  94.] [100. 140.] [ 33. -46.]\n",
      "[140.  96.] [149.  96.] [-9.  0.]\n",
      "[117. 133.] [143.  69.] [-26.  64.]\n",
      "[139. 124.] [147.  90.] [-8. 34.]\n",
      "[112.  94.] [126. 107.] [-14. -13.]\n",
      "[156.  47.] [140. 125.] [ 16. -78.]\n",
      "[170. 120.] [192.  79.] [-22.  41.]\n",
      "[ 70. 141.] [152. 106.] [-82.  35.]\n",
      "[154.  74.] [148. 122.] [  6. -48.]\n",
      "[172. 115.] [150. 100.] [22. 15.]\n",
      "[130. 124.] [125.  78.] [ 5. 46.]\n",
      "[179. 123.] [169.  90.] [10. 33.]\n",
      "[135.  67.] [152. 110.] [-17. -43.]\n",
      "[139.  63.] [136. 121.] [  3. -58.]\n",
      "[155.  77.] [140. 137.] [ 15. -60.]\n",
      "[101.  67.] [148. 101.] [-47. -34.]\n",
      "[167.  65.] [154. 113.] [ 13. -48.]\n",
      "[139. 123.] [127.  89.] [12. 34.]\n",
      "[230. 135.] [212.  38.] [18. 97.]\n",
      "[165. 127.] [165.  72.] [ 0. 55.]\n",
      "[179.  80.] [197. 121.] [-18. -41.]\n",
      "[158. 106.] [160. 104.] [-2.  2.]\n",
      "[154.  89.] [190. 114.] [-36. -25.]\n",
      "[161.  84.] [164. 104.] [ -3. -20.]\n",
      "[148. 143.] [157.  83.] [-9. 60.]\n",
      "[116.  69.] [146. 112.] [-30. -43.]\n",
      "[186. 114.] [196. 100.] [-10.  14.]\n",
      "[172.  90.] [160. 119.] [ 12. -29.]\n",
      "[134. 118.] [117.  66.] [17. 52.]\n",
      "[71. 57.] [113. 144.] [-42. -87.]\n",
      "[125. 119.] [108.  75.] [17. 44.]\n",
      "[197.  91.] [161.  88.] [36.  3.]\n",
      "[167. 106.] [149. 103.] [18.  3.]\n",
      "[156.  82.] [150. 100.] [  6. -18.]\n",
      "[185.  58.] [154. 104.] [ 31. -46.]\n",
      "[148.  74.] [157. 111.] [ -9. -37.]\n",
      "[121. 129.] [128.  85.] [-7. 44.]\n",
      "[106. 116.] [97. 84.] [ 9. 32.]\n",
      "[103. 120.] [121.  93.] [-18.  27.]\n",
      "[179.  84.] [154. 108.] [ 25. -24.]\n",
      "[186.  50.] [165. 152.] [  21. -102.]\n",
      "[149.  98.] [136. 110.] [ 13. -12.]\n",
      "[224.  80.] [198. 113.] [ 26. -33.]\n",
      "[116. 136.] [144.  78.] [-28.  58.]\n",
      "[147. 118.] [139.  95.] [ 8. 23.]\n",
      "[201. 102.] [219.  90.] [-18.  12.]\n",
      "[177. 113.] [163.  90.] [14. 23.]\n",
      "[135.  92.] [149. 108.] [-14. -16.]\n",
      "[154. 146.] [149.  87.] [ 5. 59.]\n",
      "[118. 151.] [147.  82.] [-29.  69.]\n",
      "[157. 107.] [155.  80.] [ 2. 27.]\n",
      "[146. 117.] [152.  98.] [-6. 19.]\n",
      "[126.  78.] [138. 121.] [-12. -43.]\n",
      "[167.  47.] [142. 135.] [ 25. -88.]\n",
      "[163. 136.] [148.  80.] [15. 56.]\n",
      "[98. 97.] [121. 106.] [-23.  -9.]\n",
      "[170. 106.] [173.  99.] [-3.  7.]\n",
      "[147. 114.] [210.  59.] [-63.  55.]\n",
      "[144. 132.] [162.  80.] [-18.  52.]\n",
      "[150.  89.] [146.  98.] [ 4. -9.]\n",
      "[136. 114.] [147.  74.] [-11.  40.]\n",
      "[127.  73.] [142. 114.] [-15. -41.]\n",
      "[130.  98.] [167. 104.] [-37.  -6.]\n",
      "[166. 113.] [147.  94.] [19. 19.]\n",
      "[165. 125.] [167.  79.] [-2. 46.]\n",
      "[105. 123.] [111.  98.] [-6. 25.]\n",
      "[182. 103.] [172.  86.] [10. 17.]\n",
      "[133. 145.] [142.  66.] [-9. 79.]\n",
      "[191. 100.] [173.  95.] [18.  5.]\n",
      "[103.  69.] [124. 151.] [-21. -82.]\n",
      "[140.  87.] [144. 103.] [ -4. -16.]\n",
      "[137. 140.] [132.  75.] [ 5. 65.]\n",
      "[180. 126.] [195.  91.] [-15.  35.]\n",
      "[147.  89.] [150. 105.] [ -3. -16.]\n",
      "[180. 145.] [182.  62.] [-2. 83.]\n",
      "[177.  70.] [167. 115.] [ 10. -45.]\n",
      "[181.  68.] [157. 102.] [ 24. -34.]\n",
      "[142.  85.] [147.  98.] [ -5. -13.]\n",
      "[170. 118.] [166.  88.] [ 4. 30.]\n",
      "[157. 101.] [195.  69.] [-38.  32.]\n",
      "[223. 123.] [199.  92.] [24. 31.]\n",
      "[156.  69.] [148. 115.] [  8. -46.]\n",
      "[150. 130.] [154.  60.] [-4. 70.]\n",
      "[187. 114.] [158.  86.] [29. 28.]\n",
      "[129. 100.] [168.  80.] [-39.  20.]\n",
      "[130. 152.] [141.  62.] [-11.  90.]\n",
      "[150. 111.] [136.  86.] [14. 25.]\n",
      "[214. 120.] [193.  78.] [21. 42.]\n",
      "[128. 142.] [144.  92.] [-16.  50.]\n",
      "[178.  97.] [183. 107.] [ -5. -10.]\n",
      "[191. 143.] [166.  56.] [25. 87.]\n",
      "[123.  76.] [135. 113.] [-12. -37.]\n",
      "[186.  75.] [194. 119.] [ -8. -44.]\n",
      "[91. 79.] [127. 108.] [-36. -29.]\n",
      "[159. 120.] [153.  80.] [ 6. 40.]\n",
      "[192. 107.] [178.  96.] [14. 11.]\n",
      "[182.  51.] [177. 140.] [  5. -89.]\n",
      "[133. 110.] [138.  94.] [-5. 16.]\n",
      "[180. 121.] [173.  86.] [ 7. 35.]\n",
      "[154. 121.] [149.  92.] [ 5. 29.]\n",
      "[135. 116.] [151.  97.] [-16.  19.]\n",
      "[ 89. 127.] [112.  89.] [-23.  38.]\n",
      "[146.  86.] [153. 118.] [ -7. -32.]\n",
      "[144. 114.] [141.  88.] [ 3. 26.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137. 141.] [131.  73.] [ 6. 68.]\n",
      "[190.  63.] [222. 140.] [-32. -77.]\n",
      "[177. 125.] [198.  52.] [-21.  73.]\n",
      "[165. 103.] [149. 112.] [16. -9.]\n",
      "[127.  85.] [129. 114.] [ -2. -29.]\n",
      "[178. 113.] [160.  95.] [18. 18.]\n",
      "[129.  99.] [112.  93.] [17.  6.]\n",
      "[116. 130.] [111.  80.] [ 5. 50.]\n",
      "[154.  55.] [152. 110.] [  2. -55.]\n",
      "[208.  80.] [180.  97.] [ 28. -17.]\n",
      "[110.  99.] [118.  98.] [-8.  1.]\n",
      "[158. 111.] [157.  90.] [ 1. 21.]\n",
      "[137. 119.] [152.  82.] [-15.  37.]\n",
      "[150. 110.] [153.  93.] [-3. 17.]\n",
      "[118. 123.] [129.  86.] [-11.  37.]\n",
      "[112. 129.] [130.  62.] [-18.  67.]\n",
      "[141. 146.] [148.  81.] [-7. 65.]\n",
      "[156.  56.] [155. 148.] [  1. -92.]\n",
      "[159. 103.] [171. 100.] [-12.   3.]\n",
      "[142. 145.] [105.  57.] [37. 88.]\n",
      "[110. 100.] [97. 73.] [13. 27.]\n",
      "[119. 131.] [157.  81.] [-38.  50.]\n",
      "[184. 116.] [197.  49.] [-13.  67.]\n",
      "[128. 133.] [131.  65.] [-3. 68.]\n",
      "[98. 99.] [ 63. 110.] [ 35. -11.]\n",
      "[161. 130.] [159.  85.] [ 2. 45.]\n",
      "[132.  84.] [130. 114.] [  2. -30.]\n",
      "[178.  81.] [150.  94.] [ 28. -13.]\n",
      "[106. 113.] [101. 116.] [ 5. -3.]\n",
      "[152.  35.] [159. 144.] [  -7. -109.]\n",
      "[146. 118.] [142.  73.] [ 4. 45.]\n",
      "[141. 141.] [145.  79.] [-4. 62.]\n",
      "[128. 119.] [120.  30.] [ 8. 89.]\n",
      "[173.  73.] [189. 130.] [-16. -57.]\n",
      "[128.  83.] [151. 105.] [-23. -22.]\n",
      "[145. 104.] [140.  97.] [5. 7.]\n",
      "[138.  95.] [140. 101.] [-2. -6.]\n",
      "[155. 131.] [157.  77.] [-2. 54.]\n",
      "[150. 135.] [132.  79.] [18. 56.]\n",
      "[162. 123.] [169.  66.] [-7. 57.]\n",
      "[162. 103.] [161. 105.] [ 1. -2.]\n",
      "[180.  92.] [186.  92.] [-6.  0.]\n",
      "[136.  63.] [143. 113.] [ -7. -50.]\n",
      "[177. 122.] [171.  79.] [ 6. 43.]\n",
      "[150.  80.] [150. 111.] [  0. -31.]\n",
      "[167.  98.] [151.  88.] [16. 10.]\n",
      "[140. 107.] [160. 102.] [-20.   5.]\n",
      "[158.  95.] [155. 101.] [ 3. -6.]\n",
      "[123.  95.] [144. 100.] [-21.  -5.]\n",
      "[117. 100.] [154. 111.] [-37. -11.]\n",
      "[148.  87.] [134. 112.] [ 14. -25.]\n",
      "[187.  68.] [187. 103.] [  0. -35.]\n",
      "[155. 103.] [157.  98.] [-2.  5.]\n",
      "[170.  60.] [162. 143.] [  8. -83.]\n",
      "[133.  94.] [157. 122.] [-24. -28.]\n",
      "[102. 106.] [131. 108.] [-29.  -2.]\n",
      "[100. 115.] [93. 62.] [ 7. 53.]\n",
      "[107. 107.] [117.  77.] [-10.  30.]\n",
      "[219.  89.] [203. 124.] [ 16. -35.]\n",
      "[130. 100.] [97. 98.] [33.  2.]\n",
      "[182.  72.] [166. 114.] [ 16. -42.]\n",
      "[122.  64.] [120. 129.] [  2. -65.]\n",
      "[152.  76.] [160. 119.] [ -8. -43.]\n",
      "[209.  86.] [176. 104.] [ 33. -18.]\n",
      "[154.  71.] [164. 129.] [-10. -58.]\n",
      "[77. 65.] [129. 147.] [-52. -82.]\n",
      "[137.  68.] [129. 102.] [  8. -34.]\n",
      "[96. 99.] [ 71. 105.] [25. -6.]\n",
      "[108. 107.] [95. 91.] [13. 16.]\n",
      "[96. 65.] [ 98. 140.] [ -2. -75.]\n",
      "[147.  98.] [139.  84.] [ 8. 14.]\n",
      "[165. 102.] [154. 102.] [11.  0.]\n",
      "[156.  62.] [156. 133.] [  0. -71.]\n",
      "[158.  80.] [145. 123.] [ 13. -43.]\n",
      "[119. 100.] [110.  76.] [ 9. 24.]\n",
      "[183. 104.] [165.  96.] [18.  8.]\n",
      "[150. 105.] [135. 107.] [15. -2.]\n",
      "[158. 141.] [157.  76.] [ 1. 65.]\n",
      "[151. 107.] [144.  91.] [ 7. 16.]\n",
      "[189.  54.] [164. 110.] [ 25. -56.]\n",
      "[ 93. 106.] [73. 84.] [20. 22.]\n",
      "[181.  85.] [173. 122.] [  8. -37.]\n",
      "[190. 128.] [187.  74.] [ 3. 54.]\n",
      "[132. 113.] [130.  80.] [ 2. 33.]\n",
      "[127. 124.] [91. 69.] [36. 55.]\n",
      "[119. 121.] [57. 60.] [62. 61.]\n",
      "[127. 108.] [148.  99.] [-21.   9.]\n",
      "[133. 130.] [146.  78.] [-13.  52.]\n",
      "[113.  79.] [143. 140.] [-30. -61.]\n",
      "[189. 125.] [173.  83.] [16. 42.]\n",
      "[135. 138.] [122.  83.] [13. 55.]\n",
      "[156. 106.] [156. 100.] [0. 6.]\n",
      "[126.  77.] [136. 111.] [-10. -34.]\n",
      "[102.  82.] [134. 105.] [-32. -23.]\n",
      "[154.  89.] [149. 100.] [  5. -11.]\n",
      "[191. 142.] [173.  67.] [18. 75.]\n",
      "[70. 77.] [83. 98.] [-13. -21.]\n",
      "[184.  75.] [158. 102.] [ 26. -27.]\n",
      "[111.  87.] [111. 120.] [  0. -33.]\n",
      "[190. 114.] [166. 100.] [24. 14.]\n",
      "[146.  82.] [166. 124.] [-20. -42.]\n",
      "[200. 108.] [152.  98.] [48. 10.]\n",
      "[138. 100.] [136. 100.] [2. 0.]\n",
      "[177. 105.] [155. 102.] [22.  3.]\n",
      "[163.  60.] [160. 139.] [  3. -79.]\n",
      "[131. 114.] [137. 106.] [-6.  8.]\n",
      "[123.  80.] [ 73. 134.] [ 50. -54.]\n",
      "[121.  90.] [136.  91.] [-15.  -1.]\n",
      "[135. 120.] [135.  87.] [ 0. 33.]\n",
      "[157.  90.] [179. 108.] [-22. -18.]\n",
      "[114.  88.] [ 75. 116.] [ 39. -28.]\n",
      "[110.  85.] [142. 102.] [-32. -17.]\n",
      "[127. 116.] [170.  99.] [-43.  17.]\n",
      "[101.  68.] [148. 102.] [-47. -34.]\n",
      "[144. 146.] [140.  71.] [ 4. 75.]\n",
      "[162.  97.] [170.  95.] [-8.  2.]\n",
      "[166.  99.] [154. 100.] [12. -1.]\n",
      "[214.  56.] [186. 130.] [ 28. -74.]\n",
      "[179.  78.] [172. 111.] [  7. -33.]\n",
      "[126. 151.] [132.  55.] [-6. 96.]\n",
      "[144.  58.] [155. 116.] [-11. -58.]\n",
      "[162. 100.] [138. 101.] [24. -1.]\n",
      "[147.  95.] [148. 100.] [-1. -5.]\n",
      "[127.  96.] [138. 101.] [-11.  -5.]\n",
      "[153.  73.] [162. 111.] [ -9. -38.]\n",
      "[206. 109.] [217. 106.] [-11.   3.]\n",
      "[135.  81.] [130. 113.] [  5. -32.]\n",
      "[163. 113.] [164.  88.] [-1. 25.]\n",
      "[107.  56.] [116. 116.] [ -9. -60.]\n",
      "[198. 127.] [181.  73.] [17. 54.]\n",
      "[169. 128.] [157.  81.] [12. 47.]\n",
      "[186. 100.] [199.  61.] [-13.  39.]\n",
      "[155.  80.] [153. 114.] [  2. -34.]\n",
      "[152.  87.] [153. 105.] [ -1. -18.]\n",
      "[173.  83.] [141.  92.] [32. -9.]\n",
      "[155. 128.] [154.  79.] [ 1. 49.]\n",
      "[149. 137.] [140.  44.] [ 9. 93.]\n",
      "[150. 100.] [119.  87.] [31. 13.]\n",
      "[136. 131.] [124.  77.] [12. 54.]\n",
      "[141. 134.] [143.  63.] [-2. 71.]\n",
      "[185.  64.] [165. 124.] [ 20. -60.]\n",
      "[152. 108.] [138. 101.] [14.  7.]\n",
      "[126.  97.] [139. 132.] [-13. -35.]\n",
      "[184. 139.] [178.  82.] [ 6. 57.]\n",
      "[161. 113.] [181.  76.] [-20.  37.]\n",
      "[168. 112.] [160.  95.] [ 8. 17.]\n",
      "[104. 138.] [138.  85.] [-34.  53.]\n",
      "[145.  97.] [148. 107.] [ -3. -10.]\n",
      "[108.  77.] [105. 132.] [  3. -55.]\n",
      "[140. 141.] [145.  77.] [-5. 64.]\n",
      "[157. 111.] [164.  94.] [-7. 17.]\n",
      "[138. 114.] [148.  95.] [-10.  19.]\n",
      "[152. 136.] [152.  64.] [ 0. 72.]\n",
      "[153.  87.] [152. 108.] [  1. -21.]\n",
      "[146. 132.] [150. 100.] [-4. 32.]\n",
      "[141.  88.] [125. 109.] [ 16. -21.]\n",
      "[118.  68.] [141. 111.] [-23. -43.]\n",
      "[132. 130.] [141.  86.] [-9. 44.]\n",
      "[157.  86.] [167. 125.] [-10. -39.]\n",
      "[100.  77.] [147. 103.] [-47. -26.]\n",
      "[119. 127.] [128.  80.] [-9. 47.]\n",
      "[214.  73.] [184. 123.] [ 30. -50.]\n",
      "[ 83. 129.] [95. 56.] [-12.  73.]\n",
      "[155.  95.] [146.  99.] [ 9. -4.]\n",
      "[177.  79.] [183. 133.] [ -6. -54.]\n",
      "[237.  73.] [203. 121.] [ 34. -48.]\n",
      "[120.  88.] [116. 116.] [  4. -28.]\n",
      "[174.  75.] [172. 121.] [  2. -46.]\n",
      "[136. 108.] [146.  90.] [-10.  18.]\n",
      "[179.  83.] [172. 120.] [  7. -37.]\n",
      "[138.  74.] [147. 101.] [ -9. -27.]\n",
      "[160.  90.] [156. 116.] [  4. -26.]\n",
      "[159. 105.] [160.  94.] [-1. 11.]\n",
      "[186. 148.] [169.  60.] [17. 88.]\n",
      "[124.  81.] [143. 119.] [-19. -38.]\n",
      "[149. 100.] [161. 108.] [-12.  -8.]\n",
      "[148. 159.] [150.  59.] [ -2. 100.]\n",
      "[185. 123.] [153.  88.] [32. 35.]\n",
      "[129.  99.] [125.  93.] [4. 6.]\n",
      "[157. 103.] [153.  94.] [4. 9.]\n",
      "[152.  52.] [140. 168.] [  12. -116.]\n",
      "[179. 121.] [175.  75.] [ 4. 46.]\n",
      "[141.  77.] [132. 135.] [  9. -58.]\n",
      "[134. 101.] [144.  96.] [-10.   5.]\n",
      "[177.  77.] [178. 121.] [ -1. -44.]\n",
      "[204. 140.] [210.  71.] [-6. 69.]\n",
      "[124.  87.] [139. 106.] [-15. -19.]\n",
      "[122. 116.] [146.  95.] [-24.  21.]\n",
      "[161. 120.] [150.  89.] [11. 31.]\n",
      "[149. 111.] [157.  89.] [-8. 22.]\n",
      "[190.  86.] [207. 115.] [-17. -29.]\n",
      "[121. 130.] [118.  82.] [ 3. 48.]\n",
      "[128. 143.] [132.  68.] [-4. 75.]\n",
      "[ 69. 123.] [60. 81.] [ 9. 42.]\n",
      "[186. 136.] [175.  76.] [11. 60.]\n",
      "[100. 107.] [134.  94.] [-34.  13.]\n",
      "[75. 59.] [145. 108.] [-70. -49.]\n",
      "[153. 103.] [147. 100.] [6. 3.]\n",
      "[153. 106.] [152.  98.] [1. 8.]\n",
      "[132. 138.] [135.  78.] [-3. 60.]\n",
      "[131. 123.] [123.  64.] [ 8. 59.]\n",
      "[ 94. 132.] [96. 55.] [-2. 77.]\n",
      "[81. 62.] [140. 118.] [-59. -56.]\n",
      "[188. 100.] [212.  91.] [-24.   9.]\n",
      "[130. 147.] [150.  70.] [-20.  77.]\n",
      "[ 66. 129.] [126.  89.] [-60.  40.]\n",
      "[160. 124.] [169.  74.] [-9. 50.]\n",
      "[137. 104.] [142.  94.] [-5. 10.]\n",
      "[113.  58.] [132. 137.] [-19. -79.]\n",
      "[159. 145.] [165.  63.] [-6. 82.]\n",
      "[130. 128.] [125.  47.] [ 5. 81.]\n",
      "[139. 107.] [134.  93.] [ 5. 14.]\n",
      "[165. 129.] [169.  65.] [-4. 64.]\n",
      "[168.  82.] [153. 106.] [ 15. -24.]\n",
      "[126.  79.] [143. 115.] [-17. -36.]\n",
      "[142. 129.] [142.  87.] [ 0. 42.]\n",
      "[130.  64.] [130. 155.] [  0. -91.]\n",
      "[186.  77.] [180. 109.] [  6. -32.]\n",
      "[128.  98.] [132. 107.] [-4. -9.]\n",
      "[158.  84.] [142. 104.] [ 16. -20.]\n",
      "[117. 114.] [101.  73.] [16. 41.]\n",
      "[136.  59.] [146. 137.] [-10. -78.]\n",
      "[150. 130.] [166.  69.] [-16.  61.]\n",
      "[165. 129.] [168.  73.] [-3. 56.]\n",
      "[157. 100.] [148.  82.] [ 9. 18.]\n",
      "[131. 103.] [131.  91.] [ 0. 12.]\n",
      "[171. 106.] [149.  82.] [22. 24.]\n",
      "[190. 113.] [186.  84.] [ 4. 29.]\n",
      "[146.  85.] [139. 126.] [  7. -41.]\n",
      "[83. 59.] [117. 116.] [-34. -57.]\n",
      "[ 91. 117.] [118.  87.] [-27.  30.]\n",
      "[138.  93.] [150.  93.] [-12.   0.]\n",
      "[123. 133.] [140.  61.] [-17.  72.]\n",
      "[184. 122.] [176.  82.] [ 8. 40.]\n",
      "[137. 116.] [142.  82.] [-5. 34.]\n",
      "[125.  87.] [146. 117.] [-21. -30.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180. 128.] [163.  86.] [17. 42.]\n",
      "[140.  74.] [111. 163.] [ 29. -89.]\n",
      "[124. 128.] [145.  80.] [-21.  48.]\n",
      "[126. 103.] [126. 101.] [0. 2.]\n",
      "[184. 115.] [174.  86.] [10. 29.]\n",
      "[117.  77.] [143. 112.] [-26. -35.]\n",
      "[88. 98.] [107.  94.] [-19.   4.]\n",
      "[219. 103.] [209. 114.] [ 10. -11.]\n",
      "[168. 135.] [189.  71.] [-21.  64.]\n",
      "[120. 105.] [124.  92.] [-4. 13.]\n",
      "[105.  83.] [ 93. 112.] [ 12. -29.]\n",
      "[162. 130.] [149.  81.] [13. 49.]\n",
      "[148. 123.] [157.  94.] [-9. 29.]\n",
      "[176. 145.] [199.  81.] [-23.  64.]\n",
      "[122. 124.] [134.  89.] [-12.  35.]\n",
      "[124. 100.] [121.  86.] [ 3. 14.]\n",
      "[115. 100.] [140. 102.] [-25.  -2.]\n",
      "[185. 101.] [172. 100.] [13.  1.]\n",
      "[202. 126.] [163.  91.] [39. 35.]\n",
      "[174. 106.] [163.  79.] [11. 27.]\n",
      "[125. 110.] [134.  93.] [-9. 17.]\n",
      "[207.  91.] [237. 135.] [-30. -44.]\n",
      "[157.  91.] [149. 111.] [  8. -20.]\n",
      "[153. 141.] [155.  94.] [-2. 47.]\n",
      "[114.  99.] [120.  98.] [-6.  1.]\n",
      "[140.  73.] [148. 129.] [ -8. -56.]\n",
      "[161. 117.] [174.  88.] [-13.  29.]\n",
      "[146. 101.] [165.  94.] [-19.   7.]\n",
      "[131. 125.] [135.  77.] [-4. 48.]\n",
      "[104.  78.] [117. 139.] [-13. -61.]\n",
      "[208. 113.] [188. 114.] [20. -1.]\n",
      "[97. 67.] [149. 102.] [-52. -35.]\n",
      "[145.  49.] [173. 150.] [ -28. -101.]\n",
      "[135. 112.] [151.  95.] [-16.  17.]\n",
      "[128. 106.] [145. 101.] [-17.   5.]\n",
      "[137.  60.] [128. 134.] [  9. -74.]\n",
      "[109.  47.] [111. 168.] [  -2. -121.]\n",
      "[161.  92.] [118. 106.] [ 43. -14.]\n",
      "[139.  74.] [140. 120.] [ -1. -46.]\n",
      "[134. 131.] [148.  49.] [-14.  82.]\n",
      "[157.  56.] [147. 107.] [ 10. -51.]\n",
      "[153.  74.] [142. 116.] [ 11. -42.]\n",
      "[125. 122.] [138.  86.] [-13.  36.]\n",
      "[153.  80.] [160. 115.] [ -7. -35.]\n",
      "[99. 67.] [117. 127.] [-18. -60.]\n",
      "[116.  67.] [136. 118.] [-20. -51.]\n",
      "[190.  87.] [164. 150.] [ 26. -63.]\n",
      "[141. 115.] [151.  85.] [-10.  30.]\n",
      "[170.  68.] [181. 116.] [-11. -48.]\n",
      "[179. 118.] [158.  85.] [21. 33.]\n",
      "[156. 137.] [177.  94.] [-21.  43.]\n",
      "[149. 115.] [143.  92.] [ 6. 23.]\n",
      "[178. 129.] [159.  89.] [19. 40.]\n",
      "[187.  85.] [182. 111.] [  5. -26.]\n",
      "[103. 129.] [146.  98.] [-43.  31.]\n",
      "[125. 101.] [130.  94.] [-5.  7.]\n",
      "[110.  86.] [105. 128.] [  5. -42.]\n",
      "[144. 116.] [156.  90.] [-12.  26.]\n",
      "[132.  78.] [138. 124.] [ -6. -46.]\n",
      "[159. 135.] [134.  78.] [25. 57.]\n",
      "[137. 154.] [143.  74.] [-6. 80.]\n",
      "[150. 144.] [156.  65.] [-6. 79.]\n",
      "[140. 128.] [140.  96.] [ 0. 32.]\n",
      "[157.  89.] [177.  84.] [-20.   5.]\n",
      "[120.  68.] [121. 105.] [ -1. -37.]\n",
      "[186.  66.] [160. 125.] [ 26. -59.]\n",
      "[173. 108.] [167.  87.] [ 6. 21.]\n",
      "[125. 119.] [111.  87.] [14. 32.]\n",
      "[197. 133.] [181.  75.] [16. 58.]\n",
      "[138. 134.] [161.  93.] [-23.  41.]\n",
      "[152. 102.] [148.  86.] [ 4. 16.]\n",
      "[171. 105.] [154.  96.] [17.  9.]\n",
      "[116.  96.] [126. 102.] [-10.  -6.]\n",
      "[169. 100.] [181.  81.] [-12.  19.]\n",
      "[181. 107.] [166. 102.] [15.  5.]\n",
      "[141.  87.] [136. 111.] [  5. -24.]\n",
      "[65. 99.] [ 97. 103.] [-32.  -4.]\n",
      "[194.  39.] [153. 140.] [  41. -101.]\n",
      "[116. 120.] [122.  75.] [-6. 45.]\n",
      "[151.  81.] [140. 141.] [ 11. -60.]\n",
      "[175.  75.] [169. 119.] [  6. -44.]\n",
      "[167.  79.] [149. 105.] [ 18. -26.]\n",
      "[169.  91.] [144. 102.] [ 25. -11.]\n",
      "[110.  93.] [146. 101.] [-36.  -8.]\n",
      "[173. 119.] [153.  97.] [20. 22.]\n",
      "[117. 143.] [139.  62.] [-22.  81.]\n",
      "[179.  80.] [144. 106.] [ 35. -26.]\n",
      "[129. 123.] [134.  82.] [-5. 41.]\n",
      "[140.  92.] [141. 112.] [ -1. -20.]\n",
      "[174. 114.] [176.  93.] [-2. 21.]\n",
      "[185.  77.] [165. 120.] [ 20. -43.]\n",
      "[199.  71.] [174. 117.] [ 25. -46.]\n",
      "[ 99. 127.] [114.  82.] [-15.  45.]\n",
      "[134.  44.] [143. 125.] [ -9. -81.]\n",
      "[153.  73.] [115.  77.] [38. -4.]\n",
      "[85. 79.] [ 78. 107.] [  7. -28.]\n",
      "[102. 129.] [145. 100.] [-43.  29.]\n",
      "[158.  85.] [181. 127.] [-23. -42.]\n",
      "[121. 104.] [93. 82.] [28. 22.]\n",
      "[119.  68.] [147. 111.] [-28. -43.]\n",
      "[103. 115.] [141.  96.] [-38.  19.]\n",
      "[149.  91.] [137. 104.] [ 12. -13.]\n",
      "[129. 118.] [116.  58.] [13. 60.]\n",
      "[130.  87.] [158. 113.] [-28. -26.]\n",
      "[178. 100.] [173.  88.] [ 5. 12.]\n",
      "[148. 117.] [159.  93.] [-11.  24.]\n",
      "[151.  81.] [147. 133.] [  4. -52.]\n",
      "[222. 125.] [170.  94.] [52. 31.]\n",
      "[204.  63.] [154. 111.] [ 50. -48.]\n",
      "[160.  83.] [167. 117.] [ -7. -34.]\n",
      "[154. 100.] [187.  82.] [-33.  18.]\n",
      "[149.  93.] [151. 121.] [ -2. -28.]\n",
      "[145. 117.] [159.  95.] [-14.  22.]\n",
      "[116. 106.] [113.  99.] [3. 7.]\n",
      "[161.  87.] [157. 115.] [  4. -28.]\n",
      "[127. 147.] [156.  74.] [-29.  73.]\n",
      "[131.  64.] [149. 108.] [-18. -44.]\n",
      "[138. 151.] [135.  84.] [ 3. 67.]\n",
      "[135.  95.] [127. 115.] [  8. -20.]\n",
      "[127. 104.] [141. 102.] [-14.   2.]\n",
      "[154.  94.] [166. 121.] [-12. -27.]\n",
      "[212.  88.] [230. 111.] [-18. -23.]\n",
      "[132.  96.] [141. 101.] [-9. -5.]\n",
      "[113.  79.] [137. 117.] [-24. -38.]\n",
      "[133.  94.] [147.  97.] [-14.  -3.]\n",
      "[50. 92.] [130. 101.] [-80.  -9.]\n",
      "[170.  72.] [155. 107.] [ 15. -35.]\n",
      "[131.  99.] [118.  89.] [13. 10.]\n",
      "[149.  73.] [167. 118.] [-18. -45.]\n",
      "[106.  96.] [151. 101.] [-45.  -5.]\n",
      "[176. 104.] [165.  93.] [11. 11.]\n",
      "[174.  86.] [149. 105.] [ 25. -19.]\n",
      "[174.  80.] [174. 114.] [  0. -34.]\n",
      "[210.  80.] [186. 107.] [ 24. -27.]\n",
      "[188.  67.] [173. 115.] [ 15. -48.]\n",
      "[93. 91.] [110. 110.] [-17. -19.]\n",
      "[143.  71.] [138. 127.] [  5. -56.]\n",
      "[148. 112.] [147.  97.] [ 1. 15.]\n",
      "[186.  89.] [197. 105.] [-11. -16.]\n",
      "[146. 143.] [141.  79.] [ 5. 64.]\n",
      "[132. 132.] [143.  72.] [-11.  60.]\n",
      "[169. 150.] [187.  39.] [-18. 111.]\n",
      "[142. 119.] [164.  98.] [-22.  21.]\n",
      "[142. 114.] [135.  88.] [ 7. 26.]\n",
      "[117.  90.] [123. 118.] [ -6. -28.]\n",
      "[185. 108.] [175.  88.] [10. 20.]\n",
      "[145. 103.] [135.  83.] [10. 20.]\n",
      "[174. 103.] [177.  88.] [-3. 15.]\n",
      "[ 99. 100.] [76. 55.] [23. 45.]\n",
      "[154.  75.] [144. 135.] [ 10. -60.]\n",
      "[188. 100.] [183.  90.] [ 5. 10.]\n",
      "[176. 117.] [168.  87.] [ 8. 30.]\n",
      "[82. 86.] [108. 112.] [-26. -26.]\n",
      "[ 91. 130.] [97. 60.] [-6. 70.]\n",
      "[124. 123.] [135.  81.] [-11.  42.]\n",
      "[110. 112.] [134.  95.] [-24.  17.]\n",
      "[184. 130.] [150.  64.] [34. 66.]\n",
      "[115. 153.] [132.  62.] [-17.  91.]\n",
      "[140. 160.] [170.  66.] [-30.  94.]\n",
      "[175. 117.] [138.  62.] [37. 55.]\n",
      "[140.  63.] [139. 134.] [  1. -71.]\n",
      "[164. 148.] [152.  97.] [12. 51.]\n",
      "[168.  85.] [158. 111.] [ 10. -26.]\n",
      "[163. 157.] [167.  72.] [-4. 85.]\n",
      "[137. 136.] [155.  49.] [-18.  87.]\n",
      "[217.  71.] [221. 137.] [ -4. -66.]\n",
      "[116.  78.] [138.  98.] [-22. -20.]\n",
      "[166. 106.] [162.  99.] [4. 7.]\n",
      "[93. 68.] [ 84. 111.] [  9. -43.]\n",
      "[96. 73.] [127. 108.] [-31. -35.]\n",
      "[146.  82.] [152. 113.] [ -6. -31.]\n",
      "[138.  75.] [122. 106.] [ 16. -31.]\n",
      "[149. 118.] [146.  90.] [ 3. 28.]\n",
      "[221. 131.] [210.  84.] [11. 47.]\n",
      "[161. 148.] [144.  49.] [17. 99.]\n",
      "[118. 108.] [111.  99.] [7. 9.]\n",
      "[ 98. 150.] [113.  57.] [-15.  93.]\n",
      "[107. 106.] [127.  89.] [-20.  17.]\n",
      "[139.  92.] [146. 101.] [-7. -9.]\n",
      "[121.  55.] [129. 138.] [ -8. -83.]\n",
      "[140. 148.] [139.  65.] [ 1. 83.]\n",
      "[172. 145.] [157.  66.] [15. 79.]\n",
      "[183. 104.] [159. 110.] [24. -6.]\n",
      "[158.  95.] [149.  98.] [ 9. -3.]\n",
      "[179.  84.] [168. 110.] [ 11. -26.]\n",
      "[129. 125.] [108.  66.] [21. 59.]\n",
      "[165. 133.] [152.  90.] [13. 43.]\n",
      "[111.  72.] [137. 125.] [-26. -53.]\n",
      "[119.  88.] [98. 99.] [ 21. -11.]\n",
      "[135.  96.] [134. 111.] [  1. -15.]\n",
      "[177. 104.] [170. 107.] [ 7. -3.]\n",
      "[127.  87.] [133. 125.] [ -6. -38.]\n",
      "[138.  62.] [151. 125.] [-13. -63.]\n",
      "[110.  67.] [123. 110.] [-13. -43.]\n",
      "[149. 130.] [173.  57.] [-24.  73.]\n",
      "[198.  70.] [169. 116.] [ 29. -46.]\n",
      "[192.  55.] [186. 156.] [   6. -101.]\n",
      "[174.  91.] [154. 100.] [20. -9.]\n",
      "[120.  70.] [136. 126.] [-16. -56.]\n",
      "[154. 117.] [156.  86.] [-2. 31.]\n",
      "[181.  82.] [162. 113.] [ 19. -31.]\n",
      "[93. 57.] [116. 151.] [-23. -94.]\n",
      "[174. 107.] [169. 108.] [ 5. -1.]\n",
      "[133. 131.] [150.  99.] [-17.  32.]\n",
      "[175. 136.] [154.  73.] [21. 63.]\n",
      "[168.  78.] [177. 119.] [ -9. -41.]\n",
      "[195. 134.] [172.  83.] [23. 51.]\n",
      "[176.  59.] [177. 130.] [ -1. -71.]\n",
      "[149.  71.] [150. 113.] [ -1. -42.]\n",
      "[193. 123.] [163.  92.] [30. 31.]\n",
      "[161.  95.] [168. 116.] [ -7. -21.]\n",
      "[134. 105.] [149. 114.] [-15.  -9.]\n",
      "[171.  61.] [166. 121.] [  5. -60.]\n",
      "[175.  74.] [163. 111.] [ 12. -37.]\n",
      "[141. 106.] [133.  94.] [ 8. 12.]\n",
      "[183.  73.] [172. 109.] [ 11. -36.]\n",
      "[227. 105.] [173.  91.] [54. 14.]\n",
      "[171. 132.] [174.  71.] [-3. 61.]\n",
      "[156. 111.] [146.  81.] [10. 30.]\n",
      "[117. 135.] [147.  53.] [-30.  82.]\n",
      "[168. 125.] [166.  91.] [ 2. 34.]\n",
      "[110. 104.] [134. 101.] [-24.   3.]\n",
      "[203. 134.] [186.  79.] [17. 55.]\n",
      "[146. 113.] [181.  92.] [-35.  21.]\n",
      "[147.  93.] [144. 103.] [  3. -10.]\n",
      "[140.  91.] [136. 111.] [  4. -20.]\n",
      "[137. 119.] [146.  96.] [-9. 23.]\n",
      "[155.  47.] [150. 145.] [  5. -98.]\n",
      "[85. 67.] [131. 121.] [-46. -54.]\n",
      "[149. 116.] [150.  91.] [-1. 25.]\n",
      "[121.  66.] [137. 107.] [-16. -41.]\n",
      "[136. 138.] [153.  32.] [-17. 106.]\n",
      "[106.  98.] [109. 102.] [-3. -4.]\n",
      "[195. 142.] [176.  78.] [19. 64.]\n",
      "[164.  72.] [156. 133.] [  8. -61.]\n",
      "[127.  76.] [136. 117.] [ -9. -41.]\n",
      "[123. 115.] [134.  86.] [-11.  29.]\n",
      "[178.  62.] [166. 119.] [ 12. -57.]\n",
      "[149. 138.] [131.  73.] [18. 65.]\n",
      "[126. 131.] [145.  86.] [-19.  45.]\n",
      "[167.  90.] [153.  99.] [14. -9.]\n",
      "[171. 113.] [169.  80.] [ 2. 33.]\n",
      "[160. 113.] [149.  74.] [11. 39.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158.  54.] [149. 111.] [  9. -57.]\n",
      "[129.  85.] [123. 119.] [  6. -34.]\n",
      "[156.  45.] [153. 141.] [  3. -96.]\n",
      "[229.  74.] [161. 111.] [ 68. -37.]\n",
      "[121.  77.] [132. 125.] [-11. -48.]\n",
      "[189.  78.] [203. 130.] [-14. -52.]\n",
      "[120.  83.] [129. 110.] [ -9. -27.]\n",
      "[155.  88.] [122. 112.] [ 33. -24.]\n",
      "[152. 156.] [158.  66.] [-6. 90.]\n",
      "[183. 100.] [151.  95.] [32.  5.]\n",
      "[104.  84.] [143. 101.] [-39. -17.]\n",
      "[83. 49.] [112. 120.] [-29. -71.]\n",
      "[125. 112.] [166. 114.] [-41.  -2.]\n",
      "[176.  79.] [163. 125.] [ 13. -46.]\n",
      "[129. 146.] [142.  65.] [-13.  81.]\n",
      "[190. 109.] [166.  69.] [24. 40.]\n",
      "[168.  97.] [164.  98.] [ 4. -1.]\n",
      "[81. 71.] [133. 108.] [-52. -37.]\n",
      "[151. 121.] [133.  86.] [18. 35.]\n",
      "[112.  94.] [127. 150.] [-15. -56.]\n",
      "[164.  79.] [147. 110.] [ 17. -31.]\n",
      "[201. 113.] [156.  96.] [45. 17.]\n",
      "[167. 144.] [150.  55.] [17. 89.]\n",
      "[136. 127.] [167.  78.] [-31.  49.]\n",
      "[160.  89.] [152. 101.] [  8. -12.]\n",
      "[147.  77.] [132. 126.] [ 15. -49.]\n",
      "[159.  66.] [150. 121.] [  9. -55.]\n",
      "[142.  71.] [174. 118.] [-32. -47.]\n",
      "[143. 106.] [142. 108.] [ 1. -2.]\n",
      "[150. 102.] [157. 100.] [-7.  2.]\n",
      "[175.  64.] [181. 155.] [ -6. -91.]\n",
      "[141.  96.] [127.  84.] [14. 12.]\n",
      "[167.  87.] [161.  97.] [  6. -10.]\n",
      "[154.  67.] [146. 137.] [  8. -70.]\n",
      "[128.  90.] [124. 114.] [  4. -24.]\n",
      "[109. 134.] [139.  98.] [-30.  36.]\n",
      "[112.  95.] [120.  96.] [-8. -1.]\n",
      "[168. 107.] [161.  86.] [ 7. 21.]\n",
      "[228.  79.] [183. 109.] [ 45. -30.]\n",
      "[153. 115.] [148.  92.] [ 5. 23.]\n",
      "[199. 130.] [232.  87.] [-33.  43.]\n",
      "[113. 109.] [152.  93.] [-39.  16.]\n",
      "[152.  61.] [156. 135.] [ -4. -74.]\n",
      "[148. 124.] [153.  75.] [-5. 49.]\n",
      "[173.  89.] [198.  94.] [-25.  -5.]\n",
      "[156.  82.] [141. 113.] [ 15. -31.]\n",
      "[99. 90.] [119. 105.] [-20. -15.]\n",
      "[156. 111.] [202.  72.] [-46.  39.]\n",
      "[ 93. 134.] [ 85. 108.] [ 8. 26.]\n",
      "[149.  70.] [144. 103.] [  5. -33.]\n",
      "[179.  79.] [193. 127.] [-14. -48.]\n",
      "[ 85. 141.] [79. 51.] [ 6. 90.]\n",
      "[162. 128.] [182.  86.] [-20.  42.]\n",
      "[197.  59.] [188. 129.] [  9. -70.]\n",
      "[170. 118.] [149. 100.] [21. 18.]\n",
      "[145. 105.] [144. 100.] [1. 5.]\n",
      "[134. 134.] [174.  90.] [-40.  44.]\n",
      "[155.  89.] [191. 104.] [-36. -15.]\n",
      "[145. 108.] [150.  92.] [-5. 16.]\n",
      "[160. 119.] [145.  72.] [15. 47.]\n",
      "[153. 122.] [153.  77.] [ 0. 45.]\n",
      "[133. 120.] [158. 102.] [-25.  18.]\n",
      "[157. 135.] [155.  97.] [ 2. 38.]\n",
      "[123. 106.] [130.  85.] [-7. 21.]\n",
      "[132.  82.] [118. 127.] [ 14. -45.]\n",
      "[157. 129.] [150.  75.] [ 7. 54.]\n",
      "[151.  87.] [135. 102.] [ 16. -15.]\n",
      "[162.  73.] [146. 131.] [ 16. -58.]\n",
      "[155. 132.] [150. 103.] [ 5. 29.]\n",
      "[152.  65.] [152. 116.] [  0. -51.]\n",
      "[158.  99.] [149.  99.] [9. 0.]\n",
      "[122. 113.] [149. 101.] [-27.  12.]\n",
      "[138. 101.] [139.  94.] [-1.  7.]\n",
      "[124. 110.] [148.  94.] [-24.  16.]\n",
      "[180. 110.] [150. 101.] [30.  9.]\n",
      "[137. 128.] [139.  42.] [-2. 86.]\n",
      "[176.  73.] [193. 115.] [-17. -42.]\n",
      "[192. 104.] [177.  92.] [15. 12.]\n",
      "[106. 114.] [138.  86.] [-32.  28.]\n",
      "[167.  72.] [156. 118.] [ 11. -46.]\n",
      "[142. 131.] [131.  53.] [11. 78.]\n",
      "[169.  72.] [160. 155.] [  9. -83.]\n",
      "[192. 117.] [159.  94.] [33. 23.]\n",
      "[165. 137.] [112.  22.] [ 53. 115.]\n",
      "[133. 104.] [149.  99.] [-16.   5.]\n",
      "[124. 107.] [122. 106.] [2. 1.]\n",
      "[134. 118.] [135.  79.] [-1. 39.]\n",
      "[139. 123.] [154.  89.] [-15.  34.]\n",
      "[207. 104.] [157.  98.] [50.  6.]\n",
      "[162.  63.] [140. 106.] [ 22. -43.]\n",
      "[165. 103.] [149.  92.] [16. 11.]\n",
      "[143. 119.] [116.  84.] [27. 35.]\n",
      "[101.  70.] [ 95. 104.] [  6. -34.]\n",
      "[180.  71.] [154. 104.] [ 26. -33.]\n",
      "[169. 100.] [135. 116.] [ 34. -16.]\n",
      "[160. 116.] [201.  54.] [-41.  62.]\n",
      "[211. 138.] [184.  67.] [27. 71.]\n",
      "[138. 101.] [149.  95.] [-11.   6.]\n",
      "[195.  64.] [215. 144.] [-20. -80.]\n",
      "[128. 136.] [133.  69.] [-5. 67.]\n",
      "[135. 105.] [126. 100.] [9. 5.]\n",
      "[96. 78.] [149.  98.] [-53. -20.]\n",
      "[120. 138.] [124.  75.] [-4. 63.]\n",
      "[190.  97.] [246.  69.] [-56.  28.]\n",
      "[170.  50.] [157. 122.] [ 13. -72.]\n",
      "[124.  95.] [148.  99.] [-24.  -4.]\n",
      "[169.  93.] [172.  99.] [-3. -6.]\n",
      "[210. 119.] [238.  65.] [-28.  54.]\n",
      "[158.  78.] [159. 125.] [ -1. -47.]\n",
      "[197.  79.] [203. 126.] [ -6. -47.]\n",
      "[157.  88.] [145. 118.] [ 12. -30.]\n",
      "[150. 113.] [166.  70.] [-16.  43.]\n",
      "[135. 113.] [145.  80.] [-10.  33.]\n",
      "[ 76. 136.] [117.  85.] [-41.  51.]\n",
      "[168. 105.] [151.  96.] [17.  9.]\n",
      "[119. 102.] [129.  95.] [-10.   7.]\n",
      "[129.  76.] [145. 109.] [-16. -33.]\n",
      "[125.  63.] [95. 84.] [ 30. -21.]\n",
      "[163. 117.] [148.  90.] [15. 27.]\n",
      "[145.  86.] [138. 107.] [  7. -21.]\n",
      "[107. 122.] [140.  94.] [-33.  28.]\n",
      "[208. 135.] [205.  67.] [ 3. 68.]\n",
      "[156.  85.] [178. 133.] [-22. -48.]\n",
      "[188.  64.] [164. 120.] [ 24. -56.]\n",
      "[218.  86.] [177.  88.] [41. -2.]\n",
      "[154.  89.] [138.  99.] [ 16. -10.]\n",
      "[112.  78.] [131. 118.] [-19. -40.]\n",
      "[169. 116.] [185. 114.] [-16.   2.]\n",
      "[163. 134.] [140.  67.] [23. 67.]\n",
      "[158. 103.] [145. 109.] [13. -6.]\n",
      "[134.  75.] [ 98. 131.] [ 36. -56.]\n",
      "[180.  75.] [180. 142.] [  0. -67.]\n",
      "[206.  76.] [156. 100.] [ 50. -24.]\n",
      "[185. 141.] [182.  61.] [ 3. 80.]\n",
      "[ 98. 110.] [99. 88.] [-1. 22.]\n",
      "[135.  92.] [101. 168.] [ 34. -76.]\n",
      "[117. 111.] [136.  95.] [-19.  16.]\n",
      "[179.  97.] [158. 105.] [21. -8.]\n",
      "[161. 114.] [158.  97.] [ 3. 17.]\n",
      "[146. 148.] [139.  59.] [ 7. 89.]\n",
      "[153.  76.] [142. 122.] [ 11. -46.]\n",
      "[124. 142.] [143.  94.] [-19.  48.]\n",
      "[135.  51.] [139. 154.] [  -4. -103.]\n",
      "[157.  74.] [156. 139.] [  1. -65.]\n",
      "[143.  64.] [145. 106.] [ -2. -42.]\n",
      "[201. 135.] [190.  68.] [11. 67.]\n",
      "[156.  91.] [150. 101.] [  6. -10.]\n",
      "[186.  98.] [148.  96.] [38.  2.]\n",
      "[139.  64.] [147. 143.] [ -8. -79.]\n",
      "[141. 109.] [146.  98.] [-5. 11.]\n",
      "[132. 115.] [154.  94.] [-22.  21.]\n",
      "[155. 123.] [154. 100.] [ 1. 23.]\n",
      "[150.  73.] [154. 108.] [ -4. -35.]\n",
      "[159.  95.] [153. 118.] [  6. -23.]\n",
      "[173.  70.] [142. 141.] [ 31. -71.]\n",
      "[197. 104.] [185. 100.] [12.  4.]\n",
      "[161. 119.] [151.  93.] [10. 26.]\n",
      "[126.  67.] [122. 129.] [  4. -62.]\n",
      "[161.  95.] [148. 106.] [ 13. -11.]\n",
      "[137. 124.] [131.  63.] [ 6. 61.]\n",
      "[114. 131.] [113.  38.] [ 1. 93.]\n",
      "[159.  87.] [177. 113.] [-18. -26.]\n",
      "[ 86. 148.] [110.  68.] [-24.  80.]\n",
      "[196.  92.] [167. 120.] [ 29. -28.]\n",
      "[166. 146.] [154.  76.] [12. 70.]\n",
      "[153. 103.] [151.  94.] [2. 9.]\n",
      "[138.  90.] [140.  96.] [-2. -6.]\n",
      "[139. 108.] [111.  70.] [28. 38.]\n",
      "[208.  57.] [174. 112.] [ 34. -55.]\n",
      "[107. 130.] [112.  63.] [-5. 67.]\n",
      "[127. 131.] [130.  83.] [-3. 48.]\n",
      "[160. 119.] [154.  90.] [ 6. 29.]\n",
      "[160. 102.] [152. 111.] [ 8. -9.]\n",
      "[152. 144.] [163.  59.] [-11.  85.]\n",
      "[168. 167.] [162.  85.] [ 6. 82.]\n",
      "[113. 106.] [142.  90.] [-29.  16.]\n",
      "[100. 143.] [133.  62.] [-33.  81.]\n",
      "[156. 100.] [161.  99.] [-5.  1.]\n",
      "[129.  73.] [144. 122.] [-15. -49.]\n",
      "[ 66. 144.] [132.  94.] [-66.  50.]\n",
      "[193. 131.] [176. 101.] [17. 30.]\n",
      "[170.  87.] [165. 110.] [  5. -23.]\n",
      "[138.  63.] [123. 115.] [ 15. -52.]\n",
      "[158. 125.] [186.  77.] [-28.  48.]\n",
      "[88. 89.] [100.  97.] [-12.  -8.]\n",
      "[123.  93.] [125. 102.] [-2. -9.]\n",
      "[175.  94.] [220. 109.] [-45. -15.]\n",
      "[206.  80.] [175. 108.] [ 31. -28.]\n",
      "[179. 103.] [175. 102.] [4. 1.]\n",
      "[180. 112.] [150.  92.] [30. 20.]\n",
      "[150. 100.] [118. 102.] [32. -2.]\n",
      "[149.  64.] [141. 114.] [  8. -50.]\n",
      "[184.  75.] [150. 100.] [ 34. -25.]\n",
      "[169.  83.] [160. 114.] [  9. -31.]\n",
      "[164. 124.] [178.  88.] [-14.  36.]\n",
      "[131. 117.] [127.  91.] [ 4. 26.]\n",
      "[132. 104.] [111.  99.] [21.  5.]\n",
      "[124.  99.] [129.  97.] [-5.  2.]\n",
      "[112.  57.] [115. 140.] [ -3. -83.]\n",
      "[140.  86.] [174. 120.] [-34. -34.]\n",
      "[150.  96.] [149.  97.] [ 1. -1.]\n",
      "[141. 118.] [144.  99.] [-3. 19.]\n",
      "[ 93. 134.] [102.  68.] [-9. 66.]\n",
      "[103.  68.] [115. 117.] [-12. -49.]\n",
      "[191. 116.] [149.  78.] [42. 38.]\n",
      "[166. 108.] [157.  93.] [ 9. 15.]\n",
      "[145.  78.] [145. 129.] [  0. -51.]\n",
      "[117. 111.] [109.  98.] [ 8. 13.]\n",
      "[144.  62.] [127. 136.] [ 17. -74.]\n",
      "[105. 133.] [125.  61.] [-20.  72.]\n",
      "[151.  78.] [169. 137.] [-18. -59.]\n",
      "[140.  65.] [136. 130.] [  4. -65.]\n",
      "[156. 103.] [142.  92.] [14. 11.]\n",
      "[208.  89.] [198. 119.] [ 10. -30.]\n",
      "[157.  98.] [151.  98.] [6. 0.]\n",
      "[145. 129.] [116.  56.] [29. 73.]\n",
      "[159.  76.] [164.  97.] [ -5. -21.]\n",
      "[81. 99.] [ 79. 132.] [  2. -33.]\n",
      "[167.  99.] [162.  89.] [ 5. 10.]\n",
      "[170. 101.] [148. 105.] [22. -4.]\n",
      "[138.  68.] [140. 136.] [ -2. -68.]\n",
      "[178. 126.] [164.  90.] [14. 36.]\n",
      "[163.  76.] [201. 124.] [-38. -48.]\n",
      "[185.  75.] [204. 141.] [-19. -66.]\n",
      "[109. 124.] [114.  75.] [-5. 49.]\n",
      "[147. 141.] [152.  99.] [-5. 42.]\n",
      "[175. 144.] [174.  74.] [ 1. 70.]\n",
      "[158. 101.] [148.  99.] [10.  2.]\n",
      "[158. 145.] [150.  42.] [  8. 103.]\n",
      "[150. 141.] [136.  90.] [14. 51.]\n",
      "[162. 149.] [166.  82.] [-4. 67.]\n",
      "[141.  79.] [142. 120.] [ -1. -41.]\n",
      "[153. 120.] [141.  82.] [12. 38.]\n",
      "[177. 122.] [166.  91.] [11. 31.]\n",
      "[181. 124.] [160.  82.] [21. 42.]\n",
      "[125. 101.] [112. 101.] [13.  0.]\n",
      "[170. 125.] [169.  79.] [ 1. 46.]\n",
      "[176. 129.] [185.  83.] [-9. 46.]\n",
      "[125.  85.] [135. 104.] [-10. -19.]\n",
      "[153.  78.] [139. 104.] [ 14. -26.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207.  92.] [241. 114.] [-34. -22.]\n",
      "[177.  59.] [150. 104.] [ 27. -45.]\n",
      "[116.  81.] [140. 107.] [-24. -26.]\n",
      "[192.  81.] [172. 104.] [ 20. -23.]\n",
      "[123.  94.] [120. 108.] [  3. -14.]\n",
      "[129.  84.] [143. 111.] [-14. -27.]\n",
      "[118.  89.] [133. 115.] [-15. -26.]\n",
      "[159. 127.] [160.  62.] [-1. 65.]\n",
      "[117. 105.] [130.  93.] [-13.  12.]\n",
      "[123. 142.] [139.  60.] [-16.  82.]\n",
      "[148. 145.] [162.  83.] [-14.  62.]\n",
      "[192.  91.] [159. 101.] [ 33. -10.]\n",
      "[160. 126.] [143.  79.] [17. 47.]\n",
      "[134.  75.] [139. 113.] [ -5. -38.]\n",
      "[125. 110.] [143.  86.] [-18.  24.]\n",
      "[132.  87.] [115. 115.] [ 17. -28.]\n",
      "[205. 139.] [188. 106.] [17. 33.]\n",
      "[170. 144.] [170.  46.] [ 0. 98.]\n",
      "[150.  63.] [185. 188.] [ -35. -125.]\n",
      "[161. 101.] [173.  86.] [-12.  15.]\n",
      "[163.  79.] [161. 124.] [  2. -45.]\n",
      "[151. 105.] [142.  89.] [ 9. 16.]\n",
      "[170.  97.] [173.  90.] [-3.  7.]\n",
      "[157.  85.] [137.  94.] [20. -9.]\n",
      "[178.  67.] [161. 108.] [ 17. -41.]\n",
      "[134. 133.] [157.  86.] [-23.  47.]\n",
      "[186.  71.] [155. 124.] [ 31. -53.]\n",
      "[105.  68.] [137. 104.] [-32. -36.]\n",
      "[152.  62.] [159. 143.] [ -7. -81.]\n",
      "[142. 101.] [133.  91.] [ 9. 10.]\n",
      "[129.  78.] [131. 125.] [ -2. -47.]\n",
      "[158. 117.] [183.  76.] [-25.  41.]\n",
      "[124.  92.] [112.  64.] [12. 28.]\n",
      "[228. 112.] [214.  97.] [14. 15.]\n",
      "[145.  45.] [157. 161.] [ -12. -116.]\n",
      "[178.  75.] [168. 122.] [ 10. -47.]\n",
      "[183.  87.] [192. 132.] [ -9. -45.]\n",
      "[143.  73.] [152. 106.] [ -9. -33.]\n",
      "[231. 117.] [152.  99.] [79. 18.]\n",
      "[137. 106.] [150.  92.] [-13.  14.]\n",
      "[ 86. 135.] [148.  97.] [-62.  38.]\n",
      "[127.  96.] [150. 102.] [-23.  -6.]\n",
      "[157. 131.] [188.  91.] [-31.  40.]\n",
      "[164. 149.] [165.  51.] [-1. 98.]\n",
      "[183.  78.] [181. 147.] [  2. -69.]\n",
      "[193. 100.] [162.  60.] [31. 40.]\n",
      "[155.  99.] [151.  91.] [4. 8.]\n",
      "[179. 109.] [165.  77.] [14. 32.]\n",
      "[122.  47.] [150. 135.] [-28. -88.]\n",
      "[193. 133.] [201.  83.] [-8. 50.]\n",
      "[124.  75.] [134. 116.] [-10. -41.]\n",
      "[134.  81.] [140. 134.] [ -6. -53.]\n",
      "[135. 143.] [167.  62.] [-32.  81.]\n",
      "[126. 119.] [136.  84.] [-10.  35.]\n",
      "[119.  74.] [135. 117.] [-16. -43.]\n",
      "[170.  74.] [152. 121.] [ 18. -47.]\n",
      "[143. 125.] [149. 100.] [-6. 25.]\n",
      "[134.  48.] [153. 127.] [-19. -79.]\n",
      "[114.  68.] [148. 104.] [-34. -36.]\n",
      "[141.  89.] [146. 103.] [ -5. -14.]\n",
      "[115.  87.] [ 87. 126.] [ 28. -39.]\n",
      "[179.  66.] [157. 109.] [ 22. -43.]\n",
      "[227.  83.] [193. 118.] [ 34. -35.]\n",
      "[114.  91.] [140. 113.] [-26. -22.]\n",
      "[115.  72.] [ 84. 104.] [ 31. -32.]\n",
      "[115.  94.] [138. 106.] [-23. -12.]\n",
      "[135. 121.] [149.  96.] [-14.  25.]\n",
      "[113. 127.] [126.  79.] [-13.  48.]\n",
      "[136.  87.] [147.  96.] [-11.  -9.]\n",
      "[113.  91.] [132. 101.] [-19. -10.]\n",
      "[208. 135.] [183.  91.] [25. 44.]\n",
      "[148.  94.] [157.  97.] [-9. -3.]\n",
      "[129. 101.] [137. 104.] [-8. -3.]\n",
      "[141.  44.] [139. 127.] [  2. -83.]\n",
      "[157.  53.] [146. 110.] [ 11. -57.]\n",
      "[88. 62.] [123. 106.] [-35. -44.]\n",
      "[142. 141.] [146.  55.] [-4. 86.]\n",
      "[105. 116.] [121.  95.] [-16.  21.]\n",
      "[88. 91.] [118.  97.] [-30.  -6.]\n",
      "[152.  82.] [162. 116.] [-10. -34.]\n",
      "[84. 64.] [108. 140.] [-24. -76.]\n",
      "[117.  77.] [133. 125.] [-16. -48.]\n",
      "[146. 100.] [119. 135.] [ 27. -35.]\n",
      "[233.  76.] [158. 101.] [ 75. -25.]\n",
      "[180. 112.] [160.  89.] [20. 23.]\n",
      "[135.  64.] [152. 113.] [-17. -49.]\n",
      "[187.  65.] [212. 169.] [ -25. -104.]\n",
      "[136.  93.] [93. 85.] [43.  8.]\n",
      "[146. 117.] [166.  76.] [-20.  41.]\n",
      "[128. 100.] [105.  86.] [23. 14.]\n",
      "[124. 102.] [140. 100.] [-16.   2.]\n",
      "[147.  47.] [128. 135.] [ 19. -88.]\n",
      "[145. 112.] [150.  72.] [-5. 40.]\n",
      "[142. 110.] [154.  99.] [-12.  11.]\n",
      "[150.  73.] [153. 105.] [ -3. -32.]\n",
      "[150. 105.] [137.  98.] [13.  7.]\n",
      "[196.  93.] [182.  98.] [14. -5.]\n",
      "[162.  70.] [153. 107.] [  9. -37.]\n",
      "[135. 103.] [133. 100.] [2. 3.]\n",
      "[121.  53.] [148. 127.] [-27. -74.]\n",
      "[105. 105.] [64. 79.] [41. 26.]\n",
      "[129.  98.] [104. 101.] [25. -3.]\n",
      "[209.  89.] [189. 103.] [ 20. -14.]\n",
      "[143. 105.] [129.  96.] [14.  9.]\n",
      "[174.  98.] [169.  86.] [ 5. 12.]\n",
      "[196. 128.] [192.  51.] [ 4. 77.]\n",
      "[179. 136.] [166.  72.] [13. 64.]\n",
      "[90. 57.] [ 97. 133.] [ -7. -76.]\n",
      "[166. 103.] [176.  91.] [-10.  12.]\n",
      "[188. 120.] [165.  94.] [23. 26.]\n",
      "[198.  66.] [181. 121.] [ 17. -55.]\n",
      "[142. 105.] [142.  75.] [ 0. 30.]\n",
      "[165. 143.] [159.  96.] [ 6. 47.]\n",
      "[217. 125.] [185.  87.] [32. 38.]\n",
      "[151.  67.] [156. 133.] [ -5. -66.]\n",
      "[126.  64.] [155. 129.] [-29. -65.]\n",
      "[151. 122.] [143.  71.] [ 8. 51.]\n",
      "[134.  67.] [143.  84.] [ -9. -17.]\n",
      "[175.  89.] [205. 126.] [-30. -37.]\n",
      "[141.  73.] [140. 102.] [  1. -29.]\n",
      "[ 93. 132.] [103.  58.] [-10.  74.]\n",
      "[136. 115.] [147.  98.] [-11.  17.]\n",
      "[170. 118.] [203.  69.] [-33.  49.]\n",
      "[185. 120.] [251.  54.] [-66.  66.]\n",
      "[204. 111.] [192.  74.] [12. 37.]\n",
      "[139. 108.] [141.  92.] [-2. 16.]\n",
      "[177. 142.] [157.  84.] [20. 58.]\n",
      "[134. 128.] [132.  79.] [ 2. 49.]\n",
      "[113. 101.] [132. 104.] [-19.  -3.]\n",
      "[126.  65.] [130. 116.] [ -4. -51.]\n",
      "[174.  58.] [155. 140.] [ 19. -82.]\n",
      "[104.  65.] [136. 133.] [-32. -68.]\n",
      "[80. 78.] [107. 118.] [-27. -40.]\n",
      "[147. 136.] [147.  57.] [ 0. 79.]\n",
      "[138. 148.] [146.  47.] [ -8. 101.]\n",
      "[125. 100.] [109. 115.] [ 16. -15.]\n",
      "[130.  59.] [141. 122.] [-11. -63.]\n",
      "[104.  55.] [101. 138.] [  3. -83.]\n",
      "[119.  65.] [151. 104.] [-32. -39.]\n",
      "[163.  99.] [144.  97.] [19.  2.]\n",
      "[155. 126.] [150.  78.] [ 5. 48.]\n",
      "[91. 80.] [136. 113.] [-45. -33.]\n",
      "[ 92. 142.] [148. 101.] [-56.  41.]\n",
      "[144. 101.] [181.  74.] [-37.  27.]\n",
      "[172. 113.] [157.  98.] [15. 15.]\n",
      "[ 87. 101.] [ 84. 104.] [ 3. -3.]\n",
      "[131. 142.] [134.  75.] [-3. 67.]\n",
      "[100. 144.] [95. 58.] [ 5. 86.]\n",
      "[128.  77.] [145.  98.] [-17. -21.]\n",
      "[188.  88.] [154.  96.] [34. -8.]\n",
      "[108.  78.] [130. 111.] [-22. -33.]\n",
      "[115. 122.] [115.  66.] [ 0. 56.]\n",
      "[141. 140.] [143.  87.] [-2. 53.]\n",
      "[162.  82.] [176. 123.] [-14. -41.]\n",
      "[115.  97.] [158. 104.] [-43.  -7.]\n",
      "[142. 101.] [141. 102.] [ 1. -1.]\n",
      "[126. 117.] [129.  89.] [-3. 28.]\n",
      "[105. 122.] [84. 63.] [21. 59.]\n",
      "[121.  56.] [102. 121.] [ 19. -65.]\n",
      "[179.  81.] [171. 113.] [  8. -32.]\n",
      "[79. 63.] [136. 115.] [-57. -52.]\n",
      "[138. 130.] [157.  68.] [-19.  62.]\n",
      "[125. 140.] [132.  68.] [-7. 72.]\n",
      "[130.  76.] [127. 115.] [  3. -39.]\n",
      "[167.  64.] [142.  34.] [25. 30.]\n",
      "[165. 105.] [158.  89.] [ 7. 16.]\n",
      "[156. 126.] [171.  91.] [-15.  35.]\n",
      "[167.  74.] [156. 146.] [ 11. -72.]\n",
      "[172. 132.] [173.  88.] [-1. 44.]\n",
      "[190.  76.] [152. 103.] [ 38. -27.]\n",
      "[165.  48.] [150. 141.] [ 15. -93.]\n",
      "[176. 109.] [196.  95.] [-20.  14.]\n",
      "[143. 131.] [126.  74.] [17. 57.]\n",
      "[169. 133.] [147.  66.] [22. 67.]\n",
      "[170. 123.] [169.  77.] [ 1. 46.]\n",
      "[156.  93.] [149. 112.] [  7. -19.]\n",
      "[135. 104.] [127.  90.] [ 8. 14.]\n",
      "[117.  80.] [147. 112.] [-30. -32.]\n",
      "[198. 108.] [167.  86.] [31. 22.]\n",
      "[189.  78.] [186. 130.] [  3. -52.]\n",
      "[102. 104.] [134.  95.] [-32.   9.]\n",
      "[185.  62.] [165. 131.] [ 20. -69.]\n",
      "[120. 138.] [129.  73.] [-9. 65.]\n",
      "[145.  77.] [136. 121.] [  9. -44.]\n",
      "[130.  91.] [148. 100.] [-18.  -9.]\n",
      "[160.  76.] [143. 116.] [ 17. -40.]\n",
      "[115. 138.] [135.  82.] [-20.  56.]\n",
      "[120. 122.] [108.  65.] [12. 57.]\n",
      "[128. 122.] [146.  81.] [-18.  41.]\n",
      "[159. 149.] [157.  77.] [ 2. 72.]\n",
      "[158.  81.] [148. 109.] [ 10. -28.]\n",
      "[142.  97.] [124.  99.] [18. -2.]\n",
      "[187.  47.] [174. 122.] [ 13. -75.]\n",
      "[158. 103.] [143. 106.] [15. -3.]\n",
      "[153.  43.] [146. 120.] [  7. -77.]\n",
      "[124.  98.] [139. 107.] [-15.  -9.]\n",
      "[153. 111.] [144.  92.] [ 9. 19.]\n",
      "[145. 107.] [144.  86.] [ 1. 21.]\n",
      "[210.  74.] [177. 119.] [ 33. -45.]\n",
      "[125. 115.] [124.  79.] [ 1. 36.]\n",
      "[135.  80.] [140. 108.] [ -5. -28.]\n",
      "[148. 105.] [144. 101.] [4. 4.]\n",
      "[109. 105.] [120. 107.] [-11.  -2.]\n",
      "[202.  72.] [242. 136.] [-40. -64.]\n",
      "[150.  65.] [137. 122.] [ 13. -57.]\n",
      "[167.  98.] [154.  88.] [13. 10.]\n",
      "[133. 117.] [163.  87.] [-30.  30.]\n",
      "[151. 127.] [147.  79.] [ 4. 48.]\n",
      "[141. 101.] [130. 105.] [11. -4.]\n",
      "[69. 69.] [134. 118.] [-65. -49.]\n",
      "[189.  52.] [165. 132.] [ 24. -80.]\n",
      "[153.  67.] [152. 129.] [  1. -62.]\n",
      "[191. 111.] [188.  99.] [ 3. 12.]\n",
      "[108. 116.] [123.  91.] [-15.  25.]\n",
      "[172.  89.] [154. 107.] [ 18. -18.]\n",
      "[121.  73.] [151. 121.] [-30. -48.]\n",
      "[127.  88.] [137. 114.] [-10. -26.]\n",
      "[163.  99.] [206. 126.] [-43. -27.]\n",
      "[ 98. 136.] [100.  86.] [-2. 50.]\n",
      "[129.  49.] [139. 132.] [-10. -83.]\n",
      "[161. 114.] [157.  88.] [ 4. 26.]\n",
      "[144.  93.] [148.  98.] [-4. -5.]\n",
      "[224.  76.] [187. 115.] [ 37. -39.]\n",
      "[161.  87.] [158. 102.] [  3. -15.]\n",
      "[132.  94.] [132. 134.] [  0. -40.]\n",
      "[ 99. 138.] [109.  76.] [-10.  62.]\n",
      "[ 84. 121.] [55. 72.] [29. 49.]\n",
      "[168.  68.] [156. 103.] [ 12. -35.]\n",
      "[126.  74.] [131. 114.] [ -5. -40.]\n",
      "[124. 103.] [125.  91.] [-1. 12.]\n",
      "[ 73. 112.] [113. 104.] [-40.   8.]\n",
      "[158. 121.] [138.  61.] [20. 60.]\n",
      "[198. 138.] [205.  30.] [ -7. 108.]\n",
      "[135.  65.] [140. 121.] [ -5. -56.]\n",
      "[166. 103.] [149.  90.] [17. 13.]\n",
      "[149. 120.] [144.  93.] [ 5. 27.]\n",
      "[156.  77.] [136. 109.] [ 20. -32.]\n",
      "[137. 127.] [128.  76.] [ 9. 51.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146. 119.] [163.  73.] [-17.  46.]\n",
      "[173. 125.] [185.  77.] [-12.  48.]\n",
      "[187. 112.] [171.  83.] [16. 29.]\n",
      "[134. 112.] [163.  93.] [-29.  19.]\n",
      "[212.  96.] [177. 106.] [ 35. -10.]\n",
      "[178. 116.] [162.  97.] [16. 19.]\n",
      "[156. 117.] [143. 108.] [13.  9.]\n",
      "[142.  96.] [147. 106.] [ -5. -10.]\n",
      "[ 85. 112.] [120. 109.] [-35.   3.]\n",
      "[133.  94.] [146.  96.] [-13.  -2.]\n",
      "[171. 101.] [179. 103.] [-8. -2.]\n",
      "[110. 100.] [148.  89.] [-38.  11.]\n",
      "[ 80. 118.] [55. 49.] [25. 69.]\n",
      "[144.  97.] [135. 112.] [  9. -15.]\n",
      "[167. 109.] [239. 101.] [-72.   8.]\n",
      "[202.  88.] [214.  95.] [-12.  -7.]\n",
      "[142. 127.] [146.  64.] [-4. 63.]\n",
      "[158. 127.] [150.  98.] [ 8. 29.]\n",
      "[172.  83.] [162. 105.] [ 10. -22.]\n",
      "[195.  70.] [185. 105.] [ 10. -35.]\n",
      "[167.  98.] [158. 102.] [ 9. -4.]\n",
      "[142.  79.] [145. 115.] [ -3. -36.]\n",
      "[149. 127.] [161.  80.] [-12.  47.]\n",
      "[122. 129.] [123.  71.] [-1. 58.]\n",
      "[168. 151.] [157.  79.] [11. 72.]\n",
      "[122.  83.] [131. 133.] [ -9. -50.]\n",
      "[137. 110.] [149.  99.] [-12.  11.]\n",
      "[156.  64.] [147. 115.] [  9. -51.]\n",
      "[152. 127.] [147.  76.] [ 5. 51.]\n",
      "[161.  77.] [139. 119.] [ 22. -42.]\n",
      "[153.  96.] [142.  94.] [11.  2.]\n",
      "[147.  87.] [150.  99.] [ -3. -12.]\n",
      "[140.  96.] [136. 101.] [ 4. -5.]\n",
      "[163.  82.] [171. 114.] [ -8. -32.]\n",
      "[146.  94.] [147. 102.] [-1. -8.]\n",
      "[149. 133.] [153.  78.] [-4. 55.]\n",
      "[100.  97.] [109. 106.] [-9. -9.]\n",
      "[167. 143.] [170.  81.] [-3. 62.]\n",
      "[139. 111.] [153. 102.] [-14.   9.]\n",
      "[189.  91.] [166. 104.] [ 23. -13.]\n",
      "[165.  82.] [179. 124.] [-14. -42.]\n",
      "[106.  83.] [122. 113.] [-16. -30.]\n",
      "[98. 57.] [129. 146.] [-31. -89.]\n",
      "[166.  77.] [175. 125.] [ -9. -48.]\n",
      "[141. 148.] [156.  99.] [-15.  49.]\n",
      "[157. 144.] [156.  88.] [ 1. 56.]\n",
      "[158.  72.] [174. 173.] [ -16. -101.]\n",
      "[175. 110.] [154.  91.] [21. 19.]\n",
      "[137.  71.] [130. 114.] [  7. -43.]\n",
      "[131. 109.] [111. 110.] [20. -1.]\n",
      "[130. 116.] [145.  88.] [-15.  28.]\n",
      "[123. 125.] [147.  93.] [-24.  32.]\n",
      "[177.  62.] [144. 165.] [  33. -103.]\n",
      "[161.  99.] [147.  97.] [14.  2.]\n",
      "[181. 126.] [164.  69.] [17. 57.]\n",
      "[167.  63.] [148. 115.] [ 19. -52.]\n",
      "[171. 135.] [163.  89.] [ 8. 46.]\n",
      "[191.  73.] [168. 118.] [ 23. -45.]\n",
      "[165.  60.] [164. 124.] [  1. -64.]\n",
      "[166. 124.] [168.  81.] [-2. 43.]\n",
      "[162.  76.] [149. 110.] [ 13. -34.]\n",
      "[204.  85.] [190. 112.] [ 14. -27.]\n",
      "[185.  82.] [164. 116.] [ 21. -34.]\n",
      "[161. 147.] [152.  62.] [ 9. 85.]\n",
      "[159.  89.] [155. 102.] [  4. -13.]\n",
      "[150.  81.] [144.  95.] [  6. -14.]\n",
      "[112.  79.] [127. 110.] [-15. -31.]\n",
      "[141.  67.] [142. 110.] [ -1. -43.]\n",
      "[169.  72.] [175. 124.] [ -6. -52.]\n",
      "[113.  51.] [136. 119.] [-23. -68.]\n",
      "[158.  61.] [156. 124.] [  2. -63.]\n",
      "[147. 108.] [149.  84.] [-2. 24.]\n",
      "[142. 147.] [164.  59.] [-22.  88.]\n",
      "[110. 130.] [110.  91.] [ 0. 39.]\n",
      "[135.  78.] [120. 137.] [ 15. -59.]\n",
      "[110. 103.] [128. 106.] [-18.  -3.]\n",
      "[189.  83.] [165. 103.] [ 24. -20.]\n",
      "[154.  90.] [149. 100.] [  5. -10.]\n",
      "[169.  91.] [164. 100.] [ 5. -9.]\n",
      "[178.  89.] [177. 106.] [  1. -17.]\n",
      "[178.  67.] [135. 105.] [ 43. -38.]\n",
      "[162.  70.] [168. 143.] [ -6. -73.]\n",
      "[176.  87.] [164.  86.] [12.  1.]\n",
      "[203. 138.] [167.  81.] [36. 57.]\n",
      "[ 92. 135.] [94. 75.] [-2. 60.]\n",
      "[154.  63.] [155. 115.] [ -1. -52.]\n",
      "[123.  87.] [109. 110.] [ 14. -23.]\n",
      "[186.  94.] [170.  90.] [16.  4.]\n",
      "[153.  72.] [125. 120.] [ 28. -48.]\n",
      "[130. 106.] [142.  93.] [-12.  13.]\n",
      "[165. 102.] [166. 116.] [ -1. -14.]\n",
      "[147.  94.] [150. 101.] [-3. -7.]\n",
      "[192. 141.] [171.  85.] [21. 56.]\n",
      "[154.  70.] [138. 117.] [ 16. -47.]\n",
      "[87. 77.] [115. 110.] [-28. -33.]\n",
      "[119.  74.] [144. 109.] [-25. -35.]\n",
      "[195.  69.] [166. 101.] [ 29. -32.]\n",
      "[167. 112.] [185.  86.] [-18.  26.]\n",
      "[128. 119.] [144.  85.] [-16.  34.]\n",
      "[129.  89.] [147. 100.] [-18. -11.]\n",
      "[127.  90.] [121. 121.] [  6. -31.]\n",
      "[198.  83.] [167. 102.] [ 31. -19.]\n",
      "[151.  94.] [141. 103.] [10. -9.]\n",
      "[ 97. 124.] [116.  81.] [-19.  43.]\n",
      "[167. 150.] [154.  96.] [13. 54.]\n",
      "[135. 107.] [109. 120.] [ 26. -13.]\n",
      "[188. 100.] [170.  92.] [18.  8.]\n",
      "[181. 139.] [148.  74.] [33. 65.]\n",
      "[113. 136.] [156.  72.] [-43.  64.]\n",
      "[182.  85.] [147.  97.] [ 35. -12.]\n",
      "[113.  77.] [118. 134.] [ -5. -57.]\n",
      "[ 99. 127.] [149.  95.] [-50.  32.]\n",
      "[124. 120.] [137.  81.] [-13.  39.]\n",
      "[120.  85.] [121.  98.] [ -1. -13.]\n",
      "[148. 125.] [126.  93.] [22. 32.]\n",
      "[175. 118.] [154.  94.] [21. 24.]\n",
      "[195.  63.] [204. 157.] [ -9. -94.]\n",
      "[162. 114.] [159.  94.] [ 3. 20.]\n",
      "[138. 102.] [107. 104.] [31. -2.]\n",
      "[143.  68.] [151. 106.] [ -8. -38.]\n",
      "[155.  47.] [146. 136.] [  9. -89.]\n",
      "[114.  86.] [124. 119.] [-10. -33.]\n",
      "[161.  80.] [138. 108.] [ 23. -28.]\n",
      "[173. 126.] [156.  86.] [17. 40.]\n",
      "[126. 123.] [148.  98.] [-22.  25.]\n",
      "[ 98. 120.] [114.  88.] [-16.  32.]\n",
      "[137.  61.] [133. 137.] [  4. -76.]\n",
      "[147. 152.] [130.  48.] [ 17. 104.]\n",
      "[144.  77.] [152. 105.] [ -8. -28.]\n",
      "[174.  72.] [175. 116.] [ -1. -44.]\n",
      "[135.  64.] [138. 129.] [ -3. -65.]\n",
      "[181. 127.] [151.  99.] [30. 28.]\n",
      "[199.  88.] [202. 122.] [ -3. -34.]\n",
      "[106.  87.] [132. 125.] [-26. -38.]\n",
      "[141.  55.] [136. 130.] [  5. -75.]\n",
      "[153. 111.] [150.  97.] [ 3. 14.]\n",
      "[140. 101.] [135.  94.] [5. 7.]\n",
      "[130. 127.] [153.  97.] [-23.  30.]\n",
      "[195.  69.] [188. 134.] [  7. -65.]\n",
      "[136. 103.] [138. 112.] [-2. -9.]\n",
      "[107. 110.] [116. 100.] [-9. 10.]\n",
      "[130. 121.] [130.  86.] [ 0. 35.]\n",
      "[173. 118.] [169.  88.] [ 4. 30.]\n",
      "[149.  93.] [147. 107.] [  2. -14.]\n",
      "[176. 132.] [168.  75.] [ 8. 57.]\n",
      "[113.  94.] [122. 111.] [ -9. -17.]\n",
      "[226.  89.] [169. 114.] [ 57. -25.]\n",
      "[145. 134.] [147.  98.] [-2. 36.]\n",
      "[150.  97.] [145.  89.] [5. 8.]\n",
      "[149. 105.] [150.  95.] [-1. 10.]\n",
      "[169.  91.] [183. 128.] [-14. -37.]\n",
      "[75. 67.] [124. 131.] [-49. -64.]\n",
      "[136.  60.] [160. 130.] [-24. -70.]\n",
      "[126. 115.] [147.  95.] [-21.  20.]\n",
      "[120.  91.] [148. 100.] [-28.  -9.]\n",
      "[137.  99.] [132.  97.] [5. 2.]\n",
      "[112.  88.] [108. 113.] [  4. -25.]\n",
      "[163.  91.] [158. 108.] [  5. -17.]\n",
      "[171.  69.] [167. 141.] [  4. -72.]\n",
      "[198.  65.] [163. 107.] [ 35. -42.]\n",
      "[ 99. 135.] [93. 77.] [ 6. 58.]\n",
      "[144.  97.] [155.  73.] [-11.  24.]\n",
      "[138. 110.] [127.  82.] [11. 28.]\n",
      "[134. 124.] [148.  77.] [-14.  47.]\n",
      "[153. 101.] [149.  85.] [ 4. 16.]\n",
      "[141.  67.] [133. 137.] [  8. -70.]\n",
      "[123.  92.] [106. 116.] [ 17. -24.]\n",
      "[184.  83.] [169. 115.] [ 15. -32.]\n",
      "[161.  75.] [158. 110.] [  3. -35.]\n",
      "[166. 116.] [209.  87.] [-43.  29.]\n",
      "[169. 133.] [160.  87.] [ 9. 46.]\n",
      "[142. 100.] [148.  79.] [-6. 21.]\n",
      "[125. 107.] [150.  96.] [-25.  11.]\n",
      "[73. 69.] [ 94. 140.] [-21. -71.]\n",
      "[133.  93.] [123. 102.] [10. -9.]\n",
      "[189. 120.] [171.  95.] [18. 25.]\n",
      "[116.  85.] [149.  95.] [-33. -10.]\n",
      "[176.  72.] [164. 109.] [ 12. -37.]\n",
      "[144. 135.] [179.  72.] [-35.  63.]\n",
      "[155. 134.] [139.  41.] [16. 93.]\n",
      "[176. 131.] [149.  97.] [27. 34.]\n",
      "[122.  88.] [127. 110.] [ -5. -22.]\n",
      "[147. 124.] [152. 104.] [-5. 20.]\n",
      "[155.  95.] [149.  99.] [ 6. -4.]\n",
      "[84. 99.] [135. 105.] [-51.  -6.]\n",
      "[151. 108.] [140.  62.] [11. 46.]\n",
      "[171. 115.] [157.  98.] [14. 17.]\n",
      "[101. 141.] [103.  89.] [-2. 52.]\n",
      "[194.  70.] [207. 169.] [-13. -99.]\n",
      "[142.  57.] [149. 158.] [  -7. -101.]\n",
      "[134.  79.] [130. 117.] [  4. -38.]\n",
      "[127.  88.] [146.  99.] [-19. -11.]\n",
      "[162. 118.] [152.  90.] [10. 28.]\n",
      "[148.  76.] [143. 139.] [  5. -63.]\n",
      "[150. 106.] [164.  88.] [-14.  18.]\n",
      "[139.  49.] [146. 133.] [ -7. -84.]\n",
      "[126.  65.] [124. 126.] [  2. -61.]\n",
      "[147.  77.] [157. 115.] [-10. -38.]\n",
      "[162. 102.] [161. 115.] [  1. -13.]\n",
      "[198.  84.] [174. 109.] [ 24. -25.]\n",
      "[139.  85.] [142. 105.] [ -3. -20.]\n",
      "[182. 114.] [168. 118.] [14. -4.]\n",
      "[114. 100.] [164. 105.] [-50.  -5.]\n",
      "[131.  68.] [116. 133.] [ 15. -65.]\n",
      "[158.  64.] [140. 101.] [ 18. -37.]\n",
      "[134. 134.] [151.  88.] [-17.  46.]\n",
      "[174. 126.] [186.  58.] [-12.  68.]\n",
      "[126.  65.] [142. 143.] [-16. -78.]\n",
      "[113.  79.] [ 94. 124.] [ 19. -45.]\n",
      "[111. 114.] [114.  81.] [-3. 33.]\n",
      "[148.  57.] [152. 117.] [ -4. -60.]\n",
      "[140.  90.] [133. 113.] [  7. -23.]\n",
      "[98. 52.] [103. 133.] [ -5. -81.]\n",
      "[137. 118.] [144.  91.] [-7. 27.]\n",
      "[89. 79.] [ 61. 103.] [ 28. -24.]\n",
      "[139.  79.] [154. 122.] [-15. -43.]\n",
      "[144. 113.] [165.  92.] [-21.  21.]\n",
      "[178. 123.] [157.  59.] [21. 64.]\n",
      "[132. 112.] [138.  91.] [-6. 21.]\n",
      "[139. 105.] [144.  96.] [-5.  9.]\n",
      "[165. 103.] [164.  97.] [1. 6.]\n",
      "[175. 136.] [150. 101.] [25. 35.]\n",
      "[128. 119.] [130.  81.] [-2. 38.]\n",
      "[140.  60.] [138. 115.] [  2. -55.]\n",
      "[162.  98.] [150. 100.] [12. -2.]\n",
      "[196.  76.] [161. 119.] [ 35. -43.]\n",
      "[150.  55.] [143. 159.] [   7. -104.]\n",
      "[208. 136.] [155.  98.] [53. 38.]\n",
      "[120.  65.] [115. 103.] [  5. -38.]\n",
      "[157.  45.] [161. 156.] [  -4. -111.]\n",
      "[119. 110.] [125.  95.] [-6. 15.]\n",
      "[164.  91.] [160. 107.] [  4. -16.]\n",
      "[81. 67.] [127. 108.] [-46. -41.]\n",
      "[133.  72.] [146. 105.] [-13. -33.]\n",
      "[98. 63.] [ 99. 131.] [ -1. -68.]\n",
      "[151.  57.] [155. 124.] [ -4. -67.]\n",
      "[142. 152.] [148.  56.] [-6. 96.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174. 109.] [167.  97.] [ 7. 12.]\n",
      "[170. 111.] [161.  82.] [ 9. 29.]\n",
      "[107.  91.] [115. 106.] [ -8. -15.]\n",
      "[120.  73.] [143. 107.] [-23. -34.]\n",
      "[182. 123.] [171.  85.] [11. 38.]\n",
      "[144. 130.] [155.  90.] [-11.  40.]\n",
      "[184.  98.] [156. 104.] [28. -6.]\n",
      "[187. 138.] [160.  90.] [27. 48.]\n",
      "[140.  79.] [143. 112.] [ -3. -33.]\n",
      "[93. 74.] [105. 121.] [-12. -47.]\n",
      "[141. 148.] [142.  86.] [-1. 62.]\n",
      "[125. 123.] [143.  86.] [-18.  37.]\n",
      "[169.  86.] [151. 105.] [ 18. -19.]\n",
      "[ 91. 107.] [121. 102.] [-30.   5.]\n",
      "[159. 133.] [137.  67.] [22. 66.]\n",
      "[179. 146.] [156.  97.] [23. 49.]\n",
      "[124.  87.] [135. 116.] [-11. -29.]\n",
      "[115. 114.] [112.  92.] [ 3. 22.]\n",
      "[159. 121.] [160.  78.] [-1. 43.]\n",
      "[152.  88.] [141. 105.] [ 11. -17.]\n",
      "[152. 111.] [145.  80.] [ 7. 31.]\n",
      "[157.  85.] [157. 117.] [  0. -32.]\n",
      "[156.  61.] [162. 142.] [ -6. -81.]\n",
      "[173. 146.] [147.  87.] [26. 59.]\n",
      "[142. 123.] [139.  75.] [ 3. 48.]\n",
      "[159. 107.] [140.  93.] [19. 14.]\n",
      "[113.  78.] [148. 106.] [-35. -28.]\n",
      "[171. 143.] [122. 107.] [49. 36.]\n",
      "[143.  69.] [150. 101.] [ -7. -32.]\n",
      "[113.  75.] [129. 115.] [-16. -40.]\n",
      "[144.  82.] [143. 118.] [  1. -36.]\n",
      "[135. 101.] [144.  92.] [-9.  9.]\n",
      "[150. 160.] [148.  37.] [  2. 123.]\n",
      "[123.  87.] [128.  90.] [-5. -3.]\n",
      "[188. 120.] [161.  81.] [27. 39.]\n",
      "[145.  85.] [138. 111.] [  7. -26.]\n",
      "[172. 114.] [156. 109.] [16.  5.]\n",
      "[128.  68.] [151. 112.] [-23. -44.]\n",
      "[160. 138.] [152.  44.] [ 8. 94.]\n",
      "[105. 123.] [144. 100.] [-39.  23.]\n",
      "[155. 143.] [158.  57.] [-3. 86.]\n",
      "[156. 128.] [152.  87.] [ 4. 41.]\n",
      "[201.  87.] [180. 113.] [ 21. -26.]\n",
      "[100. 105.] [123. 102.] [-23.   3.]\n",
      "[113. 119.] [108.  56.] [ 5. 63.]\n",
      "[164. 100.] [165. 101.] [-1. -1.]\n",
      "[103.  79.] [106. 104.] [ -3. -25.]\n",
      "[128. 134.] [167.  90.] [-39.  44.]\n",
      "[119. 108.] [136.  87.] [-17.  21.]\n",
      "[211.  80.] [208. 102.] [  3. -22.]\n",
      "[109.  76.] [144. 113.] [-35. -37.]\n",
      "[93. 75.] [ 49. 134.] [ 44. -59.]\n",
      "[168. 100.] [157.  82.] [11. 18.]\n",
      "[148.  98.] [150.  99.] [-2. -1.]\n",
      "[130. 117.] [119.  99.] [11. 18.]\n",
      "[135.  75.] [164. 147.] [-29. -72.]\n",
      "[142. 136.] [129.  69.] [13. 67.]\n",
      "[130. 123.] [131.  96.] [-1. 27.]\n",
      "[172.  93.] [179. 106.] [ -7. -13.]\n",
      "[139. 121.] [128.  63.] [11. 58.]\n",
      "[176. 103.] [177. 105.] [-1. -2.]\n",
      "[124. 140.] [148.  73.] [-24.  67.]\n",
      "[125. 139.] [139.  86.] [-14.  53.]\n",
      "[166. 143.] [163.  68.] [ 3. 75.]\n",
      "[139.  48.] [141. 121.] [ -2. -73.]\n",
      "[141. 118.] [144. 101.] [-3. 17.]\n",
      "[152. 127.] [155.  83.] [-3. 44.]\n",
      "[148.  48.] [152. 145.] [ -4. -97.]\n",
      "[156. 101.] [171.  99.] [-15.   2.]\n",
      "[135.  47.] [151.  95.] [-16. -48.]\n",
      "[176.  74.] [180. 128.] [ -4. -54.]\n",
      "[149.  48.] [159. 121.] [-10. -73.]\n",
      "[169.  98.] [135.  91.] [34.  7.]\n",
      "[151.  57.] [149. 120.] [  2. -63.]\n",
      "[179. 130.] [162.  97.] [17. 33.]\n",
      "[ 92. 146.] [131.  74.] [-39.  72.]\n",
      "[161. 143.] [155.  71.] [ 6. 72.]\n",
      "[106.  70.] [139. 119.] [-33. -49.]\n",
      "[106. 142.] [113.  73.] [-7. 69.]\n",
      "[104.  53.] [101. 131.] [  3. -78.]\n",
      "[175.  63.] [175. 154.] [  0. -91.]\n",
      "[160.  89.] [140. 105.] [ 20. -16.]\n",
      "[118. 128.] [133.  88.] [-15.  40.]\n",
      "[161.  63.] [154. 111.] [  7. -48.]\n",
      "[158. 105.] [163.  99.] [-5.  6.]\n",
      "[158. 120.] [144. 104.] [14. 16.]\n",
      "[135.  97.] [146. 113.] [-11. -16.]\n",
      "[163.  98.] [162. 106.] [ 1. -8.]\n",
      "[ 98. 102.] [ 74. 106.] [24. -4.]\n",
      "[147.  70.] [147. 115.] [  0. -45.]\n",
      "[104. 143.] [99. 37.] [  5. 106.]\n",
      "[183.  70.] [187. 129.] [ -4. -59.]\n",
      "[152. 114.] [153. 101.] [-1. 13.]\n",
      "[180.  69.] [166. 119.] [ 14. -50.]\n",
      "[153. 100.] [161. 105.] [-8. -5.]\n",
      "[160. 138.] [200.  61.] [-40.  77.]\n",
      "[204. 125.] [166.  89.] [38. 36.]\n",
      "[171.  87.] [176.  92.] [-5. -5.]\n",
      "[130.  91.] [126. 101.] [  4. -10.]\n",
      "[143.  80.] [141. 103.] [  2. -23.]\n",
      "[143. 106.] [142.  78.] [ 1. 28.]\n",
      "[122.  77.] [135. 112.] [-13. -35.]\n",
      "[152. 124.] [153.  89.] [-1. 35.]\n",
      "[184. 128.] [185.  69.] [-1. 59.]\n",
      "[137.  86.] [140.  90.] [-3. -4.]\n",
      "[110. 122.] [122.  89.] [-12.  33.]\n",
      "[142. 139.] [121.  66.] [21. 73.]\n",
      "[91. 96.] [62. 93.] [29.  3.]\n",
      "[132.  78.] [134. 126.] [ -2. -48.]\n",
      "[155.  94.] [157. 122.] [ -2. -28.]\n",
      "[155.  99.] [139.  96.] [16.  3.]\n",
      "[142.  58.] [160. 195.] [ -18. -137.]\n",
      "[151. 106.] [149.  88.] [ 2. 18.]\n",
      "[169.  91.] [202. 114.] [-33. -23.]\n",
      "[145.  85.] [148. 102.] [ -3. -17.]\n",
      "[141. 107.] [134. 102.] [7. 5.]\n",
      "[138.  78.] [146. 116.] [ -8. -38.]\n",
      "[146. 155.] [149.  67.] [-3. 88.]\n",
      "[203.  83.] [189. 135.] [ 14. -52.]\n",
      "[191.  67.] [150. 101.] [ 41. -34.]\n",
      "[180.  78.] [181. 103.] [ -1. -25.]\n",
      "[126.  64.] [141. 123.] [-15. -59.]\n",
      "[111.  66.] [134. 130.] [-23. -64.]\n",
      "[134.  70.] [133. 123.] [  1. -53.]\n",
      "[160.  83.] [148.  98.] [ 12. -15.]\n",
      "[159. 103.] [151. 105.] [ 8. -2.]\n",
      "[140.  94.] [143.  93.] [-3.  1.]\n",
      "[156. 146.] [153.  55.] [ 3. 91.]\n",
      "[160. 104.] [162.  97.] [-2.  7.]\n",
      "[136.  81.] [151. 127.] [-15. -46.]\n",
      "[107.  62.] [153. 166.] [ -46. -104.]\n",
      "[187. 103.] [172. 100.] [15.  3.]\n",
      "[133. 120.] [101.  74.] [32. 46.]\n",
      "[142.  57.] [126. 112.] [ 16. -55.]\n",
      "[235. 130.] [244.  75.] [-9. 55.]\n",
      "[131.  75.] [167. 129.] [-36. -54.]\n",
      "[131. 121.] [134.  86.] [-3. 35.]\n",
      "[142.  90.] [149. 108.] [ -7. -18.]\n",
      "[136.  86.] [127. 100.] [  9. -14.]\n",
      "[197.  46.] [177. 131.] [ 20. -85.]\n",
      "[131. 111.] [109.  80.] [22. 31.]\n",
      "[178. 135.] [155.  87.] [23. 48.]\n",
      "[185.  99.] [163. 114.] [ 22. -15.]\n",
      "[ 63. 119.] [97. 94.] [-34.  25.]\n",
      "[160. 118.] [156.  83.] [ 4. 35.]\n",
      "[164.  96.] [142. 101.] [22. -5.]\n",
      "[120. 108.] [137. 100.] [-17.   8.]\n",
      "[124. 107.] [126.  91.] [-2. 16.]\n",
      "[188.  91.] [174. 104.] [ 14. -13.]\n",
      "[182.  92.] [159. 103.] [ 23. -11.]\n",
      "[ 82. 139.] [130.  92.] [-48.  47.]\n",
      "[163.  86.] [157. 102.] [  6. -16.]\n",
      "[139.  84.] [132. 121.] [  7. -37.]\n",
      "[89. 79.] [ 52. 110.] [ 37. -31.]\n",
      "[108.  75.] [128. 113.] [-20. -38.]\n",
      "[86. 77.] [100. 114.] [-14. -37.]\n",
      "[142. 127.] [151.  92.] [-9. 35.]\n",
      "[174.  81.] [177. 124.] [ -3. -43.]\n",
      "[106. 105.] [100.  98.] [6. 7.]\n",
      "[ 73. 129.] [146. 105.] [-73.  24.]\n",
      "[107.  88.] [110. 107.] [ -3. -19.]\n",
      "[157.  90.] [149. 104.] [  8. -14.]\n",
      "[152.  82.] [150. 107.] [  2. -25.]\n",
      "[ 76. 142.] [87. 72.] [-11.  70.]\n",
      "[107.  89.] [136.  92.] [-29.  -3.]\n",
      "[158.  81.] [150. 100.] [  8. -19.]\n",
      "[107. 128.] [138.  85.] [-31.  43.]\n",
      "[134. 112.] [126.  86.] [ 8. 26.]\n",
      "[83. 96.] [ 73. 111.] [ 10. -15.]\n",
      "[146. 101.] [143. 100.] [3. 1.]\n",
      "[124. 141.] [148.  67.] [-24.  74.]\n",
      "[117.  89.] [130.  93.] [-13.  -4.]\n",
      "[151.  89.] [150. 106.] [  1. -17.]\n",
      "[105.  84.] [127. 100.] [-22. -16.]\n",
      "[172. 126.] [156.  72.] [16. 54.]\n",
      "[129. 110.] [147.  95.] [-18.  15.]\n",
      "[140. 103.] [156.  98.] [-16.   5.]\n",
      "[121.  89.] [113. 106.] [  8. -17.]\n",
      "[146.  71.] [159. 114.] [-13. -43.]\n",
      "[191.  61.] [168. 116.] [ 23. -55.]\n",
      "[141.  77.] [149. 107.] [ -8. -30.]\n",
      "[159.  61.] [146. 125.] [ 13. -64.]\n",
      "[116. 144.] [145.  84.] [-29.  60.]\n",
      "[137.  67.] [135. 130.] [  2. -63.]\n",
      "[99. 71.] [133. 112.] [-34. -41.]\n",
      "[127.  78.] [119. 112.] [  8. -34.]\n",
      "[103.  72.] [110. 127.] [ -7. -55.]\n",
      "[142.  80.] [141.  99.] [  1. -19.]\n",
      "[184.  77.] [202.  90.] [-18. -13.]\n",
      "[173. 127.] [162.  73.] [11. 54.]\n",
      "[165. 117.] [158.  96.] [ 7. 21.]\n",
      "[195. 141.] [188.  69.] [ 7. 72.]\n",
      "[155. 140.] [159.  74.] [-4. 66.]\n",
      "[217. 123.] [207.  68.] [10. 55.]\n",
      "[217. 118.] [170.  77.] [47. 41.]\n",
      "[217. 143.] [196.  71.] [21. 72.]\n",
      "[142. 139.] [141.  48.] [ 1. 91.]\n",
      "[130. 126.] [139.  81.] [-9. 45.]\n",
      "[159. 111.] [152.  87.] [ 7. 24.]\n",
      "[154. 162.] [136.  70.] [18. 92.]\n",
      "[177. 120.] [164.  65.] [13. 55.]\n",
      "[141.  88.] [115. 104.] [ 26. -16.]\n",
      "[117.  87.] [123. 108.] [ -6. -21.]\n",
      "[141. 145.] [137.  45.] [  4. 100.]\n",
      "[117. 126.] [132.  87.] [-15.  39.]\n",
      "[150. 102.] [135.  96.] [15.  6.]\n",
      "[179. 109.] [199.  90.] [-20.  19.]\n",
      "[133. 112.] [148. 100.] [-15.  12.]\n",
      "[165.  99.] [151. 102.] [14. -3.]\n",
      "[106.  72.] [115. 132.] [ -9. -60.]\n",
      "[162.  72.] [161. 136.] [  1. -64.]\n",
      "[137. 122.] [135.  74.] [ 2. 48.]\n",
      "[114. 123.] [129.  91.] [-15.  32.]\n",
      "[103.  54.] [117. 133.] [-14. -79.]\n",
      "[142.  96.] [106.  82.] [36. 14.]\n",
      "[231.  55.] [160. 109.] [ 71. -54.]\n",
      "[199.  90.] [181. 111.] [ 18. -21.]\n",
      "[173.  60.] [146. 122.] [ 27. -62.]\n",
      "[137. 116.] [141.  73.] [-4. 43.]\n",
      "[136. 135.] [145.  72.] [-9. 63.]\n",
      "[191.  95.] [182. 107.] [  9. -12.]\n",
      "[176.  93.] [168. 109.] [  8. -16.]\n",
      "[ 96. 107.] [109.  92.] [-13.  15.]\n",
      "[145. 117.] [140.  97.] [ 5. 20.]\n",
      "[ 71. 100.] [100.  97.] [-29.   3.]\n",
      "[117. 122.] [109.  82.] [ 8. 40.]\n",
      "[172. 129.] [162.  82.] [10. 47.]\n",
      "[160. 142.] [133.  55.] [27. 87.]\n",
      "[146. 121.] [139.  84.] [ 7. 37.]\n",
      "[ 80. 123.] [105. 107.] [-25.  16.]\n",
      "[144. 139.] [146.  57.] [-2. 82.]\n",
      "[149. 107.] [155.  90.] [-6. 17.]\n",
      "[98. 76.] [109. 119.] [-11. -43.]\n",
      "[153. 115.] [116.  88.] [37. 27.]\n",
      "[128. 115.] [146.  66.] [-18.  49.]\n",
      "[142. 104.] [150. 103.] [-8.  1.]\n",
      "[147. 126.] [146.  73.] [ 1. 53.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164. 100.] [159. 106.] [ 5. -6.]\n",
      "[152. 144.] [144.  75.] [ 8. 69.]\n",
      "[97. 65.] [101. 136.] [ -4. -71.]\n",
      "[172.  73.] [149. 102.] [ 23. -29.]\n",
      "[180. 104.] [190.  88.] [-10.  16.]\n",
      "[175.  77.] [169. 112.] [  6. -35.]\n",
      "[156.  68.] [132. 110.] [ 24. -42.]\n",
      "[182. 111.] [150.  97.] [32. 14.]\n",
      "[152.  69.] [153. 107.] [ -1. -38.]\n",
      "[98. 83.] [141. 101.] [-43. -18.]\n",
      "[152.  69.] [161. 129.] [ -9. -60.]\n",
      "[162. 137.] [156.  78.] [ 6. 59.]\n",
      "[170. 125.] [181.  81.] [-11.  44.]\n",
      "[154.  95.] [146.  98.] [ 8. -3.]\n",
      "[172. 132.] [172.  74.] [ 0. 58.]\n",
      "[191.  95.] [194. 114.] [ -3. -19.]\n",
      "[140.  66.] [147. 110.] [ -7. -44.]\n",
      "[167.  96.] [171. 101.] [-4. -5.]\n",
      "[142.  86.] [144.  95.] [-2. -9.]\n",
      "[241.  73.] [163. 105.] [ 78. -32.]\n",
      "[146.  92.] [135. 104.] [ 11. -12.]\n",
      "[150. 103.] [113. 142.] [ 37. -39.]\n",
      "[135. 115.] [144.  92.] [-9. 23.]\n",
      "[130. 130.] [136.  78.] [-6. 52.]\n",
      "[171. 115.] [168.  94.] [ 3. 21.]\n",
      "[172.  82.] [162. 113.] [ 10. -31.]\n",
      "[165.  54.] [146. 179.] [  19. -125.]\n",
      "[125. 123.] [126.  83.] [-1. 40.]\n",
      "[146. 103.] [148.  97.] [-2.  6.]\n",
      "[205. 120.] [194.  88.] [11. 32.]\n",
      "[138.  66.] [150. 124.] [-12. -58.]\n",
      "[102. 121.] [192. 111.] [-90.  10.]\n",
      "[120.  95.] [143. 100.] [-23.  -5.]\n",
      "[ 93. 125.] [136.  92.] [-43.  33.]\n",
      "[127.  97.] [115. 109.] [ 12. -12.]\n",
      "[ 91. 124.] [91. 76.] [ 0. 48.]\n",
      "[154. 123.] [143.  79.] [11. 44.]\n",
      "[139. 100.] [201. 116.] [-62. -16.]\n",
      "[161. 134.] [166.  79.] [-5. 55.]\n",
      "[152.  83.] [140. 126.] [ 12. -43.]\n",
      "[105. 113.] [100.  84.] [ 5. 29.]\n",
      "[198.  91.] [201.  96.] [-3. -5.]\n",
      "[114.  88.] [111. 101.] [  3. -13.]\n",
      "[142. 112.] [146.  91.] [-4. 21.]\n",
      "[157.  98.] [168.  98.] [-11.   0.]\n",
      "[127. 134.] [131.  88.] [-4. 46.]\n",
      "[117.  88.] [135. 125.] [-18. -37.]\n",
      "[128. 119.] [130.  95.] [-2. 24.]\n",
      "[112. 118.] [133.  92.] [-21.  26.]\n",
      "[132. 153.] [148.  96.] [-16.  57.]\n",
      "[97. 92.] [ 99. 102.] [ -2. -10.]\n",
      "[151. 143.] [131.  35.] [ 20. 108.]\n",
      "[148.  80.] [130. 125.] [ 18. -45.]\n",
      "[120.  77.] [117. 101.] [  3. -24.]\n",
      "[218.  68.] [187. 122.] [ 31. -54.]\n",
      "[149. 118.] [151.  76.] [-2. 42.]\n",
      "[124.  89.] [148. 101.] [-24. -12.]\n",
      "[171.  99.] [157.  92.] [14.  7.]\n",
      "[146. 107.] [149.  98.] [-3.  9.]\n",
      "[189. 125.] [188.  60.] [ 1. 65.]\n",
      "[156. 129.] [133.  56.] [23. 73.]\n",
      "[162.  64.] [151. 123.] [ 11. -59.]\n",
      "[158.  65.] [171. 150.] [-13. -85.]\n",
      "[155. 111.] [146.  76.] [ 9. 35.]\n",
      "[148. 146.] [143.  52.] [ 5. 94.]\n",
      "[142. 102.] [136.  97.] [6. 5.]\n",
      "[151.  81.] [167. 153.] [-16. -72.]\n",
      "[132. 127.] [137.  76.] [-5. 51.]\n",
      "[200.  80.] [251. 127.] [-51. -47.]\n",
      "[123. 102.] [143.  99.] [-20.   3.]\n",
      "[132. 112.] [141.  99.] [-9. 13.]\n",
      "[145.  89.] [142.  97.] [ 3. -8.]\n",
      "[149.  49.] [149. 138.] [  0. -89.]\n",
      "[146. 154.] [154.  54.] [ -8. 100.]\n",
      "[138.  57.] [126. 163.] [  12. -106.]\n",
      "[157.  61.] [150. 118.] [  7. -57.]\n",
      "[207. 113.] [185.  85.] [22. 28.]\n",
      "[ 83. 132.] [99. 90.] [-16.  42.]\n",
      "[127.  81.] [113. 121.] [ 14. -40.]\n",
      "[199. 118.] [178. 116.] [21.  2.]\n",
      "[161. 137.] [158.  85.] [ 3. 52.]\n",
      "[204. 103.] [213. 102.] [-9.  1.]\n",
      "[152.  81.] [146. 109.] [  6. -28.]\n",
      "[153. 115.] [149.  72.] [ 4. 43.]\n",
      "[166. 117.] [169.  89.] [-3. 28.]\n",
      "[170.  71.] [171. 122.] [ -1. -51.]\n",
      "[170.  81.] [133. 152.] [ 37. -71.]\n",
      "[136.  98.] [150. 123.] [-14. -25.]\n",
      "[127. 123.] [142.  94.] [-15.  29.]\n",
      "[123. 102.] [144. 105.] [-21.  -3.]\n",
      "[150.  94.] [150. 100.] [ 0. -6.]\n",
      "[126.  81.] [144. 124.] [-18. -43.]\n",
      "[140. 115.] [83. 83.] [57. 32.]\n",
      "[128. 106.] [113.  90.] [15. 16.]\n",
      "[178. 109.] [163.  90.] [15. 19.]\n",
      "[140.  99.] [150. 113.] [-10. -14.]\n",
      "[187.  66.] [181. 136.] [  6. -70.]\n",
      "[142.  80.] [140. 121.] [  2. -41.]\n",
      "[138. 121.] [150.  99.] [-12.  22.]\n",
      "[147. 115.] [126. 108.] [21.  7.]\n",
      "[127.  87.] [145. 103.] [-18. -16.]\n",
      "[141. 138.] [152.  84.] [-11.  54.]\n",
      "[71. 64.] [130. 119.] [-59. -55.]\n",
      "[119.  96.] [154. 112.] [-35. -16.]\n",
      "[104. 101.] [136.  98.] [-32.   3.]\n",
      "[188. 106.] [199. 111.] [-11.  -5.]\n",
      "[179.  78.] [132. 109.] [ 47. -31.]\n",
      "[112.  84.] [ 84. 137.] [ 28. -53.]\n",
      "[186.  94.] [178. 122.] [  8. -28.]\n",
      "[170.  70.] [165. 138.] [  5. -68.]\n",
      "[137. 107.] [128.  88.] [ 9. 19.]\n",
      "[151. 108.] [158.  94.] [-7. 14.]\n",
      "[141.  85.] [143. 127.] [ -2. -42.]\n",
      "[69. 59.] [140. 109.] [-71. -50.]\n",
      "[125. 121.] [146.  94.] [-21.  27.]\n",
      "[198.  84.] [184. 102.] [ 14. -18.]\n",
      "[144.  77.] [161. 115.] [-17. -38.]\n",
      "[138.  81.] [141. 113.] [ -3. -32.]\n",
      "[154. 109.] [150.  95.] [ 4. 14.]\n",
      "[109.  83.] [157. 120.] [-48. -37.]\n",
      "[177. 135.] [164.  66.] [13. 69.]\n",
      "[201.  49.] [211. 156.] [ -10. -107.]\n",
      "[207. 143.] [175.  80.] [32. 63.]\n",
      "[186. 106.] [165.  92.] [21. 14.]\n",
      "[168. 114.] [163.  84.] [ 5. 30.]\n",
      "[168.  79.] [181. 121.] [-13. -42.]\n",
      "[147.  91.] [139. 117.] [  8. -26.]\n",
      "[163. 110.] [162.  79.] [ 1. 31.]\n",
      "[124. 137.] [129.  62.] [-5. 75.]\n",
      "[143.  76.] [156. 132.] [-13. -56.]\n",
      "[158.  92.] [153. 104.] [  5. -12.]\n",
      "[197. 108.] [190.  93.] [ 7. 15.]\n",
      "[139. 129.] [145.  78.] [-6. 51.]\n",
      "[169.  62.] [170. 120.] [ -1. -58.]\n",
      "[131.  67.] [134. 119.] [ -3. -52.]\n",
      "[183.  86.] [170. 101.] [ 13. -15.]\n",
      "[161. 130.] [187.  64.] [-26.  66.]\n",
      "[110.  77.] [138. 103.] [-28. -26.]\n",
      "[142.  92.] [178.  91.] [-36.   1.]\n",
      "[157. 113.] [155.  79.] [ 2. 34.]\n",
      "[183. 104.] [217. 113.] [-34.  -9.]\n",
      "[178. 120.] [158. 101.] [20. 19.]\n",
      "[126. 132.] [172.  60.] [-46.  72.]\n",
      "[150.  95.] [151. 107.] [ -1. -12.]\n",
      "[159. 108.] [155.  89.] [ 4. 19.]\n",
      "[170. 116.] [173.  90.] [-3. 26.]\n",
      "[179. 131.] [149.  99.] [30. 32.]\n",
      "[144. 127.] [146.  41.] [-2. 86.]\n",
      "[188.  90.] [170. 102.] [ 18. -12.]\n",
      "[119. 106.] [147. 108.] [-28.  -2.]\n",
      "[95. 84.] [ 45. 112.] [ 50. -28.]\n",
      "[187.  84.] [167.  88.] [20. -4.]\n",
      "[212.  97.] [182.  81.] [30. 16.]\n",
      "[122.  89.] [ 99. 116.] [ 23. -27.]\n",
      "[146. 141.] [166.  62.] [-20.  79.]\n",
      "[184.  76.] [177. 125.] [  7. -49.]\n",
      "[138. 113.] [141.  83.] [-3. 30.]\n",
      "[133.  74.] [131. 124.] [  2. -50.]\n",
      "[131.  54.] [126. 169.] [   5. -115.]\n",
      "[95. 88.] [105.  81.] [-10.   7.]\n",
      "[176. 132.] [182.  77.] [-6. 55.]\n",
      "[167. 122.] [146.  87.] [21. 35.]\n",
      "[193.  79.] [149.  96.] [ 44. -17.]\n",
      "[125.  98.] [132. 104.] [-7. -6.]\n",
      "[166.  71.] [156. 118.] [ 10. -47.]\n",
      "[169. 130.] [138.  62.] [31. 68.]\n",
      "[158. 119.] [142.  78.] [16. 41.]\n",
      "[158.  98.] [122.  81.] [36. 17.]\n",
      "[196. 113.] [194.  92.] [ 2. 21.]\n",
      "[181. 157.] [161.  72.] [20. 85.]\n",
      "[160. 117.] [156.  83.] [ 4. 34.]\n",
      "[139. 137.] [87. 51.] [52. 86.]\n",
      "[164. 130.] [159.  75.] [ 5. 55.]\n",
      "[170.  80.] [152. 107.] [ 18. -27.]\n",
      "[114.  89.] [118.  97.] [-4. -8.]\n",
      "[191.  77.] [176. 100.] [ 15. -23.]\n",
      "[130. 131.] [132.  81.] [-2. 50.]\n",
      "[154. 126.] [151.  90.] [ 3. 36.]\n",
      "[140. 109.] [152.  85.] [-12.  24.]\n",
      "[198. 111.] [181.  91.] [17. 20.]\n",
      "[129. 110.] [136. 105.] [-7.  5.]\n",
      "[221. 110.] [206.  88.] [15. 22.]\n",
      "[133.  76.] [125. 126.] [  8. -50.]\n",
      "[114. 129.] [105.  54.] [ 9. 75.]\n",
      "[146. 127.] [131.  83.] [15. 44.]\n",
      "[112.  79.] [114. 113.] [ -2. -34.]\n",
      "[193. 135.] [194.  69.] [-1. 66.]\n",
      "[122.  64.] [135. 120.] [-13. -56.]\n",
      "[131.  98.] [120.  99.] [11. -1.]\n",
      "[173.  59.] [167. 125.] [  6. -66.]\n",
      "[137.  71.] [138. 122.] [ -1. -51.]\n",
      "[134.  88.] [157. 139.] [-23. -51.]\n",
      "[ 89. 142.] [136.  54.] [-47.  88.]\n",
      "[124. 118.] [132.  82.] [-8. 36.]\n",
      "[144.  42.] [140. 118.] [  4. -76.]\n",
      "[148. 138.] [148.  98.] [ 0. 40.]\n",
      "[143.  98.] [140.  94.] [3. 4.]\n",
      "[130. 145.] [162.  86.] [-32.  59.]\n",
      "[173. 105.] [149.  97.] [24.  8.]\n",
      "[134.  83.] [184. 129.] [-50. -46.]\n",
      "[159.  93.] [152.  95.] [ 7. -2.]\n",
      "[156.  92.] [147. 103.] [  9. -11.]\n",
      "[115. 114.] [110.  87.] [ 5. 27.]\n",
      "[180. 127.] [153.  91.] [27. 36.]\n",
      "[133.  94.] [142. 116.] [ -9. -22.]\n",
      "[144.  53.] [146. 118.] [ -2. -65.]\n",
      "[ 78. 128.] [137.  92.] [-59.  36.]\n",
      "[176.  83.] [167. 139.] [  9. -56.]\n",
      "[210. 125.] [177. 115.] [33. 10.]\n",
      "[165.  82.] [154. 103.] [ 11. -21.]\n",
      "[189. 104.] [161.  92.] [28. 12.]\n",
      "[148. 134.] [130.  53.] [18. 81.]\n",
      "[165. 115.] [187.  94.] [-22.  21.]\n",
      "[137. 109.] [150.  97.] [-13.  12.]\n",
      "[156. 101.] [136. 103.] [20. -2.]\n",
      "[178.  83.] [157. 109.] [ 21. -26.]\n",
      "[151. 117.] [155.  77.] [-4. 40.]\n",
      "[148. 111.] [163.  95.] [-15.  16.]\n",
      "[119. 104.] [148.  97.] [-29.   7.]\n",
      "[ 84. 106.] [79. 99.] [5. 7.]\n",
      "[164. 124.] [162.  71.] [ 2. 53.]\n",
      "[187.  58.] [199. 150.] [-12. -92.]\n",
      "[170.  68.] [167. 141.] [  3. -73.]\n",
      "[125. 100.] [86. 96.] [39.  4.]\n",
      "[169.  79.] [156. 118.] [ 13. -39.]\n",
      "[169.  85.] [159. 117.] [ 10. -32.]\n",
      "[124. 131.] [130.  74.] [-6. 57.]\n",
      "[178. 115.] [167.  93.] [11. 22.]\n",
      "[151.  99.] [163.  82.] [-12.  17.]\n",
      "[172.  55.] [151. 129.] [ 21. -74.]\n",
      "[145.  92.] [128. 102.] [ 17. -10.]\n",
      "[151.  99.] [156. 120.] [ -5. -21.]\n",
      "[ 81. 100.] [132.  80.] [-51.  20.]\n",
      "[155.  91.] [148. 106.] [  7. -15.]\n",
      "[ 97. 140.] [106.  84.] [-9. 56.]\n",
      "[144. 133.] [149.  98.] [-5. 35.]\n",
      "[127.  68.] [150. 102.] [-23. -34.]\n",
      "[132.  76.] [146. 126.] [-14. -50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148. 118.] [153.  98.] [-5. 20.]\n",
      "[159.  85.] [138. 106.] [ 21. -21.]\n",
      "[174. 117.] [171.  89.] [ 3. 28.]\n",
      "[189. 116.] [126.  89.] [63. 27.]\n",
      "[164.  71.] [151. 106.] [ 13. -35.]\n",
      "[108.  85.] [140.  86.] [-32.  -1.]\n",
      "[187. 116.] [151. 101.] [36. 15.]\n",
      "[151.  96.] [142.  88.] [9. 8.]\n",
      "[152.  95.] [145. 100.] [ 7. -5.]\n",
      "[170. 130.] [176.  63.] [-6. 67.]\n",
      "[121.  76.] [143.  98.] [-22. -22.]\n",
      "[102. 132.] [126.  56.] [-24.  76.]\n",
      "[163. 102.] [149.  99.] [14.  3.]\n",
      "[222.  91.] [276. 113.] [-54. -22.]\n",
      "[145. 117.] [136.  89.] [ 9. 28.]\n",
      "[178.  75.] [151.  99.] [ 27. -24.]\n",
      "[145. 140.] [153.  86.] [-8. 54.]\n",
      "[145.  68.] [150. 110.] [ -5. -42.]\n",
      "[152. 143.] [140.  49.] [12. 94.]\n",
      "[133. 131.] [115.  49.] [18. 82.]\n",
      "[202.  68.] [172. 130.] [ 30. -62.]\n",
      "[235. 111.] [212.  93.] [23. 18.]\n",
      "[161.  85.] [175. 128.] [-14. -43.]\n",
      "[142.  85.] [151. 126.] [ -9. -41.]\n",
      "[196.  57.] [183. 134.] [ 13. -77.]\n",
      "[142.  91.] [154.  96.] [-12.  -5.]\n",
      "[125. 102.] [119. 107.] [ 6. -5.]\n",
      "[163. 124.] [163.  70.] [ 0. 54.]\n",
      "[188.  85.] [182.  99.] [  6. -14.]\n",
      "[144.  94.] [129.  92.] [15.  2.]\n",
      "[177.  98.] [163. 102.] [14. -4.]\n",
      "[114.  92.] [113. 108.] [  1. -16.]\n",
      "[151.  96.] [148. 103.] [ 3. -7.]\n",
      "[140.  98.] [139. 103.] [ 1. -5.]\n",
      "[197. 114.] [238.  96.] [-41.  18.]\n",
      "[160. 120.] [148.  94.] [12. 26.]\n",
      "[99. 67.] [107. 121.] [ -8. -54.]\n",
      "[145.  65.] [158. 126.] [-13. -61.]\n",
      "[130. 132.] [181.  70.] [-51.  62.]\n",
      "[104.  87.] [102. 124.] [  2. -37.]\n",
      "[100. 114.] [120.  75.] [-20.  39.]\n",
      "[160.  90.] [164. 119.] [ -4. -29.]\n",
      "[146.  68.] [151. 105.] [ -5. -37.]\n",
      "[176. 104.] [161.  94.] [15. 10.]\n",
      "[157.  55.] [137. 135.] [ 20. -80.]\n",
      "[108.  92.] [114. 114.] [ -6. -22.]\n",
      "[153.  83.] [134.  73.] [19. 10.]\n",
      "[182.  80.] [153. 103.] [ 29. -23.]\n",
      "[166.  81.] [182. 114.] [-16. -33.]\n",
      "[151.  88.] [161. 104.] [-10. -16.]\n",
      "[141. 134.] [132.  63.] [ 9. 71.]\n",
      "[176. 131.] [164.  79.] [12. 52.]\n",
      "[97. 57.] [ 76. 156.] [ 21. -99.]\n",
      "[163.  56.] [132. 160.] [  31. -104.]\n",
      "[159.  83.] [155. 109.] [  4. -26.]\n",
      "[192. 114.] [141. 135.] [ 51. -21.]\n",
      "[149. 144.] [156.  71.] [-7. 73.]\n",
      "[175. 110.] [164. 109.] [11.  1.]\n",
      "[131.  87.] [154. 111.] [-23. -24.]\n",
      "[ 98. 133.] [137.  78.] [-39.  55.]\n",
      "[180. 131.] [180.  77.] [ 0. 54.]\n",
      "[114. 104.] [105.  97.] [9. 7.]\n",
      "[136. 113.] [125.  88.] [11. 25.]\n",
      "[132.  67.] [144. 138.] [-12. -71.]\n",
      "[212. 143.] [158.  68.] [54. 75.]\n",
      "[149. 110.] [149.  95.] [ 0. 15.]\n",
      "[127. 132.] [135.  82.] [-8. 50.]\n",
      "[186.  94.] [179. 108.] [  7. -14.]\n",
      "[208. 114.] [166.  91.] [42. 23.]\n",
      "[115. 142.] [132.  56.] [-17.  86.]\n",
      "[145.  89.] [140. 121.] [  5. -32.]\n",
      "[154.  98.] [149.  99.] [ 5. -1.]\n",
      "[162. 127.] [178.  64.] [-16.  63.]\n",
      "[170. 116.] [174.  99.] [-4. 17.]\n",
      "[194.  73.] [170. 112.] [ 24. -39.]\n",
      "[168. 119.] [163.  87.] [ 5. 32.]\n",
      "[160. 122.] [153.  94.] [ 7. 28.]\n",
      "[145. 128.] [152. 109.] [-7. 19.]\n",
      "[131. 101.] [90. 89.] [41. 12.]\n",
      "[148.  92.] [149. 126.] [ -1. -34.]\n",
      "[216.  77.] [226. 131.] [-10. -54.]\n",
      "[132. 104.] [123.  97.] [9. 7.]\n",
      "[149.  87.] [150. 113.] [ -1. -26.]\n",
      "[202. 116.] [180.  95.] [22. 21.]\n",
      "[129.  90.] [121. 100.] [  8. -10.]\n",
      "[138. 118.] [135.  80.] [ 3. 38.]\n",
      "[164. 124.] [152.  83.] [12. 41.]\n",
      "[208. 106.] [213. 106.] [-5.  0.]\n",
      "[149. 101.] [137.  90.] [12. 11.]\n",
      "[149. 106.] [157.  92.] [-8. 14.]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "for i in range(test_image_num):\n",
    "    img = Image.open(path + \"test/\"+ str(i)+'.png')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    pred = test_preds[i-15840]\n",
    "    \n",
    "    draw.line([tuple(pred - [10, 0]), tuple(pred + [10, 0])], fill=\"blue\", width=3)\n",
    "    draw.line([tuple(pred - [0, 10]), tuple(pred + [0, 10])], fill=\"red\", width=3)\n",
    "\n",
    "#    draw.point(labels_orig[i], fill=\"blue\")\n",
    "#    draw.point(preds[i-12000], fill=\"black\")\n",
    "    print(labels_orig[i], test_preds[i], labels_orig[i]- test_preds[i])\n",
    "    img.save(path + \"test/\" + \"preds_cpu/\" + str(i) + \"_pred.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE MODEL IF IT'S GOOD\n",
    "model.save_weights('/home/hippoc/schen/models/300_200_resnet8_gates_model_shitty.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
